# ECT_HW4_108403523

## 一. python 實作

### 1. 載入資料並刪除特定欄位

* 載入資料

![](https://i.imgur.com/3HfAUyj.jpg)

* 刪除題目指定不需要的欄位

![](https://i.imgur.com/hY2iMyh.jpg)

---

### 2. 將剩下的欄位做特徵篩選

* 產生所有欄位可能的組合 (共84組)

![](https://i.imgur.com/Lqt8DVv.jpg)

* 測試取得特定欄位 (成功)

![](https://i.imgur.com/rnt4QwM.jpg)

* 資料標準化 (StandardScaler)

![](https://i.imgur.com/XyNHvtM.jpg)

* 計算各種欄位組合及分群數的 silhouette score

![](https://i.imgur.com/Ce57e34.jpg)

* 找到分幾群的 silhouette score 比較高 (index+2群)

(分兩群的 score 比較高)
![](https://i.imgur.com/D0sgtY3.jpg)

* 找到是哪一種欄位組合

![](https://i.imgur.com/0LCqrVl.jpg)

* 檢視找出的資料欄位

![](https://i.imgur.com/9ZKI5j7.jpg)

* 該欄位組合分不同群時的 silhouette_score

![](https://i.imgur.com/FEvOtoh.jpg)

結論: 欄位是energy、acousticness、loudness，分2群。

---

### 3. 使用剛剛找出來的欄位用 k-means 做分群

* 設定模型參數進行預測

![](https://i.imgur.com/1VQDpSP.jpg)


* 將用來預測的資料欄位轉換為 DataFrame (後續也會重複使用到xx)

![](https://i.imgur.com/uSBJSXz.jpg)

* 將預測結果 bb 轉換成 DataFrame dd

![](https://i.imgur.com/FvGrs9n.jpg)

* 將 xx 與 dd 合併成新的 DataFrame

![](https://i.imgur.com/N3guMkb.jpg)

* 繪製出 3d 圖形

![](https://i.imgur.com/ZtOEjQe.jpg)

---

### 4. 使用剛剛找出來的欄位用 Meanshift 做分群

* 找出 bandwidth 並做 Meanshift 分群

![](https://i.imgur.com/JmznfWk.jpg)

* 將分群結果 labels 存成 DataFrame

![](https://i.imgur.com/fsUpzQO.jpg)

* 將 xx 與 jj 合併成新的 DataFrame fff

![](https://i.imgur.com/XkEQMOE.jpg)

* 繪製出 Meanshift 圖形

![](https://i.imgur.com/jHM9iaC.jpg)

---

### 5. 使用剛剛找出來的欄位用 k-prototypes 做分群

* 做 k-prototypes 分群

![](https://i.imgur.com/uGwPHQk.jpg)

* 將分群結果 bbcall 轉換成 DataFrame

![](https://i.imgur.com/JcZePgY.jpg)

* 將分群結果 bbcall_column 與原資料 xx 合併成新的 DataFrame

![](https://i.imgur.com/k7lSXFl.jpg)

* 繪製出 k-prototypes 3d 圖形

![](https://i.imgur.com/plT5bjN.jpg)

---

### 6. 使用剛剛找出來的欄位用 k-modes 做分群

* 用 k-modes 做分群

![](https://i.imgur.com/ZZhTkLN.jpg)

* 將分類結果 gg 存成 DataFrame bbcall_column2 並與原資料 xx 合併成新 DataFrame fffff

![](https://i.imgur.com/RgsphpJ.jpg)

* 繪製出 k-modes 3d 圖形

![](https://i.imgur.com/01mqhLO.jpg)

---

### 7. 比較說明上述四種分群法的差異

1. K-means : 分類時，必須通通使用 numeric 的 dtype，所以若有 categorical 的資料則需先做轉換才能做分群。給定初始群心後，它會去計算各筆資料和各群心的 Euclidean distance，利用計算出的距離遠近，判斷該筆資料要被分到哪一群。之後，新的群心會由被分類到該群的資料欄位數值平均決定，計算完後再次根據離群心之遠近，決定該筆資料歸屬何群。最後，反覆進行新群心的計算和離群心遠近的分群判斷，直到資料分群不再變動。

2. Meanshift : 在資料集中選定一個中心點，然後以這個中心點為圓心，r 為半徑，畫一個圓，求出這個圓心到所有點的向量的平均值。之後，利用圓心與向量均值的和算出新的圓心，然後反覆這個過程，直到找到涵蓋最多點的圓為止，也就是找到真正的分群中心。bandwidth 參數代表的就是圓的半徑 r。

3. K-prototypes : 兼具 K-means 和 K-modes 的特性。分群時，可以使用 categorical 和 numeric 資料，但不可以只有單一種資料，資料集必須同時具備兩種類型的資料。分群過程跟 K-means 大致相同，只是它混用與群心的 Euclidean distance 和 類別資料欄位的相似性，藉此決定該筆資料的分群歸屬。找新群心時，必須混和計算 numeric 資料平均和 categorical 資料的出現次數來擇定新群心。


4. K-modes : 分群時，必須通通使用 categorical 的 dtype，所以經過標準化的 numeric 資料還要再經過後續轉換才能做分群。給定起始群心後，它會比較各筆資料類別欄位值跟群心類別欄位值的相似程度決定資料要被分到哪一群，後續過程和 k-means 相同，群心會在每次分類後被重新計算，新群心的類別欄位值會是被分到該群資料欄位值出現次數最頻繁的值，結束計算後開啟下一輪的分群直至資料分群不再變動。

---

## 二. 使用 weka 做分群

* 載入資料、保留找出的三個欄位

![](https://i.imgur.com/BzRUTts.jpg)

* 設定分群參數

![](https://i.imgur.com/UkQVSSh.jpg)

* 分群結果(1)

![](https://i.imgur.com/MiZGOWP.jpg)

* 分群結果(2)

![](https://i.imgur.com/mw5JwNn.jpg)

* 分群結果視覺化

![](https://i.imgur.com/MCObutT.jpg)