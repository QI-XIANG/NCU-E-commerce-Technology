{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 將資料集讀取為 DataFrame 格式，並將原始順序打亂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#讀CSV檔\n",
    "df = pd.read_csv(\"gender_recog.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 檢查資料缺失與資料類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#列印欄位資訊\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 數值標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.049248</td>\n",
       "      <td>0.427355</td>\n",
       "      <td>-4.224901</td>\n",
       "      <td>-2.576102</td>\n",
       "      <td>-5.693607</td>\n",
       "      <td>-0.214778</td>\n",
       "      <td>2.293306</td>\n",
       "      <td>1.762946</td>\n",
       "      <td>-0.039083</td>\n",
       "      <td>0.471575</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.049248</td>\n",
       "      <td>-1.812038</td>\n",
       "      <td>-1.097998</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>-1.564205</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.431422</td>\n",
       "      <td>-1.419137</td>\n",
       "      <td>-1.454772</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.841053</td>\n",
       "      <td>0.611669</td>\n",
       "      <td>-3.999293</td>\n",
       "      <td>-2.486885</td>\n",
       "      <td>-5.588987</td>\n",
       "      <td>-0.258485</td>\n",
       "      <td>4.548056</td>\n",
       "      <td>4.433008</td>\n",
       "      <td>-0.065236</td>\n",
       "      <td>0.594431</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.841053</td>\n",
       "      <td>-1.079594</td>\n",
       "      <td>-1.091533</td>\n",
       "      <td>-0.294030</td>\n",
       "      <td>-1.561916</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.418107</td>\n",
       "      <td>-1.405818</td>\n",
       "      <td>-1.014103</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.463066</td>\n",
       "      <td>1.603848</td>\n",
       "      <td>-4.095851</td>\n",
       "      <td>-2.706986</td>\n",
       "      <td>-3.928699</td>\n",
       "      <td>0.909326</td>\n",
       "      <td>6.513656</td>\n",
       "      <td>7.326207</td>\n",
       "      <td>-1.083730</td>\n",
       "      <td>0.398261</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.463066</td>\n",
       "      <td>-1.365368</td>\n",
       "      <td>-1.100397</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>-1.563866</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.429203</td>\n",
       "      <td>-1.416917</td>\n",
       "      <td>-1.065344</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.992157</td>\n",
       "      <td>0.899998</td>\n",
       "      <td>-0.759454</td>\n",
       "      <td>-0.901418</td>\n",
       "      <td>-0.711205</td>\n",
       "      <td>0.632690</td>\n",
       "      <td>-0.449858</td>\n",
       "      <td>-0.240099</td>\n",
       "      <td>1.516383</td>\n",
       "      <td>1.797340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.992157</td>\n",
       "      <td>-1.666966</td>\n",
       "      <td>-0.988934</td>\n",
       "      <td>-0.294030</td>\n",
       "      <td>-1.195367</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.273867</td>\n",
       "      <td>-1.261532</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.530640</td>\n",
       "      <td>1.322561</td>\n",
       "      <td>-1.676948</td>\n",
       "      <td>-1.268395</td>\n",
       "      <td>-0.792029</td>\n",
       "      <td>1.005588</td>\n",
       "      <td>-0.480911</td>\n",
       "      <td>-0.238940</td>\n",
       "      <td>1.708336</td>\n",
       "      <td>2.114740</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.530640</td>\n",
       "      <td>-1.127233</td>\n",
       "      <td>-1.034015</td>\n",
       "      <td>0.260185</td>\n",
       "      <td>-0.221660</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>0.124154</td>\n",
       "      <td>0.136933</td>\n",
       "      <td>0.289046</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>-1.638842</td>\n",
       "      <td>1.658182</td>\n",
       "      <td>-0.877839</td>\n",
       "      <td>-1.873163</td>\n",
       "      <td>-0.999378</td>\n",
       "      <td>1.579141</td>\n",
       "      <td>-0.325020</td>\n",
       "      <td>-0.221916</td>\n",
       "      <td>1.507749</td>\n",
       "      <td>1.999883</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.638842</td>\n",
       "      <td>1.237885</td>\n",
       "      <td>2.444087</td>\n",
       "      <td>0.114817</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.237556</td>\n",
       "      <td>-0.224892</td>\n",
       "      <td>-0.098989</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>-2.162452</td>\n",
       "      <td>1.927682</td>\n",
       "      <td>-2.994482</td>\n",
       "      <td>-2.008095</td>\n",
       "      <td>-0.840021</td>\n",
       "      <td>1.820721</td>\n",
       "      <td>-0.577009</td>\n",
       "      <td>-0.252503</td>\n",
       "      <td>1.458418</td>\n",
       "      <td>1.697831</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.162452</td>\n",
       "      <td>1.429532</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>0.153573</td>\n",
       "      <td>-0.214641</td>\n",
       "      <td>-0.388453</td>\n",
       "      <td>-0.384717</td>\n",
       "      <td>0.871981</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>-1.298773</td>\n",
       "      <td>2.322724</td>\n",
       "      <td>-0.051973</td>\n",
       "      <td>-2.199039</td>\n",
       "      <td>-0.017123</td>\n",
       "      <td>2.492666</td>\n",
       "      <td>-0.298044</td>\n",
       "      <td>-0.222108</td>\n",
       "      <td>1.150198</td>\n",
       "      <td>1.385857</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.298773</td>\n",
       "      <td>2.077781</td>\n",
       "      <td>0.140728</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>-0.637833</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.599266</td>\n",
       "      <td>-0.586717</td>\n",
       "      <td>0.175887</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>-1.245202</td>\n",
       "      <td>2.012196</td>\n",
       "      <td>-0.017728</td>\n",
       "      <td>-1.991852</td>\n",
       "      <td>-0.204021</td>\n",
       "      <td>2.153653</td>\n",
       "      <td>-0.365367</td>\n",
       "      <td>-0.231123</td>\n",
       "      <td>1.229850</td>\n",
       "      <td>1.505711</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.245202</td>\n",
       "      <td>0.915445</td>\n",
       "      <td>-0.120678</td>\n",
       "      <td>-0.294030</td>\n",
       "      <td>-0.072080</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.412863</td>\n",
       "      <td>-0.400255</td>\n",
       "      <td>1.149161</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>-0.514746</td>\n",
       "      <td>2.147651</td>\n",
       "      <td>-0.070879</td>\n",
       "      <td>-1.446089</td>\n",
       "      <td>1.102679</td>\n",
       "      <td>2.254671</td>\n",
       "      <td>-0.338487</td>\n",
       "      <td>-0.228300</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>1.089126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514746</td>\n",
       "      <td>1.325111</td>\n",
       "      <td>1.324614</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>-1.146760</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.276086</td>\n",
       "      <td>-1.263752</td>\n",
       "      <td>1.475679</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0    -4.049248  0.427355 -4.224901 -2.576102 -5.693607 -0.214778  2.293306   \n",
       "1    -3.841053  0.611669 -3.999293 -2.486885 -5.588987 -0.258485  4.548056   \n",
       "2    -3.463066  1.603848 -4.095851 -2.706986 -3.928699  0.909326  6.513656   \n",
       "3    -0.992157  0.899998 -0.759454 -0.901418 -0.711205  0.632690 -0.449858   \n",
       "4    -1.530640  1.322561 -1.676948 -1.268395 -0.792029  1.005588 -0.480911   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3163 -1.638842  1.658182 -0.877839 -1.873163 -0.999378  1.579141 -0.325020   \n",
       "3164 -2.162452  1.927682 -2.994482 -2.008095 -0.840021  1.820721 -0.577009   \n",
       "3165 -1.298773  2.322724 -0.051973 -2.199039 -0.017123  2.492666 -0.298044   \n",
       "3166 -1.245202  2.012196 -0.017728 -1.991852 -0.204021  2.153653 -0.365367   \n",
       "3167 -0.514746  2.147651 -0.070879 -1.446089  1.102679  2.254671 -0.338487   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0     1.762946 -0.039083  0.471575  ... -4.049248 -1.812038 -1.097998   \n",
       "1     4.433008 -0.065236  0.594431  ... -3.841053 -1.079594 -1.091533   \n",
       "2     7.326207 -1.083730  0.398261  ... -3.463066 -1.365368 -1.100397   \n",
       "3    -0.240099  1.516383  1.797340  ... -0.992157 -1.666966 -0.988934   \n",
       "4    -0.238940  1.708336  2.114740  ... -1.530640 -1.127233 -1.034015   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3163 -0.221916  1.507749  1.999883  ... -1.638842  1.237885  2.444087   \n",
       "3164 -0.252503  1.458418  1.697831  ... -2.162452  1.429532 -0.124536   \n",
       "3165 -0.222108  1.150198  1.385857  ... -1.298773  2.077781  0.140728   \n",
       "3166 -0.231123  1.229850  1.505711  ... -1.245202  0.915445 -0.120678   \n",
       "3167 -0.228300  0.971759  1.089126  ... -0.514746  1.325111  1.324614   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.565959 -1.564205 -0.708404 -1.431422 -1.419137 -1.454772    male  \n",
       "1    -0.294030 -1.561916 -0.708404 -1.418107 -1.405818 -1.014103    male  \n",
       "2     0.410480 -1.563866 -0.708404 -1.429203 -1.416917 -1.065344    male  \n",
       "3    -0.294030 -1.195367 -0.708404 -1.273867 -1.261532  0.614286    male  \n",
       "4     0.260185 -0.221660 -0.708404  0.124154  0.136933  0.289046    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.114817  0.007024 -0.708404 -0.237556 -0.224892 -0.098989  female  \n",
       "3164  0.565959  0.153573 -0.214641 -0.388453 -0.384717  0.871981  female  \n",
       "3165  0.565959 -0.637833 -0.708404 -0.599266 -0.586717  0.175887  female  \n",
       "3166 -0.294030 -0.072080 -0.708404 -0.412863 -0.400255  1.149161  female  \n",
       "3167  0.410480 -1.146760 -0.708404 -1.276086 -1.263752  1.475679  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#資料標準化\n",
    "scaler = StandardScaler().fit(df.drop('label',axis=1))\n",
    "#label不做標準化\n",
    "X_scaled = scaler.transform(df.drop('label',axis=1))\n",
    "#重新轉回 DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled,columns=df.columns[:20])\n",
    "#串接回 label 欄位\n",
    "X_scaled = pd.concat([X_scaled,pd.DataFrame(df['label'])],axis=1)\n",
    "#顯示目前的 DataFrame\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 將 DataFrame 內的資料打散\n",
    "\n",
    "(從 index 可以觀察到順序全部被打亂，每次 shuffle 都會不一樣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>0.966214</td>\n",
       "      <td>-1.417017</td>\n",
       "      <td>0.764072</td>\n",
       "      <td>1.086742</td>\n",
       "      <td>0.338559</td>\n",
       "      <td>-1.049457</td>\n",
       "      <td>-0.233476</td>\n",
       "      <td>-0.211553</td>\n",
       "      <td>-0.721947</td>\n",
       "      <td>-1.166627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>0.876117</td>\n",
       "      <td>0.553107</td>\n",
       "      <td>0.672624</td>\n",
       "      <td>1.815255</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>0.962967</td>\n",
       "      <td>0.971572</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>-3.078091</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>-3.175789</td>\n",
       "      <td>-2.321165</td>\n",
       "      <td>-3.442414</td>\n",
       "      <td>0.739019</td>\n",
       "      <td>-0.297573</td>\n",
       "      <td>-0.216162</td>\n",
       "      <td>1.205707</td>\n",
       "      <td>1.222385</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.078091</td>\n",
       "      <td>0.381985</td>\n",
       "      <td>-1.020767</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>-1.169086</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.251676</td>\n",
       "      <td>-1.239334</td>\n",
       "      <td>1.847926</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.181057</td>\n",
       "      <td>0.171830</td>\n",
       "      <td>0.189908</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.099234</td>\n",
       "      <td>-0.418778</td>\n",
       "      <td>-0.237793</td>\n",
       "      <td>0.516373</td>\n",
       "      <td>-0.016238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>-0.957207</td>\n",
       "      <td>0.543390</td>\n",
       "      <td>0.359819</td>\n",
       "      <td>-0.313503</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>0.383787</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>-1.172998</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>1.006591</td>\n",
       "      <td>-0.313027</td>\n",
       "      <td>1.092478</td>\n",
       "      <td>1.388438</td>\n",
       "      <td>0.373613</td>\n",
       "      <td>-1.373367</td>\n",
       "      <td>0.124816</td>\n",
       "      <td>-0.128313</td>\n",
       "      <td>-1.086572</td>\n",
       "      <td>-0.535458</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006591</td>\n",
       "      <td>1.282164</td>\n",
       "      <td>0.623340</td>\n",
       "      <td>0.618983</td>\n",
       "      <td>0.260993</td>\n",
       "      <td>-0.091201</td>\n",
       "      <td>0.330529</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>-0.962614</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-0.721599</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>-0.111802</td>\n",
       "      <td>-0.859016</td>\n",
       "      <td>-1.119722</td>\n",
       "      <td>0.358722</td>\n",
       "      <td>-0.067537</td>\n",
       "      <td>-0.180964</td>\n",
       "      <td>-0.617989</td>\n",
       "      <td>-0.522094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721599</td>\n",
       "      <td>-1.316913</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>0.380015</td>\n",
       "      <td>-0.664736</td>\n",
       "      <td>0.711164</td>\n",
       "      <td>-1.195089</td>\n",
       "      <td>-1.208257</td>\n",
       "      <td>3.059694</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>1.681175</td>\n",
       "      <td>-1.553561</td>\n",
       "      <td>1.358989</td>\n",
       "      <td>1.605196</td>\n",
       "      <td>1.170706</td>\n",
       "      <td>-1.179576</td>\n",
       "      <td>-0.225096</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.577700</td>\n",
       "      <td>-1.430891</td>\n",
       "      <td>...</td>\n",
       "      <td>1.681175</td>\n",
       "      <td>1.519534</td>\n",
       "      <td>0.590242</td>\n",
       "      <td>0.513540</td>\n",
       "      <td>0.132168</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>-0.122164</td>\n",
       "      <td>-0.113903</td>\n",
       "      <td>-0.584785</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.166137</td>\n",
       "      <td>0.208401</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>-0.041784</td>\n",
       "      <td>0.448365</td>\n",
       "      <td>0.295281</td>\n",
       "      <td>-0.551583</td>\n",
       "      <td>-0.248092</td>\n",
       "      <td>0.975918</td>\n",
       "      <td>0.561639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166137</td>\n",
       "      <td>-0.231563</td>\n",
       "      <td>0.565363</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>0.186250</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>0.323872</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>-0.118745</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>-0.661678</td>\n",
       "      <td>-0.195472</td>\n",
       "      <td>-0.402724</td>\n",
       "      <td>0.440485</td>\n",
       "      <td>-1.806659</td>\n",
       "      <td>-1.499444</td>\n",
       "      <td>0.580344</td>\n",
       "      <td>0.041956</td>\n",
       "      <td>-0.725242</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661678</td>\n",
       "      <td>0.510203</td>\n",
       "      <td>-1.296316</td>\n",
       "      <td>-1.532170</td>\n",
       "      <td>-1.241120</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>-1.374003</td>\n",
       "      <td>-1.374741</td>\n",
       "      <td>-0.083740</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>-1.671142</td>\n",
       "      <td>1.891689</td>\n",
       "      <td>-1.533888</td>\n",
       "      <td>-2.003982</td>\n",
       "      <td>-0.453913</td>\n",
       "      <td>2.029381</td>\n",
       "      <td>-0.141617</td>\n",
       "      <td>-0.122001</td>\n",
       "      <td>1.532965</td>\n",
       "      <td>1.858987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.671142</td>\n",
       "      <td>-0.613973</td>\n",
       "      <td>-0.992014</td>\n",
       "      <td>-0.162074</td>\n",
       "      <td>-1.095789</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.190955</td>\n",
       "      <td>-0.178277</td>\n",
       "      <td>-0.796675</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>1.820073</td>\n",
       "      <td>-1.609991</td>\n",
       "      <td>1.444396</td>\n",
       "      <td>1.807108</td>\n",
       "      <td>1.103260</td>\n",
       "      <td>-1.446583</td>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.194010</td>\n",
       "      <td>-2.249469</td>\n",
       "      <td>-1.555109</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820073</td>\n",
       "      <td>1.996788</td>\n",
       "      <td>0.540973</td>\n",
       "      <td>0.618983</td>\n",
       "      <td>1.727932</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>1.934925</td>\n",
       "      <td>1.943839</td>\n",
       "      <td>-0.667055</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "2518  0.966214 -1.417017  0.764072  1.086742  0.338559 -1.049457 -0.233476   \n",
       "1920 -3.078091  0.762835 -3.175789 -2.321165 -3.442414  0.739019 -0.297573   \n",
       "831   0.255286  0.181057  0.171830  0.189908  0.570668  0.099234 -0.418778   \n",
       "2494  1.006591 -0.313027  1.092478  1.388438  0.373613 -1.373367  0.124816   \n",
       "679  -0.721599  0.353422 -0.111802 -0.859016 -1.119722  0.358722 -0.067537   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2616  1.681175 -1.553561  1.358989  1.605196  1.170706 -1.179576 -0.225096   \n",
       "822   0.166137  0.208401  0.214810 -0.041784  0.448365  0.295281 -0.551583   \n",
       "3076 -0.661678 -0.195472 -0.402724  0.440485 -1.806659 -1.499444  0.580344   \n",
       "508  -1.671142  1.891689 -1.533888 -2.003982 -0.453913  2.029381 -0.141617   \n",
       "2846  1.820073 -1.609991  1.444396  1.807108  1.103260 -1.446583 -0.099073   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "2518 -0.211553 -0.721947 -1.166627  ...  0.966214  0.876117  0.553107   \n",
       "1920 -0.216162  1.205707  1.222385  ... -3.078091  0.381985 -1.020767   \n",
       "831  -0.237793  0.516373 -0.016238  ...  0.255286 -0.957207  0.543390   \n",
       "2494 -0.128313 -1.086572 -0.535458  ...  1.006591  1.282164  0.623340   \n",
       "679  -0.180964 -0.617989 -0.522094  ... -0.721599 -1.316913  0.158133   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2616 -0.215919 -1.577700 -1.430891  ...  1.681175  1.519534  0.590242   \n",
       "822  -0.248092  0.975918  0.561639  ...  0.166137 -0.231563  0.565363   \n",
       "3076  0.041956 -0.725242  0.026884  ... -0.661678  0.510203 -1.296316   \n",
       "508  -0.122001  1.532965  1.858987  ... -1.671142 -0.613973 -0.992014   \n",
       "2846 -0.194010 -2.249469 -1.555109  ...  1.820073  1.996788  0.540973   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "2518  0.672624  1.815255 -0.461523  0.962967  0.971572 -0.457633  female  \n",
       "1920  0.410480 -1.169086 -0.708404 -1.251676 -1.239334  1.847926  female  \n",
       "831   0.359819 -0.313503 -0.461523  0.383787  0.392208 -1.172998    male  \n",
       "2494  0.618983  0.260993 -0.091201  0.330529  0.332274 -0.962614  female  \n",
       "679   0.380015 -0.664736  0.711164 -1.195089 -1.208257  3.059694    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "2616  0.513540  0.132168 -0.461523 -0.122164 -0.113903 -0.584785  female  \n",
       "822   0.565959  0.186250 -0.461523  0.323872  0.332274 -0.118745    male  \n",
       "3076 -1.532170 -1.241120  0.016810 -1.374003 -1.374741 -0.083740  female  \n",
       "508  -0.162074 -1.095789 -0.708404 -0.190955 -0.178277 -0.796675    male  \n",
       "2846  0.618983  1.727932 -0.461523  1.934925  1.943839 -0.667055  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#打散資料\n",
    "df_shuffle = shuffle(X_scaled)\n",
    "#顯示打散的資料\n",
    "df_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 使用 scikit learn 建立 RandomForest 分類器 ，並以 10 cross validation 評估模型在此資料集的分類表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(不特別調整模型參數的版本)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 平均的 F1-score: 0.9801409971645041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#data\n",
    "X = df_shuffle.drop(['label'], axis=1)\n",
    "#target\n",
    "y = df_shuffle['label']\n",
    "\n",
    "#定義交叉驗證方法\n",
    "cv = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "#定義 f1 score 要以哪一種類別做為判斷依據\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"female\")\n",
    "\n",
    "# 建立 RandomForest 分類器\n",
    "clf1 = RandomForestClassifier(random_state=0)\n",
    "\n",
    "#使用 k-fold 交叉驗證評估\n",
    "scores1 = cross_val_score(clf1, X, y, scoring=f1_scorer,cv=cv)\n",
    "\n",
    "#印出平均的 f1 score\n",
    "print(\"Random Forest 平均的 F1-score: \"+str(scores1.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用 scikit-learn 建立MLP 分類器，並以 10 cross validation 評估模型在此資料集 的分類表現 (評估指標：F1-score，請印出平均 F1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(不特別調整模型參數的版本)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn MLP 平均的 F1-score: 0.981101030223203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#data\n",
    "X = df_shuffle.drop(['label'], axis=1)\n",
    "#target\n",
    "y = df_shuffle['label']\n",
    "\n",
    "#定義交叉驗證方法\n",
    "cv = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "#定義 f1 score 要以哪一種類別做為判斷依據\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"female\")\n",
    "\n",
    "# 建立 MLP 分類器\n",
    "clf2 = MLPClassifier(random_state=0, max_iter=500,hidden_layer_sizes=(100,))\n",
    "\n",
    "#使用 k-fold 交叉驗證評估\n",
    "scores2 = cross_val_score(clf2, X, y, scoring=f1_scorer,cv=cv)\n",
    "\n",
    "#印出平均的 f1 score\n",
    "print(\"scikit-learn MLP 平均的 F1-score: \"+str(scores2.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 使用 Keras 建立MLP 分類器，並以 10 cross validation 評估模型在此資料集的分 類表現 (評估指標：F1-score，請印出平均 F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5276 - f1_m: 0.5654\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3941 - f1_m: 0.8912\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3176 - f1_m: 0.9379\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2641 - f1_m: 0.9539\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2258 - f1_m: 0.9638\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1986 - f1_m: 0.9671\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1772 - f1_m: 0.9666\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1609 - f1_m: 0.9670\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1471 - f1_m: 0.9707\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1359 - f1_m: 0.9684\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.1266 - f1_m: 0.9720\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.1189 - f1_m: 0.9662\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1124 - f1_m: 0.9715\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1067 - f1_m: 0.9726\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1020 - f1_m: 0.9713\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0975 - f1_m: 0.9753\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0936 - f1_m: 0.9701\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0908 - f1_m: 0.9747\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0883 - f1_m: 0.9742\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0858 - f1_m: 0.9775\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0800 - f1_m: 0.9731\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0739 - f1_m: 0.9709\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0710 - f1_m: 0.9744\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0688 - f1_m: 0.9728\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0669 - f1_m: 0.9754\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0657 - f1_m: 0.9677\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0638 - f1_m: 0.9770\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0628 - f1_m: 0.9752\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0616 - f1_m: 0.9719\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0608 - f1_m: 0.9709\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0592 - f1_m: 0.9763\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0595 - f1_m: 0.9785\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0583 - f1_m: 0.9806\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0579 - f1_m: 0.9787\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0567 - f1_m: 0.9809\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0564 - f1_m: 0.9818: 0s - loss: 0.0597 - f1\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0566 - f1_m: 0.9837\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0562 - f1_m: 0.9778: 0s - loss: 0.0598 - f1_m: 0.98\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0556 - f1_m: 0.9826: 0s - loss: 0.0539 - \n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0549 - f1_m: 0.9814\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0545 - f1_m: 0.9787\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0548 - f1_m: 0.9782\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0541 - f1_m: 0.9795\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0537 - f1_m: 0.9693\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0533 - f1_m: 0.9790\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0534 - f1_m: 0.9833\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0531 - f1_m: 0.9791\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0529 - f1_m: 0.9814\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0525 - f1_m: 0.9786\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0521 - f1_m: 0.9825\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0524 - f1_m: 0.9835\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0520 - f1_m: 0.9796\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0519 - f1_m: 0.9803\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0522 - f1_m: 0.9796\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0513 - f1_m: 0.9783\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0511 - f1_m: 0.9838\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0514 - f1_m: 0.9777\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0505 - f1_m: 0.9782\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0509 - f1_m: 0.9823\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0500 - f1_m: 0.9820\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0502 - f1_m: 0.9796\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0500 - f1_m: 0.9792\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0498 - f1_m: 0.9841\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0493 - f1_m: 0.9810\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0492 - f1_m: 0.9788\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0493 - f1_m: 0.9773\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0484 - f1_m: 0.9850\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0487 - f1_m: 0.9841\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0480 - f1_m: 0.9773\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0479 - f1_m: 0.9862\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0486 - f1_m: 0.9848: \n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0478 - f1_m: 0.9808\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0475 - f1_m: 0.9815\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0473 - f1_m: 0.9867\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0470 - f1_m: 0.9769\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0469 - f1_m: 0.9861\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0476 - f1_m: 0.9815\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0472 - f1_m: 0.9861\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0467 - f1_m: 0.9828\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0466 - f1_m: 0.9858\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0459 - f1_m: 0.9826\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0466 - f1_m: 0.9808\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0454 - f1_m: 0.9850\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0467 - f1_m: 0.9830\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9855\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0463 - f1_m: 0.9813\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0459 - f1_m: 0.9844\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0460 - f1_m: 0.9845\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9796\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9857\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0458 - f1_m: 0.9848\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9852\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0450 - f1_m: 0.9858\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9820\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0453 - f1_m: 0.9856\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0457 - f1_m: 0.9855\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0446 - f1_m: 0.9814\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0445 - f1_m: 0.9803\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0445 - f1_m: 0.9802\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9813\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 3s 4ms/step - loss: 0.5927 - f1_m: 0.6585\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3571 - f1_m: 0.8386\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2175 - f1_m: 0.8682\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1600 - f1_m: 0.9261\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1280 - f1_m: 0.9560\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1020 - f1_m: 0.9641\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0910 - f1_m: 0.9633\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0862 - f1_m: 0.9652\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0849 - f1_m: 0.9647\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0826 - f1_m: 0.9648\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0810 - f1_m: 0.9651\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0797 - f1_m: 0.9666\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0781 - f1_m: 0.9646\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0771 - f1_m: 0.9687\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0768 - f1_m: 0.9679: 0s - loss: 0.0786 - f1_m: \n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0752 - f1_m: 0.9734\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0744 - f1_m: 0.9681\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0740 - f1_m: 0.9694\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0720 - f1_m: 0.9734\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0725 - f1_m: 0.9716\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0712 - f1_m: 0.9738\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0708 - f1_m: 0.9726\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0705 - f1_m: 0.9731\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0699 - f1_m: 0.9701\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0691 - f1_m: 0.9691\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0684 - f1_m: 0.9748\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0677 - f1_m: 0.9758\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0662 - f1_m: 0.9669\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0664 - f1_m: 0.9728: 0s - loss:\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0654 - f1_m: 0.9759\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0648 - f1_m: 0.9694\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0638 - f1_m: 0.9725\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0635 - f1_m: 0.9756\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0634 - f1_m: 0.9751\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0636 - f1_m: 0.9736\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0625 - f1_m: 0.9767\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9759\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0620 - f1_m: 0.9771\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0613 - f1_m: 0.9740\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0615 - f1_m: 0.9802\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0607 - f1_m: 0.9768\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0608 - f1_m: 0.9696\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9703\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0607 - f1_m: 0.9731\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0603 - f1_m: 0.9725\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9741\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9772\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0597 - f1_m: 0.9751\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0597 - f1_m: 0.9719\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0596 - f1_m: 0.9774\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0596 - f1_m: 0.9656\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0595 - f1_m: 0.9761\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0592 - f1_m: 0.9741\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0587 - f1_m: 0.9698\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0589 - f1_m: 0.9738\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0588 - f1_m: 0.9759\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0585 - f1_m: 0.9704\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0589 - f1_m: 0.9787\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0588 - f1_m: 0.9777\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0581 - f1_m: 0.9794\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0586 - f1_m: 0.9722\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0582 - f1_m: 0.9725\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0579 - f1_m: 0.9774\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0581 - f1_m: 0.9788\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0580 - f1_m: 0.9786\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0580 - f1_m: 0.9716\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0576 - f1_m: 0.9744\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0574 - f1_m: 0.9795\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0577 - f1_m: 0.9728\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0569 - f1_m: 0.9751\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0573 - f1_m: 0.9784\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0570 - f1_m: 0.9741\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0571 - f1_m: 0.9703\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0570 - f1_m: 0.9774\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9743\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9693\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0570 - f1_m: 0.9719\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0564 - f1_m: 0.9752\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0563 - f1_m: 0.9781\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9796\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0564 - f1_m: 0.9800\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0560 - f1_m: 0.9763\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0566 - f1_m: 0.9746\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9793\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0570 - f1_m: 0.9720\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9693\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0557 - f1_m: 0.9787\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0557 - f1_m: 0.9742\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0551 - f1_m: 0.9731\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0563 - f1_m: 0.9771\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0555 - f1_m: 0.9768\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0560 - f1_m: 0.9777\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0554 - f1_m: 0.9743\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9779\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0549 - f1_m: 0.9761\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0553 - f1_m: 0.9739\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0556 - f1_m: 0.9750\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0557 - f1_m: 0.9696\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0553 - f1_m: 0.9738\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0550 - f1_m: 0.9752\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 2ms/step - loss: 0.7041 - f1_m: 0.4899\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.5892 - f1_m: 0.6764\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3849 - f1_m: 0.8231\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2755 - f1_m: 0.8834\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2052 - f1_m: 0.8986\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1697 - f1_m: 0.8987\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1532 - f1_m: 0.9069\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1430 - f1_m: 0.9155\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1345 - f1_m: 0.9428\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1223 - f1_m: 0.9524\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0971 - f1_m: 0.9668\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0865 - f1_m: 0.9685\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0821 - f1_m: 0.9665\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0792 - f1_m: 0.9704\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0770 - f1_m: 0.9686\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0757 - f1_m: 0.9756\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0742 - f1_m: 0.9712\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0731 - f1_m: 0.9706\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0712 - f1_m: 0.9723\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0708 - f1_m: 0.9763\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0700 - f1_m: 0.9765\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0692 - f1_m: 0.9703\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0684 - f1_m: 0.9737\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0680 - f1_m: 0.9737\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0676 - f1_m: 0.9715\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0667 - f1_m: 0.9686\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0664 - f1_m: 0.9754\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0654 - f1_m: 0.9774\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0656 - f1_m: 0.9717\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0650 - f1_m: 0.9755\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0643 - f1_m: 0.9725\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0638 - f1_m: 0.9716\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0640 - f1_m: 0.9737\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0637 - f1_m: 0.9753\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0628 - f1_m: 0.9690\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0619 - f1_m: 0.9688\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0622 - f1_m: 0.9739\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9678\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0615 - f1_m: 0.9686\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0606 - f1_m: 0.9679\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0603 - f1_m: 0.9775: 0s - loss: 0.0635 - f1\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0605 - f1_m: 0.9765\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0603 - f1_m: 0.9738\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0593 - f1_m: 0.9737\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0597 - f1_m: 0.9767\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0589 - f1_m: 0.9686\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0590 - f1_m: 0.9788\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0583 - f1_m: 0.9776\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0581 - f1_m: 0.9790\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0576 - f1_m: 0.9765\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0577 - f1_m: 0.9804\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0574 - f1_m: 0.9762\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0573 - f1_m: 0.9760\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0564 - f1_m: 0.9747\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0565 - f1_m: 0.9777\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0565 - f1_m: 0.9768\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9748\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0564 - f1_m: 0.9770\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9801\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9791\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0554 - f1_m: 0.9772\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0555 - f1_m: 0.9749\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9757\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0549 - f1_m: 0.9776\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0547 - f1_m: 0.9757\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0546 - f1_m: 0.9720\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0547 - f1_m: 0.9774\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0542 - f1_m: 0.9711\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0539 - f1_m: 0.9835\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0537 - f1_m: 0.9766\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0534 - f1_m: 0.9782\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0531 - f1_m: 0.9727\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0533 - f1_m: 0.9793\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0531 - f1_m: 0.9801\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0525 - f1_m: 0.9802\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0523 - f1_m: 0.9808\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0520 - f1_m: 0.9751\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0515 - f1_m: 0.9779\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0513 - f1_m: 0.9777\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0511 - f1_m: 0.9722\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0507 - f1_m: 0.9743\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0503 - f1_m: 0.9787\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0499 - f1_m: 0.9815\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0498 - f1_m: 0.9790\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0496 - f1_m: 0.9767\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0497 - f1_m: 0.9743\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0494 - f1_m: 0.9779\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0491 - f1_m: 0.9805\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0491 - f1_m: 0.9793\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0482 - f1_m: 0.9840\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0487 - f1_m: 0.9848\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0478 - f1_m: 0.9842\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0484 - f1_m: 0.9804\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0487 - f1_m: 0.9779\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0481 - f1_m: 0.9808\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0480 - f1_m: 0.9817\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0476 - f1_m: 0.9848\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0482 - f1_m: 0.9798\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0482 - f1_m: 0.9805\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0474 - f1_m: 0.9822\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 3ms/step - loss: 0.5505 - f1_m: 0.7971\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3235 - f1_m: 0.8493\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2119 - f1_m: 0.8962\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1494 - f1_m: 0.9453\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1097 - f1_m: 0.9643\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0927 - f1_m: 0.9691\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0852 - f1_m: 0.9666\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0806 - f1_m: 0.9678\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0775 - f1_m: 0.9717\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0753 - f1_m: 0.9766\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0742 - f1_m: 0.9693\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0723 - f1_m: 0.9773\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0715 - f1_m: 0.9762\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0709 - f1_m: 0.9715\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0692 - f1_m: 0.9721\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0691 - f1_m: 0.9743\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0679 - f1_m: 0.9729\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0676 - f1_m: 0.9761\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0667 - f1_m: 0.9782\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0677 - f1_m: 0.9734\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0662 - f1_m: 0.9722\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0663 - f1_m: 0.9724: 0s - loss: 0.0578 - f1_m: \n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0666 - f1_m: 0.9763\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0652 - f1_m: 0.9752\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0647 - f1_m: 0.9792\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0652 - f1_m: 0.9797\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0633 - f1_m: 0.9700\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0644 - f1_m: 0.9761\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0637 - f1_m: 0.9756\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0636 - f1_m: 0.9725\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0632 - f1_m: 0.9812\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0631 - f1_m: 0.9790\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0635 - f1_m: 0.9755\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0628 - f1_m: 0.9763\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0630 - f1_m: 0.9806\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0625 - f1_m: 0.9777\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0626 - f1_m: 0.9743\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9728\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0621 - f1_m: 0.9780\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0617 - f1_m: 0.9786\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0616 - f1_m: 0.9743\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0615 - f1_m: 0.9794\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0613 - f1_m: 0.9700\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0616 - f1_m: 0.9799\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0610 - f1_m: 0.9805\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0611 - f1_m: 0.9749\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0605 - f1_m: 0.9739\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0610 - f1_m: 0.9785\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9753\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0597 - f1_m: 0.9791\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0602 - f1_m: 0.9719\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0592 - f1_m: 0.9719\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0596 - f1_m: 0.9727\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0592 - f1_m: 0.9786\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0596 - f1_m: 0.9764\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0591 - f1_m: 0.9787\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9811\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9762\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0579 - f1_m: 0.9777\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0582 - f1_m: 0.9745\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0586 - f1_m: 0.9791\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0577 - f1_m: 0.9731\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - f1_m: 0.9757\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0575 - f1_m: 0.9794\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0569 - f1_m: 0.9811\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0571 - f1_m: 0.9784\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0568 - f1_m: 0.9789\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0566 - f1_m: 0.9727\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0564 - f1_m: 0.9814\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0563 - f1_m: 0.9757\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0564 - f1_m: 0.9788\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - f1_m: 0.9795\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0557 - f1_m: 0.9769\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0558 - f1_m: 0.9736\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0553 - f1_m: 0.9775\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - f1_m: 0.9782\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0550 - f1_m: 0.9723\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0547 - f1_m: 0.9736\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0547 - f1_m: 0.9784\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0550 - f1_m: 0.9760\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0539 - f1_m: 0.9785\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0542 - f1_m: 0.9774\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0534 - f1_m: 0.9751\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0542 - f1_m: 0.9759\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0536 - f1_m: 0.9768\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0535 - f1_m: 0.9786\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0538 - f1_m: 0.9756\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0534 - f1_m: 0.9735\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0529 - f1_m: 0.9796\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9823\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0528 - f1_m: 0.9823\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9824\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0523 - f1_m: 0.9767\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0524 - f1_m: 0.9798\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0520 - f1_m: 0.9786\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0518 - f1_m: 0.9737\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0519 - f1_m: 0.9790\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0513 - f1_m: 0.9794\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0516 - f1_m: 0.9788\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0512 - f1_m: 0.9773\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 1ms/step - loss: 0.6424 - f1_m: 0.7147\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4111 - f1_m: 0.8772\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2263 - f1_m: 0.9462\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1410 - f1_m: 0.9639\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1040 - f1_m: 0.9715\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0861 - f1_m: 0.9693\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0809 - f1_m: 0.9713\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0773 - f1_m: 0.9685\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0760 - f1_m: 0.9757\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0748 - f1_m: 0.9722\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0739 - f1_m: 0.9672\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0731 - f1_m: 0.9712\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0722 - f1_m: 0.9721\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0722 - f1_m: 0.9771\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0706 - f1_m: 0.9724\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0704 - f1_m: 0.9747\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0693 - f1_m: 0.9758\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0691 - f1_m: 0.9763\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0685 - f1_m: 0.9741\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0678 - f1_m: 0.9710\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0674 - f1_m: 0.9740\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0664 - f1_m: 0.9735\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0663 - f1_m: 0.9747\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0652 - f1_m: 0.9768\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0648 - f1_m: 0.9803\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0644 - f1_m: 0.9761\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0641 - f1_m: 0.9750\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0638 - f1_m: 0.9778\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0633 - f1_m: 0.9772\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0630 - f1_m: 0.9707\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0631 - f1_m: 0.9749\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0621 - f1_m: 0.9760\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0621 - f1_m: 0.9718\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0616 - f1_m: 0.9756\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0610 - f1_m: 0.9753\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0611 - f1_m: 0.9751\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9717\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0601 - f1_m: 0.9789\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0610 - f1_m: 0.9766\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0592 - f1_m: 0.9803\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0594 - f1_m: 0.9786\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0591 - f1_m: 0.9736\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0588 - f1_m: 0.9815\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0587 - f1_m: 0.9739\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0582 - f1_m: 0.9740\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0579 - f1_m: 0.9763\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0575 - f1_m: 0.9727\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0570 - f1_m: 0.9715\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0574 - f1_m: 0.9691\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0572 - f1_m: 0.9776\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - f1_m: 0.9778\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0568 - f1_m: 0.9744\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0564 - f1_m: 0.9800\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9768\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0563 - f1_m: 0.9755\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0557 - f1_m: 0.9750\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0557 - f1_m: 0.9776\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0560 - f1_m: 0.9786\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0565 - f1_m: 0.9724\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0552 - f1_m: 0.9764\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0555 - f1_m: 0.9735\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0548 - f1_m: 0.9760\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0545 - f1_m: 0.9772\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0545 - f1_m: 0.9736\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0544 - f1_m: 0.9770\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9773\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0530 - f1_m: 0.9745\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9735\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0538 - f1_m: 0.9739\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0542 - f1_m: 0.9786\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0539 - f1_m: 0.9780\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9807\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9781\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0531 - f1_m: 0.9751\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0522 - f1_m: 0.9730\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0533 - f1_m: 0.9795\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0525 - f1_m: 0.9735\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0528 - f1_m: 0.9751\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0526 - f1_m: 0.9798\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0520 - f1_m: 0.9816\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0516 - f1_m: 0.9782\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0518 - f1_m: 0.9765\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0527 - f1_m: 0.9787\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0526 - f1_m: 0.9790\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0513 - f1_m: 0.9824\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0519 - f1_m: 0.9735\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0502 - f1_m: 0.9819\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0508 - f1_m: 0.9813\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0514 - f1_m: 0.9775\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0513 - f1_m: 0.9776\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0508 - f1_m: 0.9726\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0505 - f1_m: 0.9810\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0506 - f1_m: 0.9810\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0507 - f1_m: 0.9797\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9734\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0508 - f1_m: 0.9815\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0503 - f1_m: 0.9778\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0495 - f1_m: 0.9769\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0515 - f1_m: 0.9753\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0497 - f1_m: 0.9793\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 4ms/step - loss: 0.5978 - f1_m: 0.7263\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3243 - f1_m: 0.8882\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1546 - f1_m: 0.9434\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1057 - f1_m: 0.9615\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0903 - f1_m: 0.9607\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0837 - f1_m: 0.9701\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0794 - f1_m: 0.9714\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0769 - f1_m: 0.9693\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0749 - f1_m: 0.9725\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0730 - f1_m: 0.9752\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0717 - f1_m: 0.9685\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0710 - f1_m: 0.9718\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0701 - f1_m: 0.9724\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0691 - f1_m: 0.9759\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0686 - f1_m: 0.9702\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0678 - f1_m: 0.9675\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0667 - f1_m: 0.9703\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0659 - f1_m: 0.9702\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0653 - f1_m: 0.9761\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0646 - f1_m: 0.9723\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0642 - f1_m: 0.9719\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0638 - f1_m: 0.9710\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0631 - f1_m: 0.9773\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9750\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0615 - f1_m: 0.9738\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0613 - f1_m: 0.9702\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0613 - f1_m: 0.9742\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0603 - f1_m: 0.9707\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0591 - f1_m: 0.9661\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0590 - f1_m: 0.9775\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0585 - f1_m: 0.9719\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0581 - f1_m: 0.9771\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0581 - f1_m: 0.9719\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0570 - f1_m: 0.9797\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0571 - f1_m: 0.9788\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0565 - f1_m: 0.9807\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0562 - f1_m: 0.9764\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0548 - f1_m: 0.9751\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0554 - f1_m: 0.9795\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0550 - f1_m: 0.9704\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0549 - f1_m: 0.9771\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0542 - f1_m: 0.9813\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0541 - f1_m: 0.9758\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0537 - f1_m: 0.9820\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9813\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0530 - f1_m: 0.9819\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0536 - f1_m: 0.9806\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0529 - f1_m: 0.9761\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0529 - f1_m: 0.9802\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0527 - f1_m: 0.9784\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0524 - f1_m: 0.9762\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0525 - f1_m: 0.9788\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0523 - f1_m: 0.9722\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0520 - f1_m: 0.9761\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0517 - f1_m: 0.9747\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0519 - f1_m: 0.9757\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0515 - f1_m: 0.9785\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0516 - f1_m: 0.9806\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0511 - f1_m: 0.9778\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9768\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0513 - f1_m: 0.9724: 0s - loss: 0.0518 - f1_m: \n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0503 - f1_m: 0.9831\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0507 - f1_m: 0.9822\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0504 - f1_m: 0.9810\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0499 - f1_m: 0.9788\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0509 - f1_m: 0.9809\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0501 - f1_m: 0.9781\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0498 - f1_m: 0.9784\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0502 - f1_m: 0.9763\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0503 - f1_m: 0.9756\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0500 - f1_m: 0.9734\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0496 - f1_m: 0.9777\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9774\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0498 - f1_m: 0.9801\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0495 - f1_m: 0.9830\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0496 - f1_m: 0.9795\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0497 - f1_m: 0.9831\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0491 - f1_m: 0.9801\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0493 - f1_m: 0.9747\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0506 - f1_m: 0.9768\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0487 - f1_m: 0.9764\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0488 - f1_m: 0.9813\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0489 - f1_m: 0.9788\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9749\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9804\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0490 - f1_m: 0.9762\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0482 - f1_m: 0.9810\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0485 - f1_m: 0.9746\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0483 - f1_m: 0.9829\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0485 - f1_m: 0.9762\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0483 - f1_m: 0.9818\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0483 - f1_m: 0.9754\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9793\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0485 - f1_m: 0.9780\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0480 - f1_m: 0.9717\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0482 - f1_m: 0.9788\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0480 - f1_m: 0.9842\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0484 - f1_m: 0.9831\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0477 - f1_m: 0.9786\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0482 - f1_m: 0.9812\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 1ms/step - loss: 0.5617 - f1_m: 0.7096\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2915 - f1_m: 0.8931\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1791 - f1_m: 0.9334\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1207 - f1_m: 0.9607\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0984 - f1_m: 0.9619\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0891 - f1_m: 0.9627\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0845 - f1_m: 0.9690\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0822 - f1_m: 0.9695\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0796 - f1_m: 0.9682\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0770 - f1_m: 0.9659\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0755 - f1_m: 0.9623\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0742 - f1_m: 0.9634\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0719 - f1_m: 0.9681\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0700 - f1_m: 0.9723\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0691 - f1_m: 0.9749\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0681 - f1_m: 0.9719\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0673 - f1_m: 0.9747\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0665 - f1_m: 0.9703\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0654 - f1_m: 0.9763\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0645 - f1_m: 0.9700\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0642 - f1_m: 0.9740\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0639 - f1_m: 0.9774\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0627 - f1_m: 0.9704\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0616 - f1_m: 0.9734\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0611 - f1_m: 0.9612\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9723\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9729\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0598 - f1_m: 0.9779\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0593 - f1_m: 0.9785: 0s - loss: 0.0570 - f1_m\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0584 - f1_m: 0.9771\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0586 - f1_m: 0.9734\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0576 - f1_m: 0.9757\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0572 - f1_m: 0.9697\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0568 - f1_m: 0.9720\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0561 - f1_m: 0.9719\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0561 - f1_m: 0.9756\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0556 - f1_m: 0.9767\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0545 - f1_m: 0.9801\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0544 - f1_m: 0.9758\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0542 - f1_m: 0.9754\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0532 - f1_m: 0.9774\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0535 - f1_m: 0.9639\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0532 - f1_m: 0.9748\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0525 - f1_m: 0.9746\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0518 - f1_m: 0.9724\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0523 - f1_m: 0.9795: 0s - los\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0511 - f1_m: 0.9791\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0517 - f1_m: 0.9769\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0516 - f1_m: 0.9790\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0514 - f1_m: 0.9741\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0503 - f1_m: 0.9750\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0500 - f1_m: 0.9770\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0500 - f1_m: 0.9712\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0501 - f1_m: 0.9736\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0498 - f1_m: 0.9750\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0496 - f1_m: 0.9720\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0497 - f1_m: 0.9758\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0488 - f1_m: 0.9789\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0484 - f1_m: 0.9812\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0487 - f1_m: 0.9806\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0490 - f1_m: 0.9793\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0484 - f1_m: 0.9754\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0477 - f1_m: 0.9782\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0474 - f1_m: 0.9769\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0477 - f1_m: 0.9791\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0484 - f1_m: 0.9762: 0s - loss: 0.0471 - f1_m\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0468 - f1_m: 0.9798\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0473 - f1_m: 0.9743\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0479 - f1_m: 0.9716\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0462 - f1_m: 0.9825\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0468 - f1_m: 0.9763\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0464 - f1_m: 0.9777\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0468 - f1_m: 0.9769: 0s - loss: 0.0438 - f1_m\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0460 - f1_m: 0.9764\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0462 - f1_m: 0.9765\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0463 - f1_m: 0.9789\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0473 - f1_m: 0.9795\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0458 - f1_m: 0.9828\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0457 - f1_m: 0.9804\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0448 - f1_m: 0.9791\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9828\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0446 - f1_m: 0.9830\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0452 - f1_m: 0.9770\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0457 - f1_m: 0.9832\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0451 - f1_m: 0.9808\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0451 - f1_m: 0.9807\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0452 - f1_m: 0.9828\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0446 - f1_m: 0.9772\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0448 - f1_m: 0.9780\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0443 - f1_m: 0.9760\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9805\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0444 - f1_m: 0.9790\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0445 - f1_m: 0.9742\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0435 - f1_m: 0.9829\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0452 - f1_m: 0.9786\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0445 - f1_m: 0.9775\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0445 - f1_m: 0.9796\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0441 - f1_m: 0.9751\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0440 - f1_m: 0.9792\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0442 - f1_m: 0.9779\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 3ms/step - loss: 0.6346 - f1_m: 0.6908\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3466 - f1_m: 0.9269\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1490 - f1_m: 0.9651\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0928 - f1_m: 0.9736\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0815 - f1_m: 0.9720\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0769 - f1_m: 0.9714\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0730 - f1_m: 0.9788\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0716 - f1_m: 0.9739\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0697 - f1_m: 0.9732\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0691 - f1_m: 0.9762\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0679 - f1_m: 0.9750\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0670 - f1_m: 0.9761\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0662 - f1_m: 0.9746\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0654 - f1_m: 0.9774\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0648 - f1_m: 0.9794\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0631 - f1_m: 0.9779\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0633 - f1_m: 0.9757\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0628 - f1_m: 0.9790\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0625 - f1_m: 0.9708\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0618 - f1_m: 0.9796\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0621 - f1_m: 0.9757\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0618 - f1_m: 0.9708\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0615 - f1_m: 0.9798\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0611 - f1_m: 0.9774\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0606 - f1_m: 0.9724: 0s - loss: 0\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0597 - f1_m: 0.9795\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0608 - f1_m: 0.9774\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0599 - f1_m: 0.9782\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0598 - f1_m: 0.9809\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0593 - f1_m: 0.9762\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0592 - f1_m: 0.9811\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0589 - f1_m: 0.9790\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0585 - f1_m: 0.9790\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9799\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0583 - f1_m: 0.9802\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0582 - f1_m: 0.9760\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9740: 0s - loss: 0\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0582 - f1_m: 0.9723\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0576 - f1_m: 0.9759\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - f1_m: 0.9770\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0574 - f1_m: 0.9759\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0569 - f1_m: 0.9753\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - f1_m: 0.9804\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9757\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0567 - f1_m: 0.9731\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0572 - f1_m: 0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0571 - f1_m: 0.9761\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9771\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0557 - f1_m: 0.9767\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0555 - f1_m: 0.9726\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0558 - f1_m: 0.9747\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9729\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0551 - f1_m: 0.9794\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0549 - f1_m: 0.9825\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0542 - f1_m: 0.9791\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9762\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0540 - f1_m: 0.9694\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9708\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0542 - f1_m: 0.9777\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0542 - f1_m: 0.9698\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0536 - f1_m: 0.9714\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0534 - f1_m: 0.9812\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0532 - f1_m: 0.9783\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0535 - f1_m: 0.9799\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0530 - f1_m: 0.9768\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0523 - f1_m: 0.9784\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9759\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9753\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0530 - f1_m: 0.9820\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9770\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0521 - f1_m: 0.9749\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0514 - f1_m: 0.9776\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0516 - f1_m: 0.9839\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0514 - f1_m: 0.9799\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0513 - f1_m: 0.9795\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0530 - f1_m: 0.9779\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0533 - f1_m: 0.9798\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0511 - f1_m: 0.9763\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0509 - f1_m: 0.9782\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0513 - f1_m: 0.9760\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0507 - f1_m: 0.9774\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0505 - f1_m: 0.9773\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0513 - f1_m: 0.9757\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0508 - f1_m: 0.9820\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0510 - f1_m: 0.9762\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0509 - f1_m: 0.9764\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0517 - f1_m: 0.9814\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0501 - f1_m: 0.9846\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0514 - f1_m: 0.9775\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0509 - f1_m: 0.9781\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0500 - f1_m: 0.9787\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0500 - f1_m: 0.9800\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0502 - f1_m: 0.9835\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0504 - f1_m: 0.9798\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0497 - f1_m: 0.9772\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0500 - f1_m: 0.9801\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0499 - f1_m: 0.9812\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0501 - f1_m: 0.9717\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0499 - f1_m: 0.9795\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0492 - f1_m: 0.9815\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 4ms/step - loss: 0.5129 - f1_m: 0.7092\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2560 - f1_m: 0.9065\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1338 - f1_m: 0.9542\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0964 - f1_m: 0.9614\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0819 - f1_m: 0.9700\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0757 - f1_m: 0.9653\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0721 - f1_m: 0.9705\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0691 - f1_m: 0.9679\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0670 - f1_m: 0.9746\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0659 - f1_m: 0.9748\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0650 - f1_m: 0.9714\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0635 - f1_m: 0.9791\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0630 - f1_m: 0.9719\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0621 - f1_m: 0.9770\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0613 - f1_m: 0.9741\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0608 - f1_m: 0.9768\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0605 - f1_m: 0.9738\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0594 - f1_m: 0.9757\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0592 - f1_m: 0.9776\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0587 - f1_m: 0.9784\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0579 - f1_m: 0.9783\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0578 - f1_m: 0.9693\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0568 - f1_m: 0.9752\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0570 - f1_m: 0.9763\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0566 - f1_m: 0.9777\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0560 - f1_m: 0.9734\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0562 - f1_m: 0.9714\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0560 - f1_m: 0.9733\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0560 - f1_m: 0.9766\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0551 - f1_m: 0.9805\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9757\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0548 - f1_m: 0.9777\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0548 - f1_m: 0.9733\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0547 - f1_m: 0.9747\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0548 - f1_m: 0.9721\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0544 - f1_m: 0.9771\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0536 - f1_m: 0.9754\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0537 - f1_m: 0.9784\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0536 - f1_m: 0.9730\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0533 - f1_m: 0.9782\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0537 - f1_m: 0.9783\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0528 - f1_m: 0.9769\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0519 - f1_m: 0.9770\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0534 - f1_m: 0.9751\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0524 - f1_m: 0.9786\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0529 - f1_m: 0.9740\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0515 - f1_m: 0.9758\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0519 - f1_m: 0.9721\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0513 - f1_m: 0.9775\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0520 - f1_m: 0.9777\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0512 - f1_m: 0.9759\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0515 - f1_m: 0.9800\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0515 - f1_m: 0.9736\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0508 - f1_m: 0.9784\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0498 - f1_m: 0.9770\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0498 - f1_m: 0.9756\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0496 - f1_m: 0.9799\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9785\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0499 - f1_m: 0.9749\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0497 - f1_m: 0.9697\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0496 - f1_m: 0.9800\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0495 - f1_m: 0.9728\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0495 - f1_m: 0.9777\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0485 - f1_m: 0.9718\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0487 - f1_m: 0.9799\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9698\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0478 - f1_m: 0.9795\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0476 - f1_m: 0.9782\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0486 - f1_m: 0.9699\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0476 - f1_m: 0.9806\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0479 - f1_m: 0.9771\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0471 - f1_m: 0.9771\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0473 - f1_m: 0.9743\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0468 - f1_m: 0.9830\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0466 - f1_m: 0.9783\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0465 - f1_m: 0.9749\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0473 - f1_m: 0.9805\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0464 - f1_m: 0.9802\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0465 - f1_m: 0.9748\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0459 - f1_m: 0.9797\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0458 - f1_m: 0.9776\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0464 - f1_m: 0.9767\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0455 - f1_m: 0.9785\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0453 - f1_m: 0.9788\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0474 - f1_m: 0.9810\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0455 - f1_m: 0.9805\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0456 - f1_m: 0.9780\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0454 - f1_m: 0.9794\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0449 - f1_m: 0.9763\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0469 - f1_m: 0.9777\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0460 - f1_m: 0.9781\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0448 - f1_m: 0.9762\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0449 - f1_m: 0.9784\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0441 - f1_m: 0.9794\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0443 - f1_m: 0.9818\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0450 - f1_m: 0.9731\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0447 - f1_m: 0.9755\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0453 - f1_m: 0.9789\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0450 - f1_m: 0.9799\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0443 - f1_m: 0.9758\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 1ms/step - loss: 0.6251 - f1_m: 0.7661\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.4208 - f1_m: 0.8631\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2426 - f1_m: 0.9251\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1524 - f1_m: 0.9592\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1167 - f1_m: 0.9620\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1020 - f1_m: 0.9677\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0945 - f1_m: 0.9673\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0898 - f1_m: 0.9646\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0863 - f1_m: 0.9674\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0841 - f1_m: 0.9721\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0824 - f1_m: 0.9672\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0806 - f1_m: 0.9723\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0792 - f1_m: 0.9727\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0787 - f1_m: 0.9659\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0774 - f1_m: 0.9717\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0768 - f1_m: 0.9740\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0756 - f1_m: 0.9743\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0755 - f1_m: 0.9740\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0742 - f1_m: 0.9749\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0738 - f1_m: 0.9731\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0734 - f1_m: 0.9732\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0729 - f1_m: 0.9771\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0725 - f1_m: 0.9733\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0719 - f1_m: 0.9746\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0713 - f1_m: 0.9746\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0705 - f1_m: 0.9756\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0700 - f1_m: 0.9757\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0701 - f1_m: 0.9728\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0690 - f1_m: 0.9762\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0693 - f1_m: 0.9772\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0686 - f1_m: 0.9770\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0682 - f1_m: 0.9731\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0676 - f1_m: 0.9768\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0680 - f1_m: 0.9690\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0677 - f1_m: 0.9763\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0672 - f1_m: 0.9776\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0671 - f1_m: 0.9786\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0672 - f1_m: 0.9707\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0661 - f1_m: 0.9792\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0661 - f1_m: 0.9780\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0659 - f1_m: 0.9718\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0656 - f1_m: 0.9786\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0655 - f1_m: 0.9759\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0650 - f1_m: 0.9752\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0647 - f1_m: 0.9734\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0648 - f1_m: 0.9767\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0637 - f1_m: 0.9759\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0636 - f1_m: 0.9669\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0630 - f1_m: 0.9782\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0633 - f1_m: 0.9767\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0625 - f1_m: 0.9777\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0623 - f1_m: 0.9791\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0617 - f1_m: 0.9792\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0614 - f1_m: 0.9797\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0610 - f1_m: 0.9810\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0615 - f1_m: 0.9758\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0609 - f1_m: 0.9740\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9821\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0605 - f1_m: 0.9754\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0597 - f1_m: 0.9760\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0593 - f1_m: 0.9765\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0595 - f1_m: 0.9762\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0590 - f1_m: 0.9777\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0591 - f1_m: 0.9788\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0586 - f1_m: 0.9752\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0582 - f1_m: 0.9789\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0582 - f1_m: 0.9802\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0575 - f1_m: 0.9754\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0579 - f1_m: 0.9778\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0577 - f1_m: 0.9745\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0571 - f1_m: 0.9804\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0574 - f1_m: 0.9698\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0566 - f1_m: 0.9812\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0567 - f1_m: 0.9831\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0562 - f1_m: 0.9816\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0565 - f1_m: 0.9804\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0560 - f1_m: 0.9803\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0555 - f1_m: 0.9800\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0560 - f1_m: 0.9769\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0557 - f1_m: 0.9809\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0548 - f1_m: 0.9816\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0551 - f1_m: 0.9823\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0548 - f1_m: 0.9825\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0550 - f1_m: 0.9775\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0549 - f1_m: 0.9745\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0556 - f1_m: 0.9821\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9827\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9790\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - ETA: 0s - loss: 0.0513 - f1_m: 0.98 - 1s 2ms/step - loss: 0.0539 - f1_m: 0.9799\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0545 - f1_m: 0.9808\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0540 - f1_m: 0.9814\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0537 - f1_m: 0.9758\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0546 - f1_m: 0.9788\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0537 - f1_m: 0.9794\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0535 - f1_m: 0.9793\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9746\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0535 - f1_m: 0.9777\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0536 - f1_m: 0.9727\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0531 - f1_m: 0.9794\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9826\n",
      "Keras MLP 平均的 F1-score: 0.9743012845516205\n"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import backend as K\n",
    "import numpy\n",
    "\n",
    "seed = 0\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#資料編碼器\n",
    "labelencoder = LabelEncoder()\n",
    "#複製成新的 DataFrame\n",
    "data_le = pd.DataFrame(df_shuffle)\n",
    "#針對 label 進行編碼 female: 0 male: 1 \n",
    "data_le['label'] = labelencoder.fit_transform(data_le['label'])\n",
    "\n",
    "#將 data 跟 target 都轉成 numpy\n",
    "X = data_le.drop(['label'], axis=1).to_numpy()\n",
    "y = data_le['label'].to_numpy()\n",
    "\n",
    "#定義如何計算 metrics 的 recall \n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "#定義如何計算 metrics 的 precision \n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "#定義如何計算 metrics 的 f1 score \n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# 定義 10 fold 方法\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#用來存放 10 fold 的 f1 score\n",
    "cvscores = [[],[]]\n",
    "\n",
    "for train, test in kfold.split(X, y): #不是用分層抽樣的 k fold\n",
    "    # 建立模型\n",
    "    model = Sequential()\n",
    "    # hidden layer\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # 編譯模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], y[train], epochs=100, batch_size=10)\n",
    "    # 評估模型\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    cvscores[0].append(scores[1])\n",
    "    \n",
    "print(\"Keras MLP 平均的 F1-score: \" + str(numpy.mean(cvscores[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras MLP 平均的 F1-score: 0.9743012845516205\n"
     ]
    }
   ],
   "source": [
    "print(\"Keras MLP 平均的 F1-score: \" + str(numpy.mean(cvscores[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 請問你在上述 3 題所使用的 F1-score 是以哪一類別為依據 (male、female、兩者平均)\n",
    "\n",
    "## Ans: 上述2、3題所使用的 F1-score 是以 female 類別為依據，第4題則以平均作為依據"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 以 t-test 比較上述三個模型的表現，並簡述結論\n",
    "\n",
    "## 做完 t-test 檢驗後，從統計學的角度來看，p-value 均大於 0.05，我們沒證據拒絕虛無假說，也就是兩兩的 F1-score 均值相等，結論是套用哪一種模型其實不影響結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.97897898, 0.97857143, 0.97704918, 0.97560976, 0.99382716,\n",
       "       0.98765432, 0.98734177, 0.97560976, 0.97029703, 0.97647059])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores1 : 存放 Random Forest F1-score 們\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98709677, 0.9702381 , 0.97610922, 0.98113208, 0.98422713,\n",
       "       0.98235294, 0.98148148, 0.98101266, 0.98026316, 0.98709677])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scores2 : 存放 scikit-learn MLP F1-score 們\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96137553, 0.98744583, 0.97801811, 0.9753722 , 0.98019296,\n",
       "       0.97021401, 0.9650467 , 0.96778077, 0.96950024, 0.98806649])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cvscores : 存放 Keras MLP F1-score 們\n",
    "numpy.array(cvscores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 與 scikit-learn MLP 比較\n",
      "t-test 檢驗結果: \n",
      "Ttest_relResult(statistic=-0.3871069299290029, pvalue=0.7076717060302897)\n",
      "================================================================================\n",
      "scikit-learn MLP 與 Keras MLP 比較\n",
      "t-test 檢驗結果: \n",
      "Ttest_relResult(statistic=1.8189428577754616, pvalue=0.10227460426868763)\n",
      "================================================================================\n",
      "Keras MLP 與 Random Forest 比較\n",
      "t-test 檢驗結果: \n",
      "Ttest_relResult(statistic=-1.5782827516108167, pvalue=0.14895670641802122)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import numpy as np\n",
    "\n",
    "print(\"Random Forest 與 scikit-learn MLP 比較\")\n",
    "print(\"t-test 檢驗結果: \")\n",
    "print(ttest_rel(scores1,scores2))\n",
    "print(\"=\"*80)\n",
    "print(\"scikit-learn MLP 與 Keras MLP 比較\")\n",
    "print(\"t-test 檢驗結果: \")\n",
    "print(ttest_rel(scores2,numpy.array(cvscores[0])))\n",
    "print(\"=\"*80)\n",
    "print(\"Keras MLP 與 Random Forest 比較\")\n",
    "print(\"t-test 檢驗結果: \")\n",
    "print(ttest_rel(numpy.array(cvscores[0]),scores1))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 有某新資料各屬性值如下，請判斷此聲音的性別：\n",
    "\n",
    "![](https://i.imgur.com/M1ByrTN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 用第2題的模型做判斷\n",
    "\n",
    "### Ans: male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測結果: male\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#資料編碼器\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "#複製成新的 DataFrame\n",
    "data_le = pd.DataFrame(df_shuffle)\n",
    "\n",
    "#針對 label 進行編碼 female: 0 male: 1 \n",
    "data_le['label'] = labelencoder.fit_transform(data_le['label'])\n",
    "\n",
    "#data\n",
    "X = df.drop(['label'], axis=1)\n",
    "#target\n",
    "y = df['label']\n",
    "\n",
    "#建立 RandomForest 分類器\n",
    "clf1 = RandomForestClassifier(random_state=0)\n",
    "\n",
    "#放入訓練資料 all data\n",
    "clf1.fit(X,y)\n",
    "\n",
    "#匯入欲判別的資料\n",
    "test_data = pd.DataFrame([[0.1528, 0.0735, 0.1490, 0.0479, 0.2095,\n",
    "                  0.1416,1.5325,7.3388,0.9631,0.7383,0.1325,\n",
    "                  0.1427,0.1101,0.0111,0.2539,0.2982, 0.0078,\n",
    "                  2.7235,2.7184,0.1251]],columns=df.columns[:20])\n",
    "\n",
    "#預測\n",
    "print(\"預測結果: \"+str(clf1.predict(test_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 哪一個屬性 在 RandomForest 的分類中最重要\n",
    "\n",
    "## Ans: meanfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAvkAAALDCAYAAACPXR+zAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABVZ0lEQVR4nO3de5xdVX338c+XAFGkRPsAGqISlKggqRSjCCJiLYoFbVX6VEULXoq3tnihiq2XVEWjggWVKinVoOKDd6iioijximiwShQhoIwoyE0gAuES4Pf8sffo4TCTZJI5OZM9n/frdV7n7LXXXvu31+zA76xZe02qCkmSJEndsdmwA5AkSZI0uUzyJUmSpI4xyZckSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJl9Q5SfZLUkn2G3YskiQNg0m+pPWW5LA2mR593ZHk8iRLkswZdnxTSdsnNc7rOcOObyxJnp/kVROov9GvMcluSRYmmTuI9jdU2ye3DjuODZHkoCQLhx2HpInZfNgBSOqEhcAvgHsBjwMOA56QZLequmWIcU01q4EXjVF+zsYOZB09H3gEcNwEjtnY17gb8BZgKTAyoHNMdwcBL6X5dy5pE2GSL2kynFlV328/n5Tkd8DrgKcDnxpeWFPOXVX18UE0nGSrqlo1iLYnaGDXuDElmQHMqKrbhx3LsEyhe0rSenC6jqRB+Fb7/tDRgiRbJnlrkmVJrk9yS5Jzkzyj/+B2eseHkjwtyf8muTXJxUmeO0bdhyc5M8mqJFcmeQ+w5VhBJXlGe85VbQyfT/KIvjoL2/M/vJ1qcX2S3yV5V5LNkmyf5FNJbkhyTZK3bFhXbVCMuyY5uf1S9bOe/fsnOTvJjUlubj/v3dfG1kmOSXJp279XJfnG6HMMSZYCTwV27J12M0nX+Jyea1yZ5AtJdu2r82dt//+ije+aJP8vyYN66hwG/L928+yeOA9r948kWTLG+ZckGenZntsed1SSVyS5GLgN2LvdPzvJ4iRXJLmtvRdflyTref0jSb6SZJ+2H25J8rMk+7f7D0jyo/a6l4/xs+v9+Z/S3ovXJzkpyTZjnO/FSc5v27s6yUeT7DBGn9yaZMckpyVZCXyp7b+XtnV6p1/NbcsOS3JW+2/vtiQrkrw+yWZ97S9NcmGSee2139zec+8co26SvDLJj9u+uTbJ15I8oa/eWu8jaTpzJF/SIMxt36/rKdsGeBnwSeDDwL2BQ4DTkjytqs7sa+NxwN8AHwL+G3gJ8PEkP66qnwMk2R74JrAVcCzwO+Dvgf37A0rzBeEU4CfAG4FZwD8B30vy6Kq6tO+QU4EVwL/SJLuvA64HngOcB7wBeDawMMlPquq0demYJNv2Fd1RVTesZ4yfopmi8ibaLzZtGx8Hzm7b2Ixm+sw3kjyxqs5tj/0g8H+BE2i+INwP2BPYnWbqy9Ft2Q7Aq9fl2tbxGl8PLAI+B3wU2Bp4BfDdJHv0XOP+NFOFPg78BtiZ5v55TJL57TSwb7XxvxJ4B/Dz9tjvTSTeHs9v41kM3Aj8tr3Hvg9s0Zb/FngC8C6avnnVep5rJ5qf30nAJ2j6+H/aLyjH0vx8TgFeD3wuyY5VdVtfG6cClwP/RvNzewnwYOApoxWSHAW8k6av/qXd/4800+n+fPTn0toM+CrwQ5r7/Q7gAuBBwF8AL+ipe037/o/ARcBXgFU0P7dFNPfuv/bFOws4C/gicBpwAHAUcClN345a3F7LWcASIDRfuJ4AfLu9rnW9j6Tpq6p8+fLla71eNHPviyYJ3hZ4IE3iezXN//B36Kk7A5jZd/yWNEnE1/rKi2Zu9y49ZfenGV19T0/ZsW3dJ/SUbQVc3Jbv15ZtQZOcXQjcp6funwN3Ah/vKVvYHvvfPWWheebgLuCtPeX3ovki84V16Kslbbv9r59uQIyf7TvHfdp4lvSVb0WTSH29p+x64ANrifkrwMgE7oe1XeOD25/rwr7jZgM39PX5VmO0v0/b3iE9Zc/p/Vn31R/p74ueOEd6tue2bdwEzO6ruxi4Crh/X/m725/L3HXok1vHiKuAfXvK9m3Lbgce3lP+f9vyZ4/x8/8ykJ7yt7blT2m3twVupfnCt3lPvb9u6719jJ/de8e4hg8BNc71jfVzOqnty5k9ZUvb9l/SV/fHwA97tvdr6y0eo91M9D7y5Ws6v5yuI2kyfIVmZO/XwGeA3wMHVdUVoxWq6s5qRyLTTN35U5rR/W8Cjx6jzbOrHbFvj7+KJgF+SE+dg4AfVdW3e+qt4u6jgrTtPwD4z6q6uafu/9KMFv7VGFMvTuqpV8APaJL9D/eU30oz6v5Q1s1qmpHO3tdLNiDGD/Zt708z+n5Kkm1HXzRJ/lk0o7dbtHV/Dzw2k78K0pqu8Vk0v0E+tS++1cC5NKPFwB9+jsAfphb9H5qf/w2Mfb9MhtOq6rc95w1wMM3I8519MZ9JM/L9xPU814qq+lbP9uhvWL5XVReNUT7WPfaB9t4c9b72/a/a978EZgL/UVV3jFaqqtNpRt8PHKPN/1zH+EfbWgXNMwxJ7tf2zVKaL5wP76t+K/CRvrJvcvd/0we3728c41yj17rO95E0nTldR9Jk+GeaqRKzgBfT/Fr9zv5KSV5CMy1hF5qEedRYc71/NUbZ9cCf9mzvSPPr+n4X9W3Pbd8vHKPuBTTTG7YBVvaUX9ZXb3Tfr8cofwTr5q6qOmucfesT4y/66j2sff/qGmK4L80XstfTJFyXJflfmi9qp/R+sVpPa7rG0fjGO0dvYn8/mukYB3P3nzk01zAI/f25Hc2Xphcx9opBANuv57nudn9V1W1JbmPs+4s2jn4X97VxbZLraf5dwJrvqZ/TjJr3uosJrlCUZB+aqVJ7cs9nYe7bt/2bqur/70L/v+mHAldX1dVrOO0630fSdGaSL2ky/LDa1XWSnEYz//cTSR5eVTe15c8F/gv4H5r5zFfTzPl9IfC8Mdq8x5eEVv9o9lhfECbyQOR4dcc8/xhJykTPtz7Ga79/edLR384eRjNXeywrAarq1CTfBJ5B8wXin4HXJ3lhDW51nNH4nkbzs+/X27en0kxhOQb4X5o58tWWr+tvocd7UHjGOOXj9ef/o+c3OH0uHqd8bca7v9f1vocNu/fHqre6d8R/rQ0kDwG+RtMHr6L54nIbsAfNv/H+n9N419Yf19oe8J7IfSRNWyb5kiZVVd3ZPhT3bZrE8R3trr8Dfgn8Te8UgyQv3IDT/YqxR9Ef1rc90r4/gnuOcj+CZjTx9xsQx2QYad83JMbRkehr1jCa/gft1JQTgROT3JfmAdO30DzsCmtPtiZqNL7LquqC8Sq1sTyFZs71v/eU34t7jmivKcbrGXvUf+46xArNbzx+TzOffa39OQQPo+dLRjtl5b788bdgI+37I2geIu/1CNZ91H68Pn4GzXMpT6+qP/zmLclO69juWC4Bnppk+zWM5q/TfSRNd87JlzTpquo7NH/86FVJ7t0Wj46u/WEEsR0JfOYGnOoMYI/epfWSbAUc3lfvPOBK4OU98ZDkUTRzxr/UN7d5GCYjxq/QzFl/Y5KZ/TuTbNe+z0gyq3dfNausXMrdk+ibmdypMZ+hGXn99/5lE3vjo5k2AvccbX419/z/1ujzC2NNZ7kE2Ku3L5LsQbs05tq0v7X5DPDM9rj+eGf1POMwDP/Y95zGP7fvX27fz6IZWT8izbr/ACR5Os18+TPW8Tw3t8f19/FY/6Zn0qy4s74+076/tX9Hz7Wu630kTWuO5EsalGOAz9I8dPl+mmk6z6JZJvB/gDk0S96tAB61nud4F82yh19M8j7+uITmzb2Vqmp1ktfQLEn43SQf44/LU66kWYJyqCYjxqq6McnhNNNLfpLkFJovDg8EnkTTL08D/gS4PMlnaR4c/j3weJolDU/oaXIZ8Owkx9M80HhXVZ26Add4aZLXAe8Fvp/kczSrAe1I87DoucDLqur3adbpf12SLWlGpvehecj1d33N/ojmS8Eb2t8A3AKcW80SiicCfwt8NcmpNPfcS2mWDL3HevLjOKo973eT/DewvD12N5qVpHam6eNhmEOzlv0Xaf4N/QPNCkpnwh/m6C+kWULzrLa/H0RzT43Q/BtdF8va9w8k+TJNgv0FmoePb6f593cizUO+L+CPX9ImrKqWpl2bvx0EGP0ishdwPvCOdb2P1jcGqTOGvbyPL1++Nt0Xf1xC83Fj7NuMZirBr4At2rJ/oZmycyvwU5oEfSF9y/O1bX5ojDaXAkv7ynahmRd8C81Sh8fQTPW4x7KKNEsH/qCtewPNWt2P6KuzsD32AX3lYy4j2LZx5Tr01RL6llIcp956x9izf2+aFWGua/v6Upq57H/Z7t+SZgnI/6X5AnFz+/N4LXdfavE+NGuQ/44mcbvH9a/nNR5Is6zj72kekryY5iHgx/TUmU2zjvzv2npfpEmoR7jnEqEvbtu4o+2Xw3r2/VN7D95K89uS/Rl/Cc2jxon3/wD/0fbj7TTPk3wHOBLYcqJ90l7DV8aoe+sY13bfNrZFY/z8H0mzxv7K9l75MDBrjHZfQvPl5Dbg2vZnOmddf3Y0zzAcT/Nl5q723HPbfU9r76NbaB4aPrrt47v9+6P5t3vhGG0v7L+vaP7b8WqaL2OjMX8VePxE7yNfvqbza3TNWUmStAloR+ffQrOm/7B+iyBpinNOviRJktQxJvmSJElSx5jkS5IkSR3jnHxJkiSpY1xCcwC23Xbbmjt37rDDkCRJUsedd95511bVPf4+hEn+AMydO5dly5atvaIkSZK0AZL8aqxy5+RLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR1jki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR1jki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUsdsPuwAumj55SuZe9QZa603sujAjRCNJEmSphtH8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6ZpNL8pN8IMnSnu0lSb44Ce3+NMnCDW1HkiRJGrYurJN/BJBhByFJkiRNFZt8kl9VK4cdgyRJkjSVTNp0nSRLk3wwybFJrktyTZIjksxMckKSG5JcluQFPcfMT3JWklvaY5YkmdWzf0aSY5Jc376OA2b0nfdu03XaOP4zyTuSXJvk6raNzXrqbJ/k9Pa8v0ryor42n5hkdZL9espeluT3SR4yWX0mSZIkDcJkz8k/BLgR2BNYBBwHnAasABYAJwMnJdkhyVbAV4CbgMcCzwT2Bj7c095rgX8AXgrsRZPgH7KOcdzRtvePwKuAv+vZvwTYGfhL4G+Avwfmju6sqm8C7wE+luRPkzwCOBb4p6r65TqcX5IkSRqayZ6u87OqWgiQ5L3AUcDqqjq+LXsr8Hqa5Pt+wNbAC6rqxnb/4cDZSXauqktokvN3V9Wn2v1HAE9dhzguqKo3t59XJPkH4MnA/0vyMOBpwD5V9d223UOB/uT9LcD+wEk0XwC+WFUnj3fCNvbDAWZss906hChJkiQNxmSP5J8/+qGqCrgaWN5Tthq4Htge2AU4fzTBb30PuAvYtZ22Mxs4p+f4u4BzJxJH64r2nLTnvQv4QU+7v2rr0FO2GngecFB77EvXdMKqWlxVC6pqwYytZq2pqiRJkjRQk53kr+7brnHKNqNZEafGaWe88g2JY/RaJ7ISz+Pa4+4LODwvSZKkTcIw18m/AHhUkj/pKdubJqaft6vm/JYm0QYgSWjm72+In7fneExPuw8GduitlGQu8AHglcDXgFOSbPKrEUmSJKn7hpnknwLcDHy0XWVnX+BE4HPtfHyA44HXJTk4ycNpHuSdvSEnraqLaB74PTHJXkl2p3kQ95bROklmAB8HvllVJwIvAR5IM09fkiRJmtKGluRX1Sqah2i3oZkffzrN/Pve5SyPBT5C8/DruTTxnjIJpz8MuBT4BvAF4BPASM/+f6VZfefFbay/Aw4FjkqyzyScX5IkSRqYNM/HajLNnD2vZh963FrrjSw6cPDBSJIkqbOSnFdVC/rLhzldR5IkSdIAmORLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUsf4x50GYP6cWSxz5RxJkiQNiSP5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx7i6zgAsv3wlc486Y0LHjLgajyRJkiaJI/mSJElSx5jkS5IkSR1jki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHTO0JD/JF5MsaT9vleQzSVYmqSRzhxWXJEmStKmbKuvkvwjYF9gHuKZ9SZIkSVoPUyXJ3xn4eVUtH69Cki2r6vaNGJMkSZK0Sdoo03Xa6ThLktyU5Kok/9qzbylwBLBvO1VnaVs+kmRhkg8nuQE4pS1flOSiJLe0dd6d5F497S1M8tMkz0nyiyQ3JjktybY9dTZP8h9Jrm9f/5Hkg6PnbuskyevaNm5JsjzJ8wfcVZIkSdIG21hz8o8B9geeDTwZ+HOa6TkAzwI+ApwDzG63R70GuBBYAIx+MbiZZnrPLsArgOcA/9Z3vrnA3wHPBJ7Snu/onv1HAocBLwEeR9MPz+tr4+3Ai4FXArsC7wROTHLgul+2JEmStPENfLpOkq1pkuUXVdWZbdkLgd8AVNV1SVYBt1fVlX2Hf7Oq3t1bUFVv69kcSfIOmqT9TT3lmwOHVdXK9nyLgRf27D8CeFdVfbbd/yrgqT0x34fmC8ZTqurbbfGlSR5Lk/SfMcZ1Hg4cDjBjm+3W2CeSJEnSIG2MOfkPBbakGakHoKpuSjLu/Psey/oLkhwMvIpmHv/WwIz21etXowl+6wpg+/b4WcADgB/0xFNJfgg8qC3aFbgX8JUk1dPOFsDIWIFW1WJgMcDM2fNqrDqSJEnSxrAxkvxswLE3362h5HHAqcC/A68GbgCeQTMdqNfqvu3inlOT1pSIj9Z9OnDZWtqWJEmSppSNkeRfQpMYPw74JfxhOsxuwC8m2Nbjgct7p+wk2XEiDVTVyiRXAo8Fzm7bCPAYYHS60AXAbcCOVfWNCcYoSZIkDdXAk/x2as5/A+9Kcg3N1Jk3c88pNutiBTAnySE003+eCjx3Pdo5HnhdkhU0Cf1LaR76/W0b841JjgGOab8AfItmatDjgLvaqTmSJEnSlLSx1sk/ErgP8HlgFfD+dntCquoLSd4DHAfcG/gqzReG/5xgU8fQzMv/CM20nY+0sd2/p86bgKva2D8I/B74MXC3B4ElSZKkqSZVPiMKkORHwHer6p82tK2Zs+fV7EOPm9AxI4tcmVOSJEkTk+S8qlrQXz5V/uLtRtXO438q8E2aPjgceFT7LkmSJG3SpmWSD9wF/D3wHpqVdC4AnlZV91iyU5IkSdrUTMskv6p+Dewz7DgkSZKkQehfO16SJEnSJs4kX5IkSeqYaTldZ9Dmz5nFMlfLkSRJ0pA4ki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMq+sMwPLLVzL3qDPW69gRV+WRJEnSBnIkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6hiTfEmSJKljOpfkJ1mQpJLMHXYskiRJ0jB0LsmXJEmSpjuTfEmSJKljJi3JT7I0yQeTHJvkuiTXJDkiycwkJyS5IcllSV7Qc8yiJBcluSXJSJJ3J7lXuy9JvpbkrCRpy7ZOcnGSD/S0cUCSC5PcmuTbwMPGiO1ZSZYnuS3Jr5P822ib7f6RJG9OsiTJjW2dv0ty3ySnJrmpPe9TJqu/JEmSpEGZ7JH8Q4AbgT2BRcBxwGnACmABcDJwUpId2vo3Ay8CdgFeATwH+DeAqirgUGB34Mi2/vuA24F/AUjyoLb9r7X13g+8uzegJI8GPg18DpgPHAW8AfjHvthfBfwA2AP4VBvrJ4AvtW1/C/j46JcQSZIkaapKk0tPQkPJUmBmVe3Vbge4Gjinqp7Rlm1Bk9g/r6o+M0YbLwOOrKqde8r+BvgkTfL+OuCxVfWTdt87gIOBh7dfCkjyRuBtwE5VNZLkFGB2Vf1FT5sLgZdU1QPb7ZE2zue221vTfFl5f1X9c1s2F7gUeExVLRsj9sOBwwFmbLPdox/48o9MsAcbI4sOXK/jJEmSNP0kOa+qFvSXT/ZI/vmjH9qk+2pgeU/ZauB6YPs2qIOTfCfJlUluAv4DeHBvg1V1Gs2I+huBN44m+K1dgO/X3b+pnNMX0y7Ad/vKvgPMSbLNOLHfBKzqjR24qn3f/p6XDVW1uKoWVNWCGVvNGquKJEmStFFMdpK/um+7xinbLMnjgFOBM4GnA39Ok8hv0Vu5nR7zGOBOYOe7N0VYu7TnHEtv+dpiH63rw8qSJEma0jYf4rkfD1xeVW8bLUiy4xj13gPMBPYHzkzypao6vd13AfDsJOkZzX9c3/EXAPv0le0D/KaqbtzQi5AkSZKmmmGOSq+gmTJzSJKHJHk58NzeCkkOAF4KPL+qzgYW0jy4+4C2yoeAucBxSR6e5GDgZX3nORZ4YpKFSR6W5BDgtfQ9oCtJkiR1xdCS/Kr6As0o/XE08+H3B948uj/JdsAS4O1VdW5bvAj4GfCRdvT+MuBZwAHAT4BX06ye03ueHwF/Czwb+GnbxiLgA0iSJEkdNGmr6+iPZs6eV7MPPW69jnV1HUmSJK2rjbW6jiRJkqQhM8mXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI4Z5h/D6qz5c2axzFVyJEmSNCSO5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR3j6joDsPzylcw96oz1OnbEVXkkSZK0gRzJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeqYKZXkJ6kkB29gGwvaduZOUliSJEnSJmWqrZM/G7h+2EFIkiRJm7IpleRX1ZXDjkGSJEna1A1suk6SpUk+mOTYJNcluSbJEUlmJjkhyQ1JLkvygp5j/jBdJ8ncdvvZSb6WZFWSC5Ls33eeA5JcmOTWJN8GHjZGLM9KsjzJbUl+neTfkqRn/0iSNydZkuTGts7fJblvklOT3JTk4iRPGVR/SZIkSZNl0HPyDwFuBPYEFgHHAacBK4AFwMnASUl2WEMbRwPvAx4F/BA4NcnWAEke1Lb3NWB34P3Au3sPTvJo4NPA54D5wFHAG4B/7DvPq4AfAHsAn2pj+wTwpbbtbwEfT3Kvdb56SZIkaQgGneT/rKoWVtXFwHuBa4HVVXV8VV0CvBUIsPca2viPqvpC28a/An9Kk3QDvBy4DPjnqrqwqj4FfKjv+NcA36yqt1TViqo6BTgGeH1fvTOr6j/b87wFmAlcUlUfbWN9G7AdsNtYQSY5PMmyJMvuXLVy7T0jSZIkDcigk/zzRz9UVQFXA8t7ylbTPGi7/bq0AVzRvo/W3wX4ftv2qHP6jt8F+G5f2XeAOUm2GSfWm4BVvbECV/Wd+26qanFVLaiqBTO2mjXetUiSJEkDN+gkf3Xfdo1TtqY4/lC/J5kfrZ97Vr+HtOcYS2/52mLtP7ckSZI0JW3qCesFwJ69D9ECjxujzj59ZfsAv6mqGwcZnCRJkjQMm3qS/yFgLnBckoe3K/O8rK/OscATkyxM8rAkhwCvpe8BXUmSJKkrNukkv6ouA54FHAD8BHg1zeo5vXV+BPwt8GzgpzSr/CwCPrBRg5UkSZI2ktz9mVVNhpmz59XsQ49br2NHFh04ucFIkiSps5KcV1UL+ss36ZF8SZIkSfdkki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHbP5sAPoovlzZrHMVXIkSZI0JI7kS5IkSR1jki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHePqOgOw/PKVzD3qjAkfN+KKPJIkSZoEjuRLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdUznkvwkNyU5bNhxSJIkScPSuSRfkiRJmu5M8iVJkqSOWWuSn2Rpkg8mOTbJdUmuSXJEkplJTkhyQ5LLkryg55g5SU5Ncn37OiPJvJ79D01yepIrk9yc5EdJDuo770iSNyY5Mcnvk/wmyb/01dm5je/WJBf1t9HWmZ/krCS3tPEvSTKrZ/+SJF9M8vo2npVJFiXZLMnCJFe35a+faOdKkiRJw7CuI/mHADcCewKLgOOA04AVwALgZOCkJDsk2Qo4G7gVeCKwF/Bb4Kx2H8DWwJeB/YFHAZ8FPpfkEX3nfTWwHNgDeBfw7iR7ASTZDPh8ew17AS8CFgIzRw9uz/cV4CbgscAzgb2BD/edZ19gJ2A/4GXA64AvtW3t07a7KMmj17G/JEmSpKFJVa25QrIUmFlVo8l1gKuBc6rqGW3ZFsDNwPOAbYA3AA+rtvEkM9pjXl5VnxrnPN8HvlhVb2+3R9pzPLenzsXAyVX19iRPofmisFNVXdbu3wf4NvDCqlqS5B+AY4AHVtWNbZ39aL6EzKuqS5IsAZ4MzK2qO9s6y4Atq+rPes49Anygqo4ZJ/7DgcMBZmyz3aMf+PKPrLFfxzKy6MAJHyNJkqTpK8l5VbWgv3zzdTz+/NEPVVVJrqYZYR8tW53kemB74JE0o+I3Nt8H/mAr4KFtMPcB3gIcBMwGtgDu1Xue/vO2rmjPAbALcPlogt86F7irZ3sX4PzRBL/1vbbOrsAlbdkFowl+6yrghr5zX9Vz7nuoqsXAYoCZs+et+ZuTJEmSNEDrmuSv7tuucco2a18/Bp4zRjvXte/HAAcARwIXA6uAjwJbrsN5R6cYhbVLe8xYessncn2SJEnSlLauSf5E/Ah4LnBtVd0wTp19gI9W1WcBktyLZpR/xQTOcwEwJ8mDqurXbdljuXsifgHwoiR/0jOav3db5+cTOJckSZK0yRjEyPQpNFNbTk/yxCQ7Jdm3XZ1ndIWdFcAzk+yRZD7wcZrpOhNxFnAh8NEku7cP5P4HcEdfLDe3deYn2Rc4EfhcVV1yjxYlSZKkDpj0JL+qVtGsVvNL4NM0ifjJwP2A69tqr6F5EPfbNA/Pfr/9PJHz3EWzWs5mNHPxPwq8HbitL5an0jwM/APgdOAcmpV4JEmSpE5a6+o6mriZs+fV7EOPm/Bxrq4jSZKkiRhvdR0fJJUkSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjpmEH8Ma9qbP2cWy1wpR5IkSUPiSL4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxrq4zAMsvX8nco84Yd/+IK+9IkiRpgBzJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeqYzif5SR6f5PwktydZOux4JEmSpEGbDuvkHw/8BDgQuHnIsUiSJEkD1/mRfGBn4BtV9euqum7YwUiSJEmDttGS/CRLk3wwybFJrktyTZIjksxMckKSG5JcluQFPccsSnJRkluSjCR5d5J7tfuS5GtJzkqStmzrJBcn+UCSuUkKmAV8OEklOSzJfu3nbXvOM7ctW9Buj9Z5cpJzk6xKsizJHhurvyRJkqT1tbFH8g8BbgT2BBYBxwGnASuABcDJwElJdmjr3wy8CNgFeAXwHODfAKqqgEOB3YEj2/rvA24H/gX4NTAbWAW8qv38yQnG+07gKGAP4HfAKaNfKCRJkqSpamMn+T+rqoVVdTHwXuBaYHVVHV9VlwBvBQLsDVBVb6uq71bVSFV9CXgH8NzRxqrqCuAlwNuTvI3mS8TzquqWqrqzqq4EClhZVVdW1S0TjPdNVXV2VV3YxvYIYM5YFZMc3o72L7tz1coJnkaSJEmaPBv7wdvzRz9UVSW5GljeU7Y6yfXA9gBJDqYZhd8Z2BqY0b7oOea0JJ8A3gi8rqp+Moh4gSva9+2B3/RXrKrFwGKAmbPn1STGIEmSJE3Ixh7JX923XeOUbZbkccCpwJnA04E/p0nkt+it3M7RfwxwJ82XgbW5a/TQnrItxqrYF9to4j4dHlaWJEnSJmwqL6H5eODyqnrbaEGSHceo9x5gJrA/cGaSL1XV6Wto95r2fXbP5903PFxJkiRpapjKo9IrgDlJDknykCQvp2c+PkCSA4CXAs+vqrOBhTQP7j5gDe1eQvNQ7sIkD0vyFJrfEEiSJEmdMGWT/Kr6As0o/XE0c+P3B948uj/JdsAS4O1VdW5bvAj4GfCR8VbBqarVNKv0PITmj2T9O/CvA7kISZIkaQjSrESpyTRz9ryafehx4+4fWXTgxgtGkiRJnZXkvKpa0F8+ZUfyJUmSJK0fk3xJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6pip/MewNlnz58ximSvoSJIkaUgcyZckSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrG1XUGYPnlK5l71BnrdeyIq/JIkiRpAzmSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxm1SSn6SSHDzBYx6f5PwktydZOqDQJEmSpCljU1snfzZw/QSPOR74CXAgcPOkRyRJkiRNMZvUSH5VXVlVt03wsJ2Bb1TVr6vqukHEJUmSJE0lQ0vykyxN8sEkxya5Lsk1SY5IMjPJCUluSHJZkhf0HPOH6TpJ5rbbz07ytSSrklyQZP/e/cAs4MNt3cOS7Nd+3ran3dG2FrTbo3WenOTctu1lSfbYuL0kSZIkTdywR/IPAW4E9gQWAccBpwErgAXAycBJSXZYQxtHA+8DHgX8EDg1ydbAr2mm96wCXtV+/uQE43sncBSwB/A74JQkmWAbkiRJ0kY17CT/Z1W1sKouBt4LXAusrqrjq+oS4K1AgL3X0MZ/VNUX2jb+FfhTYPequrOqrgQKWNlO9bllgvG9qarOrqoL21geAcwZq2KSw9vR/mV3rlo5wdNIkiRJk2fYSf75ox+qqoCrgeU9ZatpHrTdfl3aAK5o39dUf73iW1vbVbW4qhZU1YIZW82apNNLkiRJEzfsJH9133aNU7amOP9Qv/2iwFrq39W+90672WId4luXtiVJkqShm44J6zXt++yest2HEIckSZI0ENMxyb+E5qHchUkeluQpwBuHHJMkSZI0aaZdkt/O838O8BCaP5L17zQP7EqSJEmdMLS/eFtV+41RttsYZQ/o+ZyezyPcfV79Peq021uPUed73HOKTm/bS/vbHu98kiRJ0lQz7UbyJUmSpK4zyZckSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjhna6jpdNn/OLJYtOnDYYUiSJGmaciRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqGFfXGYDll69k7lFnDDsMSZIkDdjIFF1R0ZF8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI7pfJKf5AFJvprk5iQ17HgkSZKkQZsO6+QfCewA7A7cONxQJEmSpMGbDkn+zsB5VXXxsAORJEmSNoZJma6TZGmSDyY5Nsl1Sa5JckSSmUlOSHJDksuSvKDnmDlJTk1yffs6I8m8nv0PTXJ6kivbqTY/SnJQ33lHkrwxyYlJfp/kN0n+pXc/8NfA3yepJEva8kpy8BhtHdmzXUkOT/Lp9vy/TPL8yegvSZIkaZAmc07+ITTTYfYEFgHHAacBK4AFwMnASUl2SLIVcDZwK/BEYC/gt8BZ7T6ArYEvA/sDjwI+C3wuySP6zvtqYDmwB/Au4N1J9mr3PQY4C/gUMBs4YoLX9Gbg9Pb8nwQ+nGTHCbYhSZIkbVSTmeT/rKoWttNi3gtcC6yuquOr6hLgrUCAvYHntJ9fWFXnV9WFwEtpEvuDAKrqJ1X1oapaXlWXVNXRwI+Ag/vO+9Wq+kBb5/3AJcCT2zauAW4DbqmqK6tq5QSv6WNV9fE2/jcBdwBPGKtiO+q/LMmyO1dN9DSSJEnS5JnMOfnnj36oqkpyNc0I+2jZ6iTXA9sDjwR2Am5M0tvGVsBDAZLcB3gLTdI/G9gCuFfvefrP27qiPcdk6L2mO5JcM17bVbUYWAwwc/Y8V/GRJEnS0Exmkr+6b7vGKdusff2YZkS/33Xt+zHAATSr41wMrAI+Cmy5Dudd228oiuY3Cb22GKPe+rQtSZIkDdWwVtf5EfBc4NqqumGcOvsAH62qzwIkuRfNKP+KSTj/NTS/HaBt+/6925IkSdKmbFij0qcAVwGnJ3likp2S7NuuzjO6ws4K4JlJ9kgyH/g4zXSdyfAN4JVJFiT5c2AJzUPAkiRJ0iZvKEl+Va0C9gV+CXwauJBm9Z37Ade31V4DXA18m2aVne+3nyfDa9tzLwU+A5zUnkuSJEna5KXKZ0Qn28zZ82r2occNOwxJkiQN2MiiA4d6/iTnVdWC/nIfIpUkSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjpmWH8Mq9Pmz5nFsiE/aS1JkqTpy5F8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY1xdZwCWX76SuUedMdQYRlzdR5IkadpyJF+SJEnqGJN8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyW0kqycFr2L9tW2e/jReVJEmSNHGb7Dr5SZYA21bVQZPU5Gzg+klqS5IkSRqaTTbJX1dJtqiq1WurV1VXbox4JEmSpEEb2HSdNF6b5OIktyX5TZJ3tvvmJDk1yfXt64wk83qOXZjkp0mek+QXSW5MclqSbUf3A4cCB7ZTaCrJfknmtp+fm+QbSW4BXppksyRvSvLrNpblSf66L967TddJ8pgk5yW5Ncn/AnsOqq8kSZKkyTTIOfnvAN4EvBN4JPC3wK+TbAWcDdwKPBHYC/gtcFa7b9Rc4O+AZwJPAf4cOLrddwzwKeAsmmk2s4Hv9Rz7TuA/gV2B04AjgH8BXg/MBz4PfC7J7mMFnuQ+wBnAL4EFwFHtOSVJkqQpbyDTdZJsDbwaeFVVfbgtvgQ4J8mLgAAvrKpq678UuBo4iCZ5H43tsKpa2dZZDLwQoKpuakfpb+udZpNk9OP7q+ozPeVHAsdU1Sfaojcn2Rc4Enj+GJdwCLBlG+NNwE+THA18bA3XfDhwOMCMbbZbSw9JkiRJgzOokfxdgZnA18fY92hgJ+DGJDcluQlYCdwPeGhPvV+NJvitK4Dt1/H8y0Y/JNkG2AH4bl+d77RxjmUX4Pw2wR91zppOWFWLq2pBVS2YsdWsdQxTkiRJmnyDevA2a9i3GfBj4Dlj7Luu53P/w7LFun8puXmMslrHMlhz/JIkSdKUNqiR/AuA24Anj7HvR8DOwLVVdUnf67ox6o/ndmDG2ipV1e9pfguwT9+ufdo4x3IBML+dmz/qcROITZIkSRqagST5VXUjcDzwziQvTPLQJI9N8nLgFOAq4PQkT0yyU5J9kxzbu8LOOhgBdkvy8PYPVW2xhrrvAY5sV915WJK3Ak8Ajh2n/ieAO4APJ3lkkv2Bf5tAbJIkSdLQDHKd/DfQ/HGpNwEPpEnsP1pVq9qHXhcBnwZm0Yy0n83E/hjVfwH70cy/3xp4Ek3iP5b3AX8CvBu4P3AR8Oyq+vFYldsHew8CPkjzm4cLaVbm+Z8JxCdJkiQNRdoFbjSJZs6eV7MPPW6oMYwsOnCo55ckSdLgJTmvqhb0lw9ynXxJkiRJQ2CSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdM8glNKet+XNmsczVbSRJkjQkjuRLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkd4+o6A7D88pXMPeqMYYcBwIir/EiSJE07juRLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJfivJB5IsHXYckiRJ0oYyyZckSZI6xiRfkiRJ6pgpn+QnWZrkg0mOTXJdkmuSHJFkZpITktyQ5LIkL+g5Zn6Ss5Lc0h6zJMmsnv0zkhyT5Pr2dRwwo++8SfK6JL9o21me5Pkb78olSZKk9TPlk/zWIcCNwJ7AIuA44DRgBbAAOBk4KckOSbYCvgLcBDwWeCawN/DhnvZeC/wD8FJgL5oE/5C+c74deDHwSmBX4J3AiUkOnPSrkyRJkiZRqmrYMaxR+zDszKraq90OcDVwTlU9oy3bArgZeB5wP+AY4IFVdWO7fz/gbGBeVV2S5ArghKo6ut2/GXAhcEVV7ZfkPsC1wFOq6ts9sRwHPKyq/mqMOA8HDgeYsc12j37gyz8yyT2xfkYW+Z1EkiSpq5KcV1UL+ss3H0Yw6+H80Q9VVUmuBpb3lK1Ocj2wPbAzcP5ogt/6HnAXsGuSa4DZwDk9x9+V5FzgQW3RrsC9gK8k6f0WtAUwMlaAVbUYWAwwc/a8qf3NSZIkSZ22qST5q/u2a5yyzYC0n8eyrsn36DSmpwOXrSUWSZIkaUrZVObkT8QFwKOS/ElP2d401/rzqloJ/BZ43OjOdgrQY/vauA3Ysaou6Xv9avCXIEmSJK2/TWUkfyJOAf4d+GiSN9PM0T8R+FxVXdLWOR54Q5IVNNN+XkEzhee3AFV1Y5JjgGPaLwDfAram+WJwVzs1R5IkSZqSOjeSX1WrgKcC2wA/AE6nmX//op5qxwIfAU4CzqXph1P6mnoTsBA4EvgZ8DXg2cClg4tekiRJ2nBTfnWdTdHM2fNq9qHHDTsMwNV1JEmSumy81XU6N5IvSZIkTXcm+ZIkSVLHmORLkiRJHWOSL0mSJHWMSb4kSZLUMV1cJ3/o5s+ZxTJXtZEkSdKQOJIvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR1jki9JkiR1jKvrDMDyy1cy96gzhh3GGo24+o8kSVJnOZIvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR1jki9JkiR1jEm+JEmS1DHTMslP8tdJLk5yR5Ilw45HkiRJmkzTdZ38k4D/Bt4P3DTkWCRJkqRJNe2S/CT3BbYFzqyqy4ccjiRJkjTpOjtdJ8m+Sb6f5KYkK5Ocm+QfgevbKt9IUkn2S3JYW+9pSS5MsirJ/ySZleTgdmrPyiQfS3LvYV6XJEmStDadHMlPsjlwOs2UnEOALYA9gJ8Bj2zfnw18D7gOmAvMBF7b1t8S+CzwGeDWtu7/AT4HvAI4dqNdjCRJkjRBnUzygW2A+wJfqKpftGUXAiTZtt2+rqqubMug6YtXVtVFbdkngFcD96+qa9uy04EnMUaSn+Rw4HCAGdtsN5CLkiRJktZFJ6frVNV1wBLgzCRnJHlNkget5bDbRhP81lXAlaMJfk/Z9uOcc3FVLaiqBTO2mrUh4UuSJEkbpJNJPkBVvRDYE/gW8AxgRZKnruGQO/qbAFaPUdbZPpMkSVI3dDphraqfVNW7qmo/YClw6HAjkiRJkgavk0l+kp2SLEqyd5IdkzwJ+DPggmHHJkmSJA1aVx+8XQU8DPg0zZr4VwGnAO8CnDAvSZKkTktVDTuGzpk5e17NPvS4YYexRiOLDhx2CJIkSdpASc6rqgX95Z2criNJkiRNZyb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxXV1Cc6jmz5nFMlevkSRJ0pA4ki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMq+sMwPLLVzL3qDOGHcZGN+KKQpIkSVOCI/mSJElSx5jkS5IkSR1jki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMSf46SLIwyU+HHYckSZK0LkzyJUmSpI6Zckl+kn2TfD/JTUlWJjk3yW5JDmvLnp5kRZJbk5yd5CFraW9WksVJrk5yY5JvJlnQs3+03Scn+WmSm9t2dxrdD7wFeGSSal+HDbIPJEmSpA0xpZL8JJsDpwPfAR4F7AkcD9zZVplJk3C/ENgLmAF8PknGaS/AGcAc4CDgz4FvAd9IMrun6kzgDcCL2nbvC3yo3fdJ4FjgImB2+/rkBl+sJEmSNCCbDzuAPtvQJNhfqKpftGUXAiTZkybeI6rqu23ZC4BfAk8GzhqjvScBuwPbVdUtbdmbkjwdeAHw7rZsc+CVVXVR2+4xwEeSbFZVtyS5Cbijqq4cL/AkhwOHA8zYZrv1uHRJkiRpckypkfyqug5YApyZ5Iwkr0nyoJ4qdwE/6Kn/K+AKYNdxmnw0sBVwTTsl56Y2Yd8NeGhPvdtGE/zWFcAWNF841jX2xVW1oKoWzNhq1roeJkmSJE26qTaST1W9MMlxwAHAM4Cjk/zNeja3GXAV8IQx9v2+5/Md/WH0HC9JkiRtUqZckg9QVT8BfgK8K8mXgUOBr9Ik3Y8BvgeQ5MHADsDPx2nqR8D9gbuq6pcbENLtNPP/JUmSpClvSo1UJ9kpyaIkeyfZMcmTgD8DLmir3AEcl2SvJLsDJwM/o52Pn+SxSS5M8ti2/lnAd4HTkzytbX+vJP+eZKzR/fGMADsm2SPJtklmbvjVSpIkSYMxpZJ8YBXwMODTwAqaJP4U4F3t/tuAo4GPAufSxP+sqhqdXrMV8PD2nbb8r4BvAP9Fs0LOp9o6V0wgrs8CXwK+DlwDPHe9rk6SJEnaCPLH/Hhqa9em/0BVbT3sWNZm5ux5NfvQ44YdxkY3sujAYYcgSZI0rSQ5r6oW9JdPtZF8SZIkSRvIJF+SJEnqmE0mya+qJZvCVB1JkiRp2DaZJF+SJEnSujHJlyRJkjpmSv4xrE3d/DmzWOZKM5IkSRoSR/IlSZKkjjHJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOcXWdAVh++UrmHnXGhI4ZcTUeSZIkTRJH8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6plNJfpKlST4w7DgkSZKkYepUkj8ISfZLUkm2HXYskiRJ0rowyV+DJFsOOwZJkiRpojqd5Cd5cpIbkry0HY0/uG//SJIje7YrySuTfC7JzcAngLPb3de0+5dsvCuQJEmSJq6zSX6SZwOfBw6vqhMncOhbgC8B84HXA89uyx8JzAaOmMw4JUmSpMm2+bADGIQkhwPvAQ6uqq9O8PBPVtVJPW09qP14dVVdu5ZzHg4wY5vtJnhKSZIkafJ0cST/r4ETgAPWI8EHWLY+J62qxVW1oKoWzNhq1vo0IUmSJE2KLib55wO/BV6cJD3lBaSv7hZjHH/zoAKTJEmSNoYuJvmXAvsBTwEW9yT619DMqQcgyf17t9fg9vZ9xiTGKEmSJA1MF5N8quqXwJOAA/hjov8N4JVJFiT5c2AJcOs6NPcrmt8CHJhkuyRbDyhsSZIkaVJ0MskHqKpf0IzoHwCcCBwJ/BJYCnwGOAm4eh3auZxmxZ2jgasA/6KuJEmSprROra5TVfv1bf8CeFBP0dP6DvlsX/3+Ofuj5W8D3jYJIUqSJEkD19mRfEmSJGm6MsmXJEmSOsYkX5IkSeoYk3xJkiSpYzr14O1UMX/OLJYtOnDYYUiSJGmaciRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqGFfXGYDll69k7lFnbHA7I67QI0mSpPXgSL4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR3TqSQ/yWFJbhp2HJIkSdIwdSrJlyRJkmSSL0mSJHXOJpnkJ9k3yfeT3JRkZZJzk+w2Rr37JflukjOT3CeN1yX5RZJbkixP8vye+p9M8sGe7aOTVJI9e8p+k+SQwV+lJEmStH42uSQ/yebA6cB3gEcBewLHA3f21ZsNfAu4HHh6Vd0MvB14MfBKYFfgncCJSQ5sD1sKPKmnmf2Aa0fLkswD5rT1+uM6PMmyJMvuXLVyEq5UkiRJWj+bXJIPbAPcF/hCVf2iqi6sqk9U1c9HKyTZGfguzReB51TV7UnuA7wGeElVfaWqLq2qTwD/RZP0Q5O8PzzJ7CRbAQuAY/lj4r8fcElVXd4fVFUtrqoFVbVgxlazBnDZkiRJ0rrZfNgBTFRVXZdkCXBmkq8DXwc+XVW/bqtsSZPcf7aqXtlz6K7AvYCvJKme8i2Akbbtnye5ij+O4P8COBV4Y5It2vKlA7kwSZIkaZJsckk+QFW9MMlxwAHAM4Cjk/xNu3s18FXgr5LsWFW/astHf2vxdOCyviZX93z+Js3I/TXA2VU1kuRa4DHAE4HXT/LlSJIkSZNqU5yuA0BV/aSq3lVV+9GMrh86ugs4jGY0/+wkD27LLwBuA3asqkv6Xr/qaXopTZI/2i40if/hjDMfX5IkSZpKNrkkP8lOSRYl2TvJjkmeBPwZTRIPQFXdRZP0fw9YmuTBVXUjcAxwTJIXJdk5ye5JXpbk8J5TLAV2Bh7LHxP6pcDzGWc+viRJkjSVbHJJPrAKeBjwaWAFcDJwCvCu3kp9if7oiP6bgIXAkcDPgK8BzwYu7Tnu58CVwEVVdU1bfDYwA0fxJUmStAlIVa29liZk5ux5NfvQ4za4nZFFB669kiRJkqatJOdV1YL+8k1xJF+SJEnSGpjkS5IkSR1jki9JkiR1jEm+JEmS1DGb5B/Dmurmz5nFMh+alSRJ0pA4ki9JkiR1jEm+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMq+sMwPLLVzL3qDOGHYYkTSsjrmomSX/gSL4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx5jkS5IkSR1jki9JkiR1TGeT/CRLknyxZ/u+SY5J8ssktye5OsmpSR7Rd9zCJNW+7kpyRZJTkjxo41+FJEmSNHGdTfJ7JbkfcA5wIHAEsDPwDOA+wA+TPKbvkIuA2cADgb8D5gOf2mgBS5IkSRtg82EHsJEcDTwYmFdVV7RllyX5a2AZ8JEk86uq2n13VNWV7ecrkvwX8L4k21TV7zdu6JIkSdLEdH4kP8lmwHOAU3oSfACq6i7gWOCRwJ+Nc/wDgGcBd7av8c5zeJJlSZbduWrlZIUvSZIkTdh0GMnfDrgf8PNx9l/Qvj8c+En7eZckN9F8Cbp3W/a+qrp5vJNU1WJgMcDM2fNqvHqSJEnSoE2HJH/UeIl32vfbe8p+AfwVMBP4a+DZwL8OLjRJkiRp8kyHJP8a4HqaKTlj2aV9X9FTdntVXdJ+/lmSecAJwGEDiVCSJEmaRJ2fk9/Ouz8VeF6SHXr3tfP1Xwssq6oLxjq+9TbgkCSPHlykkiRJ0uTofJLf+jfg18BZSZ6e5EFJHgecBuwEHLqmg6vql8D/0CT7kiRJ0pQ2LZL8qroe2Av4MvA+4FKadfMfBuy2llH8UccCT0uy98AClSRJkiZBZ5P8qjqsqg7q2b6+ql5bVTtV1eY0D9M+hObB2t7jFlbVbmO0972qSlV9b+DBS5IkSRugs0n+2lTV54CDgG2T/J9hxyNJkiRNlumwus64quqrwFeHHYckSZI0mabtSL4kSZLUVSb5kiRJUsdM6+k6gzJ/ziyWLTpw2GFIkiRpmnIkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6hhX1xmA5ZevZO5RZ6z38SOuzCNJkqQN4Ei+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdUznkvwkc5IsTvKbJLcnuTzJfyV5YE+dkSQ1xuuMnjpLxtj//eFclSRJkrTuOvUXb5PsBHwPuBQ4FLgYeChwNPDDJHtV1QjwGGBGz6GzgfOAT/U1eRbwgp7t2wcTuSRJkjR5OpXkAycAdwF/WVWr2rLLkvwlTcJ/AnBgVV3Te1CSFwO/Bz7d195tVXXlgGOWJEmSJlVnpusk+VPgAOCEngQfgHb7P4GnJblf33EBXgx8vP84YJ8kVydZ0U752X4N5z88ybIky+5ctXJSrkmSJElaH51J8oF5QICfj7P/gnb/vL7y/YGdgJP6yr8C/D3wZOC1wGOBbySZOVbjVbW4qhZU1YIZW81avyuQJEmSJkHXpusA1Djlad/759X/A/DDqvrx3RqpOrVnc3mS84BfAQcCn5uEOCVJkqSB6NJI/sU0Cf4jx9m/C3AHzUO5ALTTb/4a+K+1NV5VVwC/4Z6/CZAkSZKmlM4k+VV1Hc0Um1ck2ap3X7v9SuDzVdU7Yf6FwG1A76j9mJJsC8wBfjtpQUuSJEkD0Jkkv/VKmqUxz0ryF0kelGQ/4GvAauCfRyu2D9y+BDi1qm7sbSTJ1kmOSbJXkrltG18ArgY+vzEuRJIkSVpfnUryq+pSYAHwM+BjwAhwNs2ymrv3LYe5H7AzY0/VuROYD5wOrABOBi4C9ur/QiBJkiRNNZ178LaqfkPzMC0ASf4JOBbYlyZpH613Nn98GLe/jVuApw42UkmSJGkwOjWSP5aqej/wfGDXJPcedjySJEnSoHVuJH8sVfWpYccgSZIkbSydH8mXJEmSphuTfEmSJKljpsV0nY1t/pxZLFt04LDDkCRJ0jTlSL4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxrq4zAMsvX8nco84YdhiS1sGIK2FJkjrIkXxJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqmM4l+UnmJFmc5DdJbk9yeZL/SvLAnjpvSPLDJL9Pck2SLyTZra+dJUmq7/X9jX9FkiRJ0sR0KslPshOwDNgNOBTYGXg+8Ejgh0nmtlX3A/4T2Bv4C+AO4Kwkf9rX5FnA7J7XXw32CiRJkqQNt/mwA5hkJwB3AX9ZVavassuS/CVwcbv/wKp6au9BSV4ArAQeD3yhZ9dtVXXl4MOWJEmSJk9nRvLbUfgDgBN6EnwA2u3/BJ6W5H5jHP4nNH1xfV/5PkmuTrKinfKz/RrOf3iSZUmW3blq5YZdjCRJkrQBOpPkA/OAAD8fZ/8F7f55Y+w7HvgxcE5P2VeAvweeDLwWeCzwjSQzx2q8qhZX1YKqWjBjq1nrdQGSJEnSZOjadB2AGqc87fvtdytM3gvsA+xTVXf+oZGqU3uqLU9yHvAr4EDgc5MXriRJkjS5ujSSfzFNgv/IcfbvQvOA7aWjBUn+A3gu8BdV9cs1NV5VVwC/YezfBEiSJElTRmeS/Kq6jmaKzSuSbNW7r91+JfD5qlrZlh0PPI8mwb9wbe0n2RaYA/x2smOXJEmSJlNnkvzWK4EZNMth/kWSByXZD/gasBr4Z4AkJwAvpBnFvz7JA9rX1u3+rZMck2SvJHPbNr4AXA18fiNfkyRJkjQhnUryq+pSYAHwM+BjwAhwNs2ymrv3LIf5CpoVdb5OMzI/+jqy3X8nMB84HVgBnAxcBOxVVTdujGuRJEmS1lfnHrytqt8A/zC6neSfgGOBfWmSdqoqYx/9hzZuAZ66pjqSJEnSVNWpkfyxVNX7af7q7a5J7j3seCRJkqRB69xI/liq6lPDjkGSJEnaWDo/ki9JkiRNNyb5kiRJUsdMi+k6G9v8ObNYtujAYYchSZKkacqRfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqGJN8SZIkqWNcXWcAll++krlHnTHQc4y4eo8kSZLG4Ui+JEmS1DEm+ZIkSVLHmORLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUsd0MslPcmSSkZ7thUl+OsSQJEmSpI2mk0n+GI4BnjjsICRJkqSNYVr8Mayqugm4adhxSJIkSRvDRh3JT7I0yQeTHJvkuiTXJDkiycwkJyS5IcllSV7Qc8ycJKcmub59nZFkXl+7r0tyZZKbknwU2Lpv/92m6yR5TJKvJrk2ye+TfCfJXn3HVJLDk3w6yc1Jfpnk+QPqGkmSJGnSDGO6ziHAjcCewCLgOOA0YAWwADgZOCnJDkm2As4GbqWZbrMX8FvgrHYfSf4v8HbgLcAewEXAa9YSw58AHwOeADwW+DHwpSTb9tV7M3A68Cjgk8CHk+y4fpctSZIkbRzDSPJ/VlULq+pi4L3AtcDqqjq+qi4B3goE2Bt4Tvv5hVV1flVdCLyUZqT+oLa9VwEnV9WJVbWiqo4GfrCmAKrqG1X1sar6edvmP9F8kTigr+rHqurjbVxvAu6g+WJwD+2o/7Iky+5ctXKCXSJJkiRNnmEk+eePfqiqAq4GlveUrQauB7YHHg3sBNzYTsW5CVgJ3A94aHvILsA5fefo376bJNsnOTHJiiQraX6zsD3w4DXEegdwTVvvHqpqcVUtqKoFM7aatabTS5IkSQM1jAdvV/dt1zhlm7WvH9OM6Pe7bgNiOBm4P/BqYAS4Dfg6sOU6xDpdViSSJEnSJmqqr67zI+C5wLVVdcM4dX4OPA74cE/Z49bS7j7AP1fVGQBJ7g/M3rBQJUmSpKlhqo9KnwJcBZye5IlJdkqyb7s6z+gKO8cDhyb5hyTzkryB5qHeNVkBPD/JrkkeA5wK3D6wq5AkSZI2oimd5FfVKmBf4JfAp4ELaaba3I9m3j5V9UlgIXA08L/AfJoHetfkRTQP755Hk+B/mGbajiRJkrTJS/PsqybTzNnzavahxw30HCOLDhxo+5IkSZr6kpxXVQv6y6f0SL4kSZKkiTPJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOmep/DGuTNH/OLJa5+o0kSZKGxJF8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY1xdZwCWX76SuUedMewwNIWMuNqSJEnaiBzJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk/wJSHJwkhp2HJIkSdKamORLkiRJHWOSL0mSJHXMtE/yk+yb5PtJbkqyMsm5SXZr9/19kl8lWZXki8D9hxyuJEmStFbTOslPsjlwOvAd4FHAnsDxwJ1J9gSWAIuB3YEvAG8dSqCSJEnSBGw+7ACGbBvgvsAXquoXbdmFAEk+AXy9qo5uy1ckeQzw4rEaSnI4cDjAjG22G2TMkiRJ0hpN65H8qrqOZrT+zCRnJHlNkge1u3cBzuk7pH+7t63FVbWgqhbM2GrWYAKWJEmS1sG0TvIBquqFNNN0vgU8g2bE/qlAhhqYJEmStJ6m+3QdAKrqJ8BPgHcl+TJwKHAB8Li+qv3bkiRJ0pQzrZP8JDsBLwX+B7gceAjwZ8AHgbOA7yV5A/AZYD/gmcOJVJIkSVp30326zirgYcCngRXAycApwLuq6vs0D9m+HDgfeBawcDhhSpIkSetuWo/kV9VVNMn7ePs/Anykr/gDAw1KkiRJ2kDTfSRfkiRJ6hyTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqmGm9us6gzJ8zi2WLDhx2GJIkSZqmHMmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6xtV1BmD55SuZe9QZww7jbkZc7UeSJGnacCRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqGJN8SZIkqWM6k+QneUCSrya5OUkNOx5JkiRpWLq0Tv6RwA7A7sCNww1FkiRJGp4uJfk7A+dV1cXjVUiyZVXdvhFjkiRJkja6CU3XSbI0yQeTHJvkuiTXJDkiycwkJyS5IcllSV7Qc8ycJKcmub59nZFkXs/+hyY5PcmV7VSbHyU5qO+8I0nemOTEJL9P8psk/9K7H/hr4O+TVJIlbXkleWWSzyW5GXhHW/70JOcluTXJpUmOTrJlT3vbtzHdkuRXSV6U5KdJFk6kvyRJkqRhWJ85+YfQTIfZE1gEHAecBqwAFgAnAycl2SHJVsDZwK3AE4G9gN8CZ7X7ALYGvgzsDzwK+CzwuSSP6Dvvq4HlwB7Au4B3J9mr3fcY4CzgU8Bs4Iie494CfAmYD5yQ5KnAKcAHgEcCLwIOpv0C0FpC85uBvwT+Bvh7YO66d5EkSZI0PKla92dUkywFZlbVXu12gKuBc6rqGW3ZFsDNwPOAbYA3AA+r9kRJZrTHvLyqPjXOeb4PfLGq3t5uj7TneG5PnYuBk3vqfBG4tqoO66lTwAeq6p96yr4FfK2q3tZT9jfAx4E/AeYBFwH7VNV32/07Ar8E3lZVC8eJ+XDgcIAZ22z36Ae+/CNr6MmNb2TRgcMOQZIkSZMsyXlVtaC/fH3m5J8/+qGqKsnVNCPso2Wrk1wPbE8zUr4TcGPzfeAPtgIe2gZ2H5rR9oNoRuG3AO7Ve57+87auaM+xNsv6th8NPDbJ63vKNgPuDTwA2AW4C/hBzzX9KskVazpJVS0GFgPMnD3P1X0kSZI0NOuT5K/u265xyjZrXz8GnjNGO9e178cAB9CsjnMxsAr4KLBlX/3xzrE2N/dtbwb8O/DpMepeA2SMckmSJGmTMejVdX4EPJdmGs0N49TZB/hoVX0WIMm9aEb5VwwwpkdU1SVj7Uzyc5ovAo8BvteWPZhmeU5JkiRpyhv0H8M6BbgKOD3JE5PslGTfdnWe0RV2VgDPTLJHkvk0c+PvNcCY3go8L8lbk+yW5BFJDk7yboCqugj4CnBikr2S7E7zIO4tA4xJkiRJmjQDTfKrahWwL81Dq58GLqRZfed+wPVttdfQPIj7bZpVdr7ffh5UTGcCBwJPopl3/wPgKOCynmqHAZcC3wC+AHwCGBlUTJIkSdJkmtDqOtNZkp8CnxlvdZ1eM2fPq9mHHjfwmCbC1XUkSZK6Z7zVdQY9XUeSJEnSRmaSL0mSJHXMoFfX6Yyq2m3YMUiSJEnrwpF8SZIkqWNM8iVJkqSOcbrOAMyfM4tlrmYjSZKkIXEkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6hiTfEmSJKljTPIlSZKkjjHJlyRJkjrGJF+SJEnqGJN8SZIkqWNM8iVJkqSOMcmXJEmSOsYkX5IkSeoYk3xJkiSpY0zyJUmSpI4xyZckSZI6xiRfkiRJ6phU1bBj6JwkNwIXDTuODtoWuHbYQXSUfTsY9uvg2LeDYb8Ohv06OPYt7FhV2/UXbj6MSKaBi6pqwbCD6Joky+zXwbBvB8N+HRz7djDs18GwXwfHvh2f03UkSZKkjjHJlyRJkjrGJH8wFg87gI6yXwfHvh0M+3Vw7NvBsF8Hw34dHPt2HD54K0mSJHWMI/mSJElSx5jkS5IkSR1jki9JkiR1jEn+WiR5RZJLk9ya5LwkT1hL/flJvpnkliSXJ3lzkvTVeWLb1q1JfpnkZYO9iqlpsvs2yX5JaozXIwZ/NVPHRPo1yb2SLElyfpLVSZaOU897lsnvW+/ZxgT7db8kpyf5bZJVbf++aIx60/6enex+9X79own27a5Jzk5yVc/9+I4kW/bV856d5H6d9vdsVfka5wX8HbAa+AdgF+D9wE3Ag8epvw1wJfApYDfg2cCNwGt76uwE3Ny2tUvb9mrg2cO+3g707X5AAbsCD+h5zRj29U7hfr0P8CHgcOA0YOkYdbxnB9e33rMT79d/Bd4OPB54CPBy4A7geT11pv09O6B+nfb363r27c7AYcCjgB2BZwBXAe/uqeM9O5h+ndb37NADmMov4Fzgv/rKLgbeOU79lwO/B+7dU/ZG4HL+uJLRu4CL+447CThn2Nfbgb4d/ce87bCvb1Pp1756H2DsRNR7dnB96z27Af3aU/9TwGd7tqf9PTugfp329+sk9u17e+9H79mB9eu0vmedrjOO9tc9jwa+2rfrq8De4xy2F/Dtqrqlp+xMYAdgbk+d/jbPBBYk2WJDYt5UDLBvRy1rf+X89SRPmoSQNwnr2a/rwnt2cH07ynv27ibar9sA1/dsT+t7doD9Ompa3q8wOX2bZGfgAOCbPcXes4Pp11HT8p41yR/ftsAMml/99LqK5lc9Y3nAOPVH962pzubtOaeDQfXtb2lG/J8NPAu4CPh6kn03NOBNxPr067rwnh1c33rPbmC/JjkIeDJ3/4M40/2eHVS/Tvf7FTagb5N8L8mtNKPT36GZIjXKe3Yw/Tqt79nNhx3AJqD/r4VljLK11e8vX5c608Gk9m1VXUTzD3jUOUnmAkcC31r/MDc5E+3X9W1zrPKum9S+9Z79g/Xq1ySPBz4B/HNV/WAd2hyrvMsmtV+9X+9mffr274A/oZlD/h7g9cA719LmWOVdNqn9Ot3vWZP88V0L3Mk9v0Fuzz2/aY66cpz69BwzXp07gN+tV6SbnkH17VjOBZ4z0QA3UevTr+vCe3ZwfTsW79l16Nck+wBfAt5cVR/s2z3d79lB9etYptP9ChvQt1X16/bjBUlmACcleU9V3YH37KD6dSzT5p51us44qup24Dxg/75d+wPfG+ewc4AnJLlXX/0rgJGeOn85RpvLqmr1hsS8qRhg345ld5pf13XeevbruvCeHVzfjmV3vGfX2K/tr9q/DPx7VR03RpVpfc8OsF/HsjvT5H6FSf1vwWY0A60z2m3v2cH061h2Z7rcs8N+8ncqv2h+BXQ78BKa5ZyOp1nOacd2/zuBr/fUn0XzbfxUmmUen0WzIsxYS2ge17b5kvYc02aZrAH27auAvwHmAY9s2yjgWcO+3qnar23ZrjT/0TsVWNZ+3r1nv/fs4PrWe3bi/y3Yr70f38Pdl8TbrqfOtL9nB9Sv0/5+Xc++fQHwt8AjaJYn/b80K8Od2lPHe3Yw/Tqt79mhBzDVX8AraEaKb6P5lrlvz74lwEhf/fk087xupfmm+BbaJR576jwR+FHb5qXAy4Z9nV3oW+B1wCXALcB1wLeBvxr2dW4C/TrS/kfvbq++Ot6zA+hb79mJ92u7fY8+HaPvp/09O9n96v263n373PZevJEmaf0ZzcOh9+5r03t2kvt1ut+zo+uLS5IkSeoI5+RLkiRJHWOSL0mSJHWMSb4kSZLUMSb5kiRJUseY5EuSJEkdY5IvSZIkdYxJviRJktQxJvmSJElSx/x/jc6RpWH8Sw8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#用來放除了 label 外的 feature names\n",
    "names = []\n",
    "for feature_name in df.columns:\n",
    "    names.append(feature_name)\n",
    "\n",
    "#label不會是重要的屬性之一\n",
    "names.remove(\"label\")\n",
    "\n",
    "#將資料放入模型訓練\n",
    "clf1.fit(X,y)\n",
    "#調整字體大小\n",
    "plt.rc('font', size=14)\n",
    "#調整繪製圖的大小\n",
    "plt.figure(figsize=(12,12))\n",
    "#clf1.feature_importances_ 可以知道重要屬性是誰\n",
    "plt.barh(names, clf1.feature_importances_)\n",
    "#圖的標題\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "#畫出圖\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
