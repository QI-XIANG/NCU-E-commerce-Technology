{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 將資料集讀取為 DataFrame 格式，並將原始順序打亂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.064241</td>\n",
       "      <td>0.032027</td>\n",
       "      <td>0.015071</td>\n",
       "      <td>0.090193</td>\n",
       "      <td>0.075122</td>\n",
       "      <td>12.863462</td>\n",
       "      <td>274.402906</td>\n",
       "      <td>0.893369</td>\n",
       "      <td>0.491918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.059781</td>\n",
       "      <td>0.084279</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.067310</td>\n",
       "      <td>0.040229</td>\n",
       "      <td>0.019414</td>\n",
       "      <td>0.092666</td>\n",
       "      <td>0.073252</td>\n",
       "      <td>22.423285</td>\n",
       "      <td>634.613855</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.513724</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066009</td>\n",
       "      <td>0.107937</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.054688</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.036718</td>\n",
       "      <td>0.008701</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0.123207</td>\n",
       "      <td>30.757155</td>\n",
       "      <td>1024.927705</td>\n",
       "      <td>0.846389</td>\n",
       "      <td>0.478905</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.015656</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.007990</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.072111</td>\n",
       "      <td>0.158011</td>\n",
       "      <td>0.096582</td>\n",
       "      <td>0.207955</td>\n",
       "      <td>0.111374</td>\n",
       "      <td>1.232831</td>\n",
       "      <td>4.177296</td>\n",
       "      <td>0.963322</td>\n",
       "      <td>0.727232</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151228</td>\n",
       "      <td>0.088965</td>\n",
       "      <td>0.017798</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.201497</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.247119</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.079146</td>\n",
       "      <td>0.124656</td>\n",
       "      <td>0.078720</td>\n",
       "      <td>0.206045</td>\n",
       "      <td>0.127325</td>\n",
       "      <td>1.101174</td>\n",
       "      <td>4.333713</td>\n",
       "      <td>0.971955</td>\n",
       "      <td>0.783568</td>\n",
       "      <td>...</td>\n",
       "      <td>0.135120</td>\n",
       "      <td>0.106398</td>\n",
       "      <td>0.016931</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.712812</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>5.484375</td>\n",
       "      <td>5.476562</td>\n",
       "      <td>0.208274</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.153707</td>\n",
       "      <td>0.049285</td>\n",
       "      <td>0.201144</td>\n",
       "      <td>0.151859</td>\n",
       "      <td>1.762129</td>\n",
       "      <td>6.630383</td>\n",
       "      <td>0.962934</td>\n",
       "      <td>0.763182</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131884</td>\n",
       "      <td>0.182790</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.262295</td>\n",
       "      <td>0.832899</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>4.210938</td>\n",
       "      <td>4.203125</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.089221</td>\n",
       "      <td>0.076758</td>\n",
       "      <td>0.042718</td>\n",
       "      <td>0.204911</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>0.693730</td>\n",
       "      <td>2.503954</td>\n",
       "      <td>0.960716</td>\n",
       "      <td>0.709570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.116221</td>\n",
       "      <td>0.188980</td>\n",
       "      <td>0.034409</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.909856</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>3.679688</td>\n",
       "      <td>3.640625</td>\n",
       "      <td>0.277897</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.095798</td>\n",
       "      <td>0.183731</td>\n",
       "      <td>0.033424</td>\n",
       "      <td>0.224360</td>\n",
       "      <td>0.190936</td>\n",
       "      <td>1.876502</td>\n",
       "      <td>6.604509</td>\n",
       "      <td>0.946854</td>\n",
       "      <td>0.654196</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142056</td>\n",
       "      <td>0.209918</td>\n",
       "      <td>0.039506</td>\n",
       "      <td>0.275862</td>\n",
       "      <td>0.494271</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>2.937500</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>0.194759</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.090628</td>\n",
       "      <td>0.184976</td>\n",
       "      <td>0.043508</td>\n",
       "      <td>0.219943</td>\n",
       "      <td>0.176435</td>\n",
       "      <td>1.591065</td>\n",
       "      <td>5.388298</td>\n",
       "      <td>0.950436</td>\n",
       "      <td>0.675470</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143659</td>\n",
       "      <td>0.172375</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.791360</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>3.593750</td>\n",
       "      <td>3.585938</td>\n",
       "      <td>0.311002</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.092884</td>\n",
       "      <td>0.183044</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.250827</td>\n",
       "      <td>0.180756</td>\n",
       "      <td>1.705029</td>\n",
       "      <td>5.769115</td>\n",
       "      <td>0.938829</td>\n",
       "      <td>0.601529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165509</td>\n",
       "      <td>0.185607</td>\n",
       "      <td>0.062257</td>\n",
       "      <td>0.271186</td>\n",
       "      <td>0.227022</td>\n",
       "      <td>0.007812</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR       skew  \\\n",
       "0     0.059781  0.064241  0.032027  0.015071  0.090193  0.075122  12.863462   \n",
       "1     0.066009  0.067310  0.040229  0.019414  0.092666  0.073252  22.423285   \n",
       "2     0.077316  0.083829  0.036718  0.008701  0.131908  0.123207  30.757155   \n",
       "3     0.151228  0.072111  0.158011  0.096582  0.207955  0.111374   1.232831   \n",
       "4     0.135120  0.079146  0.124656  0.078720  0.206045  0.127325   1.101174   \n",
       "...        ...       ...       ...       ...       ...       ...        ...   \n",
       "3163  0.131884  0.084734  0.153707  0.049285  0.201144  0.151859   1.762129   \n",
       "3164  0.116221  0.089221  0.076758  0.042718  0.204911  0.162193   0.693730   \n",
       "3165  0.142056  0.095798  0.183731  0.033424  0.224360  0.190936   1.876502   \n",
       "3166  0.143659  0.090628  0.184976  0.043508  0.219943  0.176435   1.591065   \n",
       "3167  0.165509  0.092884  0.183044  0.070072  0.250827  0.180756   1.705029   \n",
       "\n",
       "             kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0      274.402906  0.893369  0.491918  ...  0.059781  0.084279  0.015702   \n",
       "1      634.613855  0.892193  0.513724  ...  0.066009  0.107937  0.015826   \n",
       "2     1024.927705  0.846389  0.478905  ...  0.077316  0.098706  0.015656   \n",
       "3        4.177296  0.963322  0.727232  ...  0.151228  0.088965  0.017798   \n",
       "4        4.333713  0.971955  0.783568  ...  0.135120  0.106398  0.016931   \n",
       "...           ...       ...       ...  ...       ...       ...       ...   \n",
       "3163     6.630383  0.962934  0.763182  ...  0.131884  0.182790  0.083770   \n",
       "3164     2.503954  0.960716  0.709570  ...  0.116221  0.188980  0.034409   \n",
       "3165     6.604509  0.946854  0.654196  ...  0.142056  0.209918  0.039506   \n",
       "3166     5.388298  0.950436  0.675470  ...  0.143659  0.172375  0.034483   \n",
       "3167     5.769115  0.938829  0.601529  ...  0.165509  0.185607  0.062257   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.275862  0.007812  0.007812  0.007812  0.000000  0.000000    male  \n",
       "1     0.250000  0.009014  0.007812  0.054688  0.046875  0.052632    male  \n",
       "2     0.271186  0.007990  0.007812  0.015625  0.007812  0.046512    male  \n",
       "3     0.250000  0.201497  0.007812  0.562500  0.554688  0.247119    male  \n",
       "4     0.266667  0.712812  0.007812  5.484375  5.476562  0.208274    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.262295  0.832899  0.007812  4.210938  4.203125  0.161929  female  \n",
       "3164  0.275862  0.909856  0.039062  3.679688  3.640625  0.277897  female  \n",
       "3165  0.275862  0.494271  0.007812  2.937500  2.929688  0.194759  female  \n",
       "3166  0.250000  0.791360  0.007812  3.593750  3.585938  0.311002  female  \n",
       "3167  0.271186  0.227022  0.007812  0.554688  0.546875  0.350000  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "#讀CSV檔\n",
    "df = pd.read_csv(\"gender_recog.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 檢查資料缺失與資料類別"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 21 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   meanfreq  3168 non-null   float64\n",
      " 1   sd        3168 non-null   float64\n",
      " 2   median    3168 non-null   float64\n",
      " 3   Q25       3168 non-null   float64\n",
      " 4   Q75       3168 non-null   float64\n",
      " 5   IQR       3168 non-null   float64\n",
      " 6   skew      3168 non-null   float64\n",
      " 7   kurt      3168 non-null   float64\n",
      " 8   sp.ent    3168 non-null   float64\n",
      " 9   sfm       3168 non-null   float64\n",
      " 10  mode      3168 non-null   float64\n",
      " 11  centroid  3168 non-null   float64\n",
      " 12  meanfun   3168 non-null   float64\n",
      " 13  minfun    3168 non-null   float64\n",
      " 14  maxfun    3168 non-null   float64\n",
      " 15  meandom   3168 non-null   float64\n",
      " 16  mindom    3168 non-null   float64\n",
      " 17  maxdom    3168 non-null   float64\n",
      " 18  dfrange   3168 non-null   float64\n",
      " 19  modindx   3168 non-null   float64\n",
      " 20  label     3168 non-null   object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 519.9+ KB\n"
     ]
    }
   ],
   "source": [
    "#列印欄位資訊\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 數值標準化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.049248</td>\n",
       "      <td>0.427355</td>\n",
       "      <td>-4.224901</td>\n",
       "      <td>-2.576102</td>\n",
       "      <td>-5.693607</td>\n",
       "      <td>-0.214778</td>\n",
       "      <td>2.293306</td>\n",
       "      <td>1.762946</td>\n",
       "      <td>-0.039083</td>\n",
       "      <td>0.471575</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.049248</td>\n",
       "      <td>-1.812038</td>\n",
       "      <td>-1.097998</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>-1.564205</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.431422</td>\n",
       "      <td>-1.419137</td>\n",
       "      <td>-1.454772</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.841053</td>\n",
       "      <td>0.611669</td>\n",
       "      <td>-3.999293</td>\n",
       "      <td>-2.486885</td>\n",
       "      <td>-5.588987</td>\n",
       "      <td>-0.258485</td>\n",
       "      <td>4.548056</td>\n",
       "      <td>4.433008</td>\n",
       "      <td>-0.065236</td>\n",
       "      <td>0.594431</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.841053</td>\n",
       "      <td>-1.079594</td>\n",
       "      <td>-1.091533</td>\n",
       "      <td>-0.294030</td>\n",
       "      <td>-1.561916</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.418107</td>\n",
       "      <td>-1.405818</td>\n",
       "      <td>-1.014103</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.463066</td>\n",
       "      <td>1.603848</td>\n",
       "      <td>-4.095851</td>\n",
       "      <td>-2.706986</td>\n",
       "      <td>-3.928699</td>\n",
       "      <td>0.909326</td>\n",
       "      <td>6.513656</td>\n",
       "      <td>7.326207</td>\n",
       "      <td>-1.083730</td>\n",
       "      <td>0.398261</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.463066</td>\n",
       "      <td>-1.365368</td>\n",
       "      <td>-1.100397</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>-1.563866</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.429203</td>\n",
       "      <td>-1.416917</td>\n",
       "      <td>-1.065344</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.992157</td>\n",
       "      <td>0.899998</td>\n",
       "      <td>-0.759454</td>\n",
       "      <td>-0.901418</td>\n",
       "      <td>-0.711205</td>\n",
       "      <td>0.632690</td>\n",
       "      <td>-0.449858</td>\n",
       "      <td>-0.240099</td>\n",
       "      <td>1.516383</td>\n",
       "      <td>1.797340</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.992157</td>\n",
       "      <td>-1.666966</td>\n",
       "      <td>-0.988934</td>\n",
       "      <td>-0.294030</td>\n",
       "      <td>-1.195367</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.273867</td>\n",
       "      <td>-1.261532</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.530640</td>\n",
       "      <td>1.322561</td>\n",
       "      <td>-1.676948</td>\n",
       "      <td>-1.268395</td>\n",
       "      <td>-0.792029</td>\n",
       "      <td>1.005588</td>\n",
       "      <td>-0.480911</td>\n",
       "      <td>-0.238940</td>\n",
       "      <td>1.708336</td>\n",
       "      <td>2.114740</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.530640</td>\n",
       "      <td>-1.127233</td>\n",
       "      <td>-1.034015</td>\n",
       "      <td>0.260185</td>\n",
       "      <td>-0.221660</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>0.124154</td>\n",
       "      <td>0.136933</td>\n",
       "      <td>0.289046</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3163</th>\n",
       "      <td>-1.638842</td>\n",
       "      <td>1.658182</td>\n",
       "      <td>-0.877839</td>\n",
       "      <td>-1.873163</td>\n",
       "      <td>-0.999378</td>\n",
       "      <td>1.579141</td>\n",
       "      <td>-0.325020</td>\n",
       "      <td>-0.221916</td>\n",
       "      <td>1.507749</td>\n",
       "      <td>1.999883</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.638842</td>\n",
       "      <td>1.237885</td>\n",
       "      <td>2.444087</td>\n",
       "      <td>0.114817</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.237556</td>\n",
       "      <td>-0.224892</td>\n",
       "      <td>-0.098989</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3164</th>\n",
       "      <td>-2.162452</td>\n",
       "      <td>1.927682</td>\n",
       "      <td>-2.994482</td>\n",
       "      <td>-2.008095</td>\n",
       "      <td>-0.840021</td>\n",
       "      <td>1.820721</td>\n",
       "      <td>-0.577009</td>\n",
       "      <td>-0.252503</td>\n",
       "      <td>1.458418</td>\n",
       "      <td>1.697831</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.162452</td>\n",
       "      <td>1.429532</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>0.153573</td>\n",
       "      <td>-0.214641</td>\n",
       "      <td>-0.388453</td>\n",
       "      <td>-0.384717</td>\n",
       "      <td>0.871981</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>-1.298773</td>\n",
       "      <td>2.322724</td>\n",
       "      <td>-0.051973</td>\n",
       "      <td>-2.199039</td>\n",
       "      <td>-0.017123</td>\n",
       "      <td>2.492666</td>\n",
       "      <td>-0.298044</td>\n",
       "      <td>-0.222108</td>\n",
       "      <td>1.150198</td>\n",
       "      <td>1.385857</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.298773</td>\n",
       "      <td>2.077781</td>\n",
       "      <td>0.140728</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>-0.637833</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.599266</td>\n",
       "      <td>-0.586717</td>\n",
       "      <td>0.175887</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>-1.245202</td>\n",
       "      <td>2.012196</td>\n",
       "      <td>-0.017728</td>\n",
       "      <td>-1.991852</td>\n",
       "      <td>-0.204021</td>\n",
       "      <td>2.153653</td>\n",
       "      <td>-0.365367</td>\n",
       "      <td>-0.231123</td>\n",
       "      <td>1.229850</td>\n",
       "      <td>1.505711</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.245202</td>\n",
       "      <td>0.915445</td>\n",
       "      <td>-0.120678</td>\n",
       "      <td>-0.294030</td>\n",
       "      <td>-0.072080</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.412863</td>\n",
       "      <td>-0.400255</td>\n",
       "      <td>1.149161</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>-0.514746</td>\n",
       "      <td>2.147651</td>\n",
       "      <td>-0.070879</td>\n",
       "      <td>-1.446089</td>\n",
       "      <td>1.102679</td>\n",
       "      <td>2.254671</td>\n",
       "      <td>-0.338487</td>\n",
       "      <td>-0.228300</td>\n",
       "      <td>0.971759</td>\n",
       "      <td>1.089126</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.514746</td>\n",
       "      <td>1.325111</td>\n",
       "      <td>1.324614</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>-1.146760</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.276086</td>\n",
       "      <td>-1.263752</td>\n",
       "      <td>1.475679</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "0    -4.049248  0.427355 -4.224901 -2.576102 -5.693607 -0.214778  2.293306   \n",
       "1    -3.841053  0.611669 -3.999293 -2.486885 -5.588987 -0.258485  4.548056   \n",
       "2    -3.463066  1.603848 -4.095851 -2.706986 -3.928699  0.909326  6.513656   \n",
       "3    -0.992157  0.899998 -0.759454 -0.901418 -0.711205  0.632690 -0.449858   \n",
       "4    -1.530640  1.322561 -1.676948 -1.268395 -0.792029  1.005588 -0.480911   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3163 -1.638842  1.658182 -0.877839 -1.873163 -0.999378  1.579141 -0.325020   \n",
       "3164 -2.162452  1.927682 -2.994482 -2.008095 -0.840021  1.820721 -0.577009   \n",
       "3165 -1.298773  2.322724 -0.051973 -2.199039 -0.017123  2.492666 -0.298044   \n",
       "3166 -1.245202  2.012196 -0.017728 -1.991852 -0.204021  2.153653 -0.365367   \n",
       "3167 -0.514746  2.147651 -0.070879 -1.446089  1.102679  2.254671 -0.338487   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "0     1.762946 -0.039083  0.471575  ... -4.049248 -1.812038 -1.097998   \n",
       "1     4.433008 -0.065236  0.594431  ... -3.841053 -1.079594 -1.091533   \n",
       "2     7.326207 -1.083730  0.398261  ... -3.463066 -1.365368 -1.100397   \n",
       "3    -0.240099  1.516383  1.797340  ... -0.992157 -1.666966 -0.988934   \n",
       "4    -0.238940  1.708336  2.114740  ... -1.530640 -1.127233 -1.034015   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3163 -0.221916  1.507749  1.999883  ... -1.638842  1.237885  2.444087   \n",
       "3164 -0.252503  1.458418  1.697831  ... -2.162452  1.429532 -0.124536   \n",
       "3165 -0.222108  1.150198  1.385857  ... -1.298773  2.077781  0.140728   \n",
       "3166 -0.231123  1.229850  1.505711  ... -1.245202  0.915445 -0.120678   \n",
       "3167 -0.228300  0.971759  1.089126  ... -0.514746  1.325111  1.324614   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "0     0.565959 -1.564205 -0.708404 -1.431422 -1.419137 -1.454772    male  \n",
       "1    -0.294030 -1.561916 -0.708404 -1.418107 -1.405818 -1.014103    male  \n",
       "2     0.410480 -1.563866 -0.708404 -1.429203 -1.416917 -1.065344    male  \n",
       "3    -0.294030 -1.195367 -0.708404 -1.273867 -1.261532  0.614286    male  \n",
       "4     0.260185 -0.221660 -0.708404  0.124154  0.136933  0.289046    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "3163  0.114817  0.007024 -0.708404 -0.237556 -0.224892 -0.098989  female  \n",
       "3164  0.565959  0.153573 -0.214641 -0.388453 -0.384717  0.871981  female  \n",
       "3165  0.565959 -0.637833 -0.708404 -0.599266 -0.586717  0.175887  female  \n",
       "3166 -0.294030 -0.072080 -0.708404 -0.412863 -0.400255  1.149161  female  \n",
       "3167  0.410480 -1.146760 -0.708404 -1.276086 -1.263752  1.475679  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#資料標準化\n",
    "scaler = StandardScaler().fit(df.drop('label',axis=1))\n",
    "#label不做標準化\n",
    "X_scaled = scaler.transform(df.drop('label',axis=1))\n",
    "#重新轉回 DataFrame\n",
    "X_scaled = pd.DataFrame(X_scaled,columns=df.columns[:20])\n",
    "#串接回 label 欄位\n",
    "X_scaled = pd.concat([X_scaled,pd.DataFrame(df['label'])],axis=1)\n",
    "#顯示目前的 DataFrame\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 將 DataFrame 內的資料打散\n",
    "\n",
    "(從 index 可以觀察到順序全部被打亂，每次 shuffle 都會不一樣)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meanfreq</th>\n",
       "      <th>sd</th>\n",
       "      <th>median</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q75</th>\n",
       "      <th>IQR</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>sp.ent</th>\n",
       "      <th>sfm</th>\n",
       "      <th>...</th>\n",
       "      <th>centroid</th>\n",
       "      <th>meanfun</th>\n",
       "      <th>minfun</th>\n",
       "      <th>maxfun</th>\n",
       "      <th>meandom</th>\n",
       "      <th>mindom</th>\n",
       "      <th>maxdom</th>\n",
       "      <th>dfrange</th>\n",
       "      <th>modindx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2518</th>\n",
       "      <td>0.966214</td>\n",
       "      <td>-1.417017</td>\n",
       "      <td>0.764072</td>\n",
       "      <td>1.086742</td>\n",
       "      <td>0.338559</td>\n",
       "      <td>-1.049457</td>\n",
       "      <td>-0.233476</td>\n",
       "      <td>-0.211553</td>\n",
       "      <td>-0.721947</td>\n",
       "      <td>-1.166627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.966214</td>\n",
       "      <td>0.876117</td>\n",
       "      <td>0.553107</td>\n",
       "      <td>0.672624</td>\n",
       "      <td>1.815255</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>0.962967</td>\n",
       "      <td>0.971572</td>\n",
       "      <td>-0.457633</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>-3.078091</td>\n",
       "      <td>0.762835</td>\n",
       "      <td>-3.175789</td>\n",
       "      <td>-2.321165</td>\n",
       "      <td>-3.442414</td>\n",
       "      <td>0.739019</td>\n",
       "      <td>-0.297573</td>\n",
       "      <td>-0.216162</td>\n",
       "      <td>1.205707</td>\n",
       "      <td>1.222385</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.078091</td>\n",
       "      <td>0.381985</td>\n",
       "      <td>-1.020767</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>-1.169086</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-1.251676</td>\n",
       "      <td>-1.239334</td>\n",
       "      <td>1.847926</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>0.255286</td>\n",
       "      <td>0.181057</td>\n",
       "      <td>0.171830</td>\n",
       "      <td>0.189908</td>\n",
       "      <td>0.570668</td>\n",
       "      <td>0.099234</td>\n",
       "      <td>-0.418778</td>\n",
       "      <td>-0.237793</td>\n",
       "      <td>0.516373</td>\n",
       "      <td>-0.016238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255286</td>\n",
       "      <td>-0.957207</td>\n",
       "      <td>0.543390</td>\n",
       "      <td>0.359819</td>\n",
       "      <td>-0.313503</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>0.383787</td>\n",
       "      <td>0.392208</td>\n",
       "      <td>-1.172998</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2494</th>\n",
       "      <td>1.006591</td>\n",
       "      <td>-0.313027</td>\n",
       "      <td>1.092478</td>\n",
       "      <td>1.388438</td>\n",
       "      <td>0.373613</td>\n",
       "      <td>-1.373367</td>\n",
       "      <td>0.124816</td>\n",
       "      <td>-0.128313</td>\n",
       "      <td>-1.086572</td>\n",
       "      <td>-0.535458</td>\n",
       "      <td>...</td>\n",
       "      <td>1.006591</td>\n",
       "      <td>1.282164</td>\n",
       "      <td>0.623340</td>\n",
       "      <td>0.618983</td>\n",
       "      <td>0.260993</td>\n",
       "      <td>-0.091201</td>\n",
       "      <td>0.330529</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>-0.962614</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>-0.721599</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>-0.111802</td>\n",
       "      <td>-0.859016</td>\n",
       "      <td>-1.119722</td>\n",
       "      <td>0.358722</td>\n",
       "      <td>-0.067537</td>\n",
       "      <td>-0.180964</td>\n",
       "      <td>-0.617989</td>\n",
       "      <td>-0.522094</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.721599</td>\n",
       "      <td>-1.316913</td>\n",
       "      <td>0.158133</td>\n",
       "      <td>0.380015</td>\n",
       "      <td>-0.664736</td>\n",
       "      <td>0.711164</td>\n",
       "      <td>-1.195089</td>\n",
       "      <td>-1.208257</td>\n",
       "      <td>3.059694</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>1.681175</td>\n",
       "      <td>-1.553561</td>\n",
       "      <td>1.358989</td>\n",
       "      <td>1.605196</td>\n",
       "      <td>1.170706</td>\n",
       "      <td>-1.179576</td>\n",
       "      <td>-0.225096</td>\n",
       "      <td>-0.215919</td>\n",
       "      <td>-1.577700</td>\n",
       "      <td>-1.430891</td>\n",
       "      <td>...</td>\n",
       "      <td>1.681175</td>\n",
       "      <td>1.519534</td>\n",
       "      <td>0.590242</td>\n",
       "      <td>0.513540</td>\n",
       "      <td>0.132168</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>-0.122164</td>\n",
       "      <td>-0.113903</td>\n",
       "      <td>-0.584785</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>0.166137</td>\n",
       "      <td>0.208401</td>\n",
       "      <td>0.214810</td>\n",
       "      <td>-0.041784</td>\n",
       "      <td>0.448365</td>\n",
       "      <td>0.295281</td>\n",
       "      <td>-0.551583</td>\n",
       "      <td>-0.248092</td>\n",
       "      <td>0.975918</td>\n",
       "      <td>0.561639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166137</td>\n",
       "      <td>-0.231563</td>\n",
       "      <td>0.565363</td>\n",
       "      <td>0.565959</td>\n",
       "      <td>0.186250</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>0.323872</td>\n",
       "      <td>0.332274</td>\n",
       "      <td>-0.118745</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3076</th>\n",
       "      <td>-0.661678</td>\n",
       "      <td>-0.195472</td>\n",
       "      <td>-0.402724</td>\n",
       "      <td>0.440485</td>\n",
       "      <td>-1.806659</td>\n",
       "      <td>-1.499444</td>\n",
       "      <td>0.580344</td>\n",
       "      <td>0.041956</td>\n",
       "      <td>-0.725242</td>\n",
       "      <td>0.026884</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.661678</td>\n",
       "      <td>0.510203</td>\n",
       "      <td>-1.296316</td>\n",
       "      <td>-1.532170</td>\n",
       "      <td>-1.241120</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>-1.374003</td>\n",
       "      <td>-1.374741</td>\n",
       "      <td>-0.083740</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>-1.671142</td>\n",
       "      <td>1.891689</td>\n",
       "      <td>-1.533888</td>\n",
       "      <td>-2.003982</td>\n",
       "      <td>-0.453913</td>\n",
       "      <td>2.029381</td>\n",
       "      <td>-0.141617</td>\n",
       "      <td>-0.122001</td>\n",
       "      <td>1.532965</td>\n",
       "      <td>1.858987</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.671142</td>\n",
       "      <td>-0.613973</td>\n",
       "      <td>-0.992014</td>\n",
       "      <td>-0.162074</td>\n",
       "      <td>-1.095789</td>\n",
       "      <td>-0.708404</td>\n",
       "      <td>-0.190955</td>\n",
       "      <td>-0.178277</td>\n",
       "      <td>-0.796675</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>1.820073</td>\n",
       "      <td>-1.609991</td>\n",
       "      <td>1.444396</td>\n",
       "      <td>1.807108</td>\n",
       "      <td>1.103260</td>\n",
       "      <td>-1.446583</td>\n",
       "      <td>-0.099073</td>\n",
       "      <td>-0.194010</td>\n",
       "      <td>-2.249469</td>\n",
       "      <td>-1.555109</td>\n",
       "      <td>...</td>\n",
       "      <td>1.820073</td>\n",
       "      <td>1.996788</td>\n",
       "      <td>0.540973</td>\n",
       "      <td>0.618983</td>\n",
       "      <td>1.727932</td>\n",
       "      <td>-0.461523</td>\n",
       "      <td>1.934925</td>\n",
       "      <td>1.943839</td>\n",
       "      <td>-0.667055</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3168 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      meanfreq        sd    median       Q25       Q75       IQR      skew  \\\n",
       "2518  0.966214 -1.417017  0.764072  1.086742  0.338559 -1.049457 -0.233476   \n",
       "1920 -3.078091  0.762835 -3.175789 -2.321165 -3.442414  0.739019 -0.297573   \n",
       "831   0.255286  0.181057  0.171830  0.189908  0.570668  0.099234 -0.418778   \n",
       "2494  1.006591 -0.313027  1.092478  1.388438  0.373613 -1.373367  0.124816   \n",
       "679  -0.721599  0.353422 -0.111802 -0.859016 -1.119722  0.358722 -0.067537   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2616  1.681175 -1.553561  1.358989  1.605196  1.170706 -1.179576 -0.225096   \n",
       "822   0.166137  0.208401  0.214810 -0.041784  0.448365  0.295281 -0.551583   \n",
       "3076 -0.661678 -0.195472 -0.402724  0.440485 -1.806659 -1.499444  0.580344   \n",
       "508  -1.671142  1.891689 -1.533888 -2.003982 -0.453913  2.029381 -0.141617   \n",
       "2846  1.820073 -1.609991  1.444396  1.807108  1.103260 -1.446583 -0.099073   \n",
       "\n",
       "          kurt    sp.ent       sfm  ...  centroid   meanfun    minfun  \\\n",
       "2518 -0.211553 -0.721947 -1.166627  ...  0.966214  0.876117  0.553107   \n",
       "1920 -0.216162  1.205707  1.222385  ... -3.078091  0.381985 -1.020767   \n",
       "831  -0.237793  0.516373 -0.016238  ...  0.255286 -0.957207  0.543390   \n",
       "2494 -0.128313 -1.086572 -0.535458  ...  1.006591  1.282164  0.623340   \n",
       "679  -0.180964 -0.617989 -0.522094  ... -0.721599 -1.316913  0.158133   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2616 -0.215919 -1.577700 -1.430891  ...  1.681175  1.519534  0.590242   \n",
       "822  -0.248092  0.975918  0.561639  ...  0.166137 -0.231563  0.565363   \n",
       "3076  0.041956 -0.725242  0.026884  ... -0.661678  0.510203 -1.296316   \n",
       "508  -0.122001  1.532965  1.858987  ... -1.671142 -0.613973 -0.992014   \n",
       "2846 -0.194010 -2.249469 -1.555109  ...  1.820073  1.996788  0.540973   \n",
       "\n",
       "        maxfun   meandom    mindom    maxdom   dfrange   modindx   label  \n",
       "2518  0.672624  1.815255 -0.461523  0.962967  0.971572 -0.457633  female  \n",
       "1920  0.410480 -1.169086 -0.708404 -1.251676 -1.239334  1.847926  female  \n",
       "831   0.359819 -0.313503 -0.461523  0.383787  0.392208 -1.172998    male  \n",
       "2494  0.618983  0.260993 -0.091201  0.330529  0.332274 -0.962614  female  \n",
       "679   0.380015 -0.664736  0.711164 -1.195089 -1.208257  3.059694    male  \n",
       "...        ...       ...       ...       ...       ...       ...     ...  \n",
       "2616  0.513540  0.132168 -0.461523 -0.122164 -0.113903 -0.584785  female  \n",
       "822   0.565959  0.186250 -0.461523  0.323872  0.332274 -0.118745    male  \n",
       "3076 -1.532170 -1.241120  0.016810 -1.374003 -1.374741 -0.083740  female  \n",
       "508  -0.162074 -1.095789 -0.708404 -0.190955 -0.178277 -0.796675    male  \n",
       "2846  0.618983  1.727932 -0.461523  1.934925  1.943839 -0.667055  female  \n",
       "\n",
       "[3168 rows x 21 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "#打散資料\n",
    "df_shuffle = shuffle(X_scaled)\n",
    "#顯示打散的資料\n",
    "df_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 使用 scikit learn 建立 RandomForest 分類器 ，並以 10 cross validation 評估模型在此資料集的分類表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(不特別調整模型參數的版本)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest 平均的 F1-score: 0.9801409971645041\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#data\n",
    "X = df_shuffle.drop(['label'], axis=1)\n",
    "#target\n",
    "y = df_shuffle['label']\n",
    "\n",
    "#定義交叉驗證方法\n",
    "cv = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "#定義 f1 score 要以哪一種類別做為判斷依據\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"female\")\n",
    "\n",
    "# 建立 RandomForest 分類器\n",
    "clf1 = RandomForestClassifier(random_state=0)\n",
    "\n",
    "#使用 k-fold 交叉驗證評估\n",
    "scores1 = cross_val_score(clf1, X, y, scoring=f1_scorer,cv=cv)\n",
    "\n",
    "#印出平均的 f1 score\n",
    "print(\"Random Forest 平均的 F1-score: \"+str(scores1.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 使用 scikit-learn 建立MLP 分類器，並以 10 cross validation 評估模型在此資料集 的分類表現 (評估指標：F1-score，請印出平均 F1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(不特別調整模型參數的版本)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn MLP 平均的 F1-score: 0.981101030223203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#data\n",
    "X = df_shuffle.drop(['label'], axis=1)\n",
    "#target\n",
    "y = df_shuffle['label']\n",
    "\n",
    "#定義交叉驗證方法\n",
    "cv = KFold(n_splits=10,shuffle=True)\n",
    "\n",
    "#定義 f1 score 要以哪一種類別做為判斷依據\n",
    "f1_scorer = make_scorer(f1_score, pos_label=\"female\")\n",
    "\n",
    "# 建立 MLP 分類器\n",
    "clf2 = MLPClassifier(random_state=0, max_iter=500,hidden_layer_sizes=(100,))\n",
    "\n",
    "#使用 k-fold 交叉驗證評估\n",
    "scores2 = cross_val_score(clf2, X, y, scoring=f1_scorer,cv=cv)\n",
    "\n",
    "#印出平均的 f1 score\n",
    "print(\"scikit-learn MLP 平均的 F1-score: \"+str(scores2.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 使用 Keras 建立MLP 分類器，並以 10 cross validation 評估模型在此資料集的分 類表現 (評估指標：F1-score，請印出平均 F1-score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.5276 - f1_m: 0.5654\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3941 - f1_m: 0.8912\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3176 - f1_m: 0.9379\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2641 - f1_m: 0.9539\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2258 - f1_m: 0.9638\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1986 - f1_m: 0.9671\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1772 - f1_m: 0.9666\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1609 - f1_m: 0.9670\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1471 - f1_m: 0.9707\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1359 - f1_m: 0.9684\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.1266 - f1_m: 0.9720\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.1189 - f1_m: 0.9662\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1124 - f1_m: 0.9715\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.1067 - f1_m: 0.9726\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1020 - f1_m: 0.9713\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0975 - f1_m: 0.9753\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0936 - f1_m: 0.9701\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0908 - f1_m: 0.9747\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0883 - f1_m: 0.9742\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0858 - f1_m: 0.9775\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0800 - f1_m: 0.9731\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0739 - f1_m: 0.9709\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0710 - f1_m: 0.9744\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0688 - f1_m: 0.9728\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0669 - f1_m: 0.9754\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0657 - f1_m: 0.9677\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0638 - f1_m: 0.9770\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0628 - f1_m: 0.9752\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0616 - f1_m: 0.9719\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0608 - f1_m: 0.9709\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0592 - f1_m: 0.9763\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0595 - f1_m: 0.9785\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0583 - f1_m: 0.9806\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0579 - f1_m: 0.9787\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0567 - f1_m: 0.9809\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0564 - f1_m: 0.9818: 0s - loss: 0.0597 - f1\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0566 - f1_m: 0.9837\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0562 - f1_m: 0.9778: 0s - loss: 0.0598 - f1_m: 0.98\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0556 - f1_m: 0.9826: 0s - loss: 0.0539 - \n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0549 - f1_m: 0.9814\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0545 - f1_m: 0.9787\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0548 - f1_m: 0.9782\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0541 - f1_m: 0.9795\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0537 - f1_m: 0.9693\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0533 - f1_m: 0.9790\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0534 - f1_m: 0.9833\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0531 - f1_m: 0.9791\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0529 - f1_m: 0.9814\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0525 - f1_m: 0.9786\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0521 - f1_m: 0.9825\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0524 - f1_m: 0.9835\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0520 - f1_m: 0.9796\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0519 - f1_m: 0.9803\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0522 - f1_m: 0.9796\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0513 - f1_m: 0.9783\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0511 - f1_m: 0.9838\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0514 - f1_m: 0.9777\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0505 - f1_m: 0.9782\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0509 - f1_m: 0.9823\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0500 - f1_m: 0.9820\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0502 - f1_m: 0.9796\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0500 - f1_m: 0.9792\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0498 - f1_m: 0.9841\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0493 - f1_m: 0.9810\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0492 - f1_m: 0.9788\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0493 - f1_m: 0.9773\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0484 - f1_m: 0.9850\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 2s 6ms/step - loss: 0.0487 - f1_m: 0.9841\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0480 - f1_m: 0.9773\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0479 - f1_m: 0.9862\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0486 - f1_m: 0.9848: \n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0478 - f1_m: 0.9808\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0475 - f1_m: 0.9815\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0473 - f1_m: 0.9867\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0470 - f1_m: 0.9769\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0469 - f1_m: 0.9861\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0476 - f1_m: 0.9815\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0472 - f1_m: 0.9861\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0467 - f1_m: 0.9828\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0466 - f1_m: 0.9858\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0459 - f1_m: 0.9826\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0466 - f1_m: 0.9808\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0454 - f1_m: 0.9850\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0467 - f1_m: 0.9830\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9855\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0463 - f1_m: 0.9813\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0459 - f1_m: 0.9844\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0460 - f1_m: 0.9845\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9796\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9857\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0458 - f1_m: 0.9848\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0456 - f1_m: 0.9852\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0450 - f1_m: 0.9858\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9820\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0453 - f1_m: 0.9856\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0457 - f1_m: 0.9855\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0446 - f1_m: 0.9814\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0445 - f1_m: 0.9803\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0445 - f1_m: 0.9802\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9813\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 3s 4ms/step - loss: 0.5927 - f1_m: 0.6585\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3571 - f1_m: 0.8386\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2175 - f1_m: 0.8682\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1600 - f1_m: 0.9261\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1280 - f1_m: 0.9560\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1020 - f1_m: 0.9641\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0910 - f1_m: 0.9633\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0862 - f1_m: 0.9652\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0849 - f1_m: 0.9647\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0826 - f1_m: 0.9648\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0810 - f1_m: 0.9651\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0797 - f1_m: 0.9666\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0781 - f1_m: 0.9646\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0771 - f1_m: 0.9687\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0768 - f1_m: 0.9679: 0s - loss: 0.0786 - f1_m: \n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0752 - f1_m: 0.9734\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0744 - f1_m: 0.9681\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0740 - f1_m: 0.9694\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0720 - f1_m: 0.9734\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0725 - f1_m: 0.9716\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0712 - f1_m: 0.9738\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0708 - f1_m: 0.9726\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0705 - f1_m: 0.9731\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0699 - f1_m: 0.9701\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0691 - f1_m: 0.9691\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0684 - f1_m: 0.9748\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0677 - f1_m: 0.9758\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0662 - f1_m: 0.9669\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0664 - f1_m: 0.9728: 0s - loss:\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0654 - f1_m: 0.9759\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0648 - f1_m: 0.9694\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0638 - f1_m: 0.9725\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0635 - f1_m: 0.9756\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0634 - f1_m: 0.9751\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0636 - f1_m: 0.9736\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0625 - f1_m: 0.9767\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9759\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0620 - f1_m: 0.9771\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0613 - f1_m: 0.9740\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0615 - f1_m: 0.9802\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0607 - f1_m: 0.9768\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0608 - f1_m: 0.9696\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9703\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0607 - f1_m: 0.9731\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0603 - f1_m: 0.9725\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9741\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9772\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0597 - f1_m: 0.9751\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0597 - f1_m: 0.9719\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0596 - f1_m: 0.9774\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0596 - f1_m: 0.9656\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0595 - f1_m: 0.9761\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0592 - f1_m: 0.9741\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0587 - f1_m: 0.9698\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0589 - f1_m: 0.9738\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0588 - f1_m: 0.9759\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0585 - f1_m: 0.9704\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0589 - f1_m: 0.9787\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0588 - f1_m: 0.9777\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0581 - f1_m: 0.9794\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0586 - f1_m: 0.9722\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0582 - f1_m: 0.9725\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0579 - f1_m: 0.9774\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0581 - f1_m: 0.9788\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0580 - f1_m: 0.9786\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0580 - f1_m: 0.9716\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0576 - f1_m: 0.9744\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0574 - f1_m: 0.9795\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0577 - f1_m: 0.9728\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0569 - f1_m: 0.9751\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0573 - f1_m: 0.9784\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0570 - f1_m: 0.9741\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0571 - f1_m: 0.9703\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0570 - f1_m: 0.9774\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9743\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9693\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0570 - f1_m: 0.9719\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0564 - f1_m: 0.9752\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0563 - f1_m: 0.9781\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9796\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0564 - f1_m: 0.9800\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0560 - f1_m: 0.9763\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0566 - f1_m: 0.9746\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9793\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0570 - f1_m: 0.9720\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9693\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0557 - f1_m: 0.9787\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0557 - f1_m: 0.9742\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0551 - f1_m: 0.9731\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0563 - f1_m: 0.9771\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0555 - f1_m: 0.9768\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0560 - f1_m: 0.9777\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0554 - f1_m: 0.9743\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9779\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0549 - f1_m: 0.9761\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0553 - f1_m: 0.9739\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0556 - f1_m: 0.9750\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0557 - f1_m: 0.9696\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0553 - f1_m: 0.9738\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0550 - f1_m: 0.9752\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 2ms/step - loss: 0.7041 - f1_m: 0.4899\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.5892 - f1_m: 0.6764\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3849 - f1_m: 0.8231\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2755 - f1_m: 0.8834\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2052 - f1_m: 0.8986\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1697 - f1_m: 0.8987\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1532 - f1_m: 0.9069\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1430 - f1_m: 0.9155\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1345 - f1_m: 0.9428\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1223 - f1_m: 0.9524\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0971 - f1_m: 0.9668\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0865 - f1_m: 0.9685\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0821 - f1_m: 0.9665\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0792 - f1_m: 0.9704\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0770 - f1_m: 0.9686\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0757 - f1_m: 0.9756\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0742 - f1_m: 0.9712\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0731 - f1_m: 0.9706\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0712 - f1_m: 0.9723\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0708 - f1_m: 0.9763\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0700 - f1_m: 0.9765\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0692 - f1_m: 0.9703\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0684 - f1_m: 0.9737\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0680 - f1_m: 0.9737\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0676 - f1_m: 0.9715\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0667 - f1_m: 0.9686\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0664 - f1_m: 0.9754\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0654 - f1_m: 0.9774\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0656 - f1_m: 0.9717\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0650 - f1_m: 0.9755\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0643 - f1_m: 0.9725\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0638 - f1_m: 0.9716\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0640 - f1_m: 0.9737\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0637 - f1_m: 0.9753\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0628 - f1_m: 0.9690\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0619 - f1_m: 0.9688\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0622 - f1_m: 0.9739\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9678\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0615 - f1_m: 0.9686\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0606 - f1_m: 0.9679\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0603 - f1_m: 0.9775: 0s - loss: 0.0635 - f1\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0605 - f1_m: 0.9765\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0603 - f1_m: 0.9738\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0593 - f1_m: 0.9737\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0597 - f1_m: 0.9767\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0589 - f1_m: 0.9686\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0590 - f1_m: 0.9788\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0583 - f1_m: 0.9776\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0581 - f1_m: 0.9790\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0576 - f1_m: 0.9765\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0577 - f1_m: 0.9804\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0574 - f1_m: 0.9762\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0573 - f1_m: 0.9760\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0564 - f1_m: 0.9747\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0565 - f1_m: 0.9777\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0565 - f1_m: 0.9768\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9748\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0564 - f1_m: 0.9770\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9801\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9791\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0554 - f1_m: 0.9772\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0555 - f1_m: 0.9749\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9757\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0549 - f1_m: 0.9776\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0547 - f1_m: 0.9757\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0546 - f1_m: 0.9720\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0547 - f1_m: 0.9774\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0542 - f1_m: 0.9711\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0539 - f1_m: 0.9835\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0537 - f1_m: 0.9766\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0534 - f1_m: 0.9782\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0531 - f1_m: 0.9727\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0533 - f1_m: 0.9793\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0531 - f1_m: 0.9801\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0525 - f1_m: 0.9802\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0523 - f1_m: 0.9808\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0520 - f1_m: 0.9751\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0515 - f1_m: 0.9779\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0513 - f1_m: 0.9777\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0511 - f1_m: 0.9722\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0507 - f1_m: 0.9743\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0503 - f1_m: 0.9787\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0499 - f1_m: 0.9815\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0498 - f1_m: 0.9790\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0496 - f1_m: 0.9767\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0497 - f1_m: 0.9743\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0494 - f1_m: 0.9779\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0491 - f1_m: 0.9805\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0491 - f1_m: 0.9793\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0482 - f1_m: 0.9840\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0487 - f1_m: 0.9848\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0478 - f1_m: 0.9842\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0484 - f1_m: 0.9804\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0487 - f1_m: 0.9779\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0481 - f1_m: 0.9808\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0480 - f1_m: 0.9817\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0476 - f1_m: 0.9848\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0482 - f1_m: 0.9798\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0482 - f1_m: 0.9805\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0474 - f1_m: 0.9822\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 3ms/step - loss: 0.5505 - f1_m: 0.7971\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3235 - f1_m: 0.8493\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2119 - f1_m: 0.8962\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1494 - f1_m: 0.9453\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1097 - f1_m: 0.9643\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0927 - f1_m: 0.9691\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0852 - f1_m: 0.9666\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0806 - f1_m: 0.9678\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0775 - f1_m: 0.9717\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0753 - f1_m: 0.9766\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0742 - f1_m: 0.9693\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0723 - f1_m: 0.9773\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0715 - f1_m: 0.9762\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0709 - f1_m: 0.9715\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0692 - f1_m: 0.9721\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0691 - f1_m: 0.9743\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0679 - f1_m: 0.9729\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0676 - f1_m: 0.9761\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0667 - f1_m: 0.9782\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0677 - f1_m: 0.9734\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0662 - f1_m: 0.9722\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0663 - f1_m: 0.9724: 0s - loss: 0.0578 - f1_m: \n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0666 - f1_m: 0.9763\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0652 - f1_m: 0.9752\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0647 - f1_m: 0.9792\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0652 - f1_m: 0.9797\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0633 - f1_m: 0.9700\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0644 - f1_m: 0.9761\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0637 - f1_m: 0.9756\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0636 - f1_m: 0.9725\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0632 - f1_m: 0.9812\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0631 - f1_m: 0.9790\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0635 - f1_m: 0.9755\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0628 - f1_m: 0.9763\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0630 - f1_m: 0.9806\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0625 - f1_m: 0.9777\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0626 - f1_m: 0.9743\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9728\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0621 - f1_m: 0.9780\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0617 - f1_m: 0.9786\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0616 - f1_m: 0.9743\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0615 - f1_m: 0.9794\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0613 - f1_m: 0.9700\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0616 - f1_m: 0.9799\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0610 - f1_m: 0.9805\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0611 - f1_m: 0.9749\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0605 - f1_m: 0.9739\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0610 - f1_m: 0.9785\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9753\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0597 - f1_m: 0.9791\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0602 - f1_m: 0.9719\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0592 - f1_m: 0.9719\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0596 - f1_m: 0.9727\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0592 - f1_m: 0.9786\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0596 - f1_m: 0.9764\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0591 - f1_m: 0.9787\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9811\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9762\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0579 - f1_m: 0.9777\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0582 - f1_m: 0.9745\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0586 - f1_m: 0.9791\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0577 - f1_m: 0.9731\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - f1_m: 0.9757\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0575 - f1_m: 0.9794\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0569 - f1_m: 0.9811\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0571 - f1_m: 0.9784\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0568 - f1_m: 0.9789\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0566 - f1_m: 0.9727\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0564 - f1_m: 0.9814\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0563 - f1_m: 0.9757\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0564 - f1_m: 0.9788\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - f1_m: 0.9795\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0557 - f1_m: 0.9769\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0558 - f1_m: 0.9736\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0553 - f1_m: 0.9775\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - f1_m: 0.9782\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0550 - f1_m: 0.9723\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0547 - f1_m: 0.9736\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0547 - f1_m: 0.9784\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0550 - f1_m: 0.9760\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0539 - f1_m: 0.9785\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0542 - f1_m: 0.9774\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0534 - f1_m: 0.9751\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0542 - f1_m: 0.9759\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0536 - f1_m: 0.9768\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0535 - f1_m: 0.9786\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0538 - f1_m: 0.9756\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0534 - f1_m: 0.9735\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0529 - f1_m: 0.9796\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9823\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0528 - f1_m: 0.9823\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9824\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0523 - f1_m: 0.9767\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0524 - f1_m: 0.9798\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0520 - f1_m: 0.9786\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0518 - f1_m: 0.9737\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0519 - f1_m: 0.9790\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0513 - f1_m: 0.9794\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0516 - f1_m: 0.9788\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0512 - f1_m: 0.9773\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 1ms/step - loss: 0.6424 - f1_m: 0.7147\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.4111 - f1_m: 0.8772\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.2263 - f1_m: 0.9462\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1410 - f1_m: 0.9639\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1040 - f1_m: 0.9715\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0861 - f1_m: 0.9693\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0809 - f1_m: 0.9713\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0773 - f1_m: 0.9685\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0760 - f1_m: 0.9757\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0748 - f1_m: 0.9722\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0739 - f1_m: 0.9672\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0731 - f1_m: 0.9712\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0722 - f1_m: 0.9721\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0722 - f1_m: 0.9771\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0706 - f1_m: 0.9724\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0704 - f1_m: 0.9747\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0693 - f1_m: 0.9758\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0691 - f1_m: 0.9763\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0685 - f1_m: 0.9741\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0678 - f1_m: 0.9710\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0674 - f1_m: 0.9740\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0664 - f1_m: 0.9735\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0663 - f1_m: 0.9747\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0652 - f1_m: 0.9768\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0648 - f1_m: 0.9803\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0644 - f1_m: 0.9761\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0641 - f1_m: 0.9750\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0638 - f1_m: 0.9778\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0633 - f1_m: 0.9772\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0630 - f1_m: 0.9707\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0631 - f1_m: 0.9749\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0621 - f1_m: 0.9760\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0621 - f1_m: 0.9718\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0616 - f1_m: 0.9756\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0610 - f1_m: 0.9753\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0611 - f1_m: 0.9751\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9717\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0601 - f1_m: 0.9789\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0610 - f1_m: 0.9766\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0592 - f1_m: 0.9803\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0594 - f1_m: 0.9786\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0591 - f1_m: 0.9736\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0588 - f1_m: 0.9815\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0587 - f1_m: 0.9739\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0582 - f1_m: 0.9740\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0579 - f1_m: 0.9763\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0575 - f1_m: 0.9727\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0570 - f1_m: 0.9715\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0574 - f1_m: 0.9691\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0572 - f1_m: 0.9776\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - f1_m: 0.9778\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0568 - f1_m: 0.9744\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0564 - f1_m: 0.9800\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0559 - f1_m: 0.9768\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0563 - f1_m: 0.9755\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0557 - f1_m: 0.9750\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0557 - f1_m: 0.9776\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0560 - f1_m: 0.9786\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0565 - f1_m: 0.9724\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0552 - f1_m: 0.9764\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0555 - f1_m: 0.9735\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0548 - f1_m: 0.9760\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0545 - f1_m: 0.9772\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0545 - f1_m: 0.9736\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0544 - f1_m: 0.9770\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9773\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0530 - f1_m: 0.9745\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9735\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0538 - f1_m: 0.9739\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0542 - f1_m: 0.9786\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0539 - f1_m: 0.9780\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9807\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9781\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0531 - f1_m: 0.9751\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0522 - f1_m: 0.9730\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0533 - f1_m: 0.9795\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0525 - f1_m: 0.9735\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0528 - f1_m: 0.9751\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0526 - f1_m: 0.9798\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0520 - f1_m: 0.9816\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0516 - f1_m: 0.9782\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0518 - f1_m: 0.9765\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0527 - f1_m: 0.9787\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0526 - f1_m: 0.9790\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0513 - f1_m: 0.9824\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0519 - f1_m: 0.9735\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0502 - f1_m: 0.9819\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0508 - f1_m: 0.9813\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0514 - f1_m: 0.9775\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0513 - f1_m: 0.9776\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0508 - f1_m: 0.9726\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0505 - f1_m: 0.9810\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0506 - f1_m: 0.9810\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0507 - f1_m: 0.9797\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9734\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0508 - f1_m: 0.9815\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0503 - f1_m: 0.9778\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0495 - f1_m: 0.9769\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0515 - f1_m: 0.9753\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0497 - f1_m: 0.9793\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 4ms/step - loss: 0.5978 - f1_m: 0.7263\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.3243 - f1_m: 0.8882\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1546 - f1_m: 0.9434\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.1057 - f1_m: 0.9615\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0903 - f1_m: 0.9607\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0837 - f1_m: 0.9701\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0794 - f1_m: 0.9714\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0769 - f1_m: 0.9693\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0749 - f1_m: 0.9725\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0730 - f1_m: 0.9752\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0717 - f1_m: 0.9685\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0710 - f1_m: 0.9718\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0701 - f1_m: 0.9724\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0691 - f1_m: 0.9759\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0686 - f1_m: 0.9702\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0678 - f1_m: 0.9675\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0667 - f1_m: 0.9703\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0659 - f1_m: 0.9702\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0653 - f1_m: 0.9761\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0646 - f1_m: 0.9723\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0642 - f1_m: 0.9719\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0638 - f1_m: 0.9710\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0631 - f1_m: 0.9773\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0622 - f1_m: 0.9750\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0615 - f1_m: 0.9738\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0613 - f1_m: 0.9702\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0613 - f1_m: 0.9742\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0603 - f1_m: 0.9707\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0591 - f1_m: 0.9661\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0590 - f1_m: 0.9775\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0585 - f1_m: 0.9719\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0581 - f1_m: 0.9771\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0581 - f1_m: 0.9719\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0570 - f1_m: 0.9797\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0571 - f1_m: 0.9788\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0565 - f1_m: 0.9807\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0562 - f1_m: 0.9764\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0548 - f1_m: 0.9751\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0554 - f1_m: 0.9795\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0550 - f1_m: 0.9704\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0549 - f1_m: 0.9771\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0542 - f1_m: 0.9813\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0541 - f1_m: 0.9758\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0537 - f1_m: 0.9820\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9813\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0530 - f1_m: 0.9819\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0536 - f1_m: 0.9806\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0529 - f1_m: 0.9761\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0529 - f1_m: 0.9802\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0527 - f1_m: 0.9784\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0524 - f1_m: 0.9762\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0525 - f1_m: 0.9788\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0523 - f1_m: 0.9722\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0520 - f1_m: 0.9761\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0517 - f1_m: 0.9747\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0519 - f1_m: 0.9757\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0515 - f1_m: 0.9785\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0516 - f1_m: 0.9806\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0511 - f1_m: 0.9778\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9768\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0513 - f1_m: 0.9724: 0s - loss: 0.0518 - f1_m: \n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0503 - f1_m: 0.9831\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0507 - f1_m: 0.9822\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0504 - f1_m: 0.9810\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0499 - f1_m: 0.9788\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0509 - f1_m: 0.9809\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0501 - f1_m: 0.9781\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0498 - f1_m: 0.9784\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0502 - f1_m: 0.9763\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0503 - f1_m: 0.9756\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0500 - f1_m: 0.9734\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0496 - f1_m: 0.9777\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9774\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0498 - f1_m: 0.9801\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0495 - f1_m: 0.9830\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0496 - f1_m: 0.9795\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0497 - f1_m: 0.9831\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0491 - f1_m: 0.9801\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0493 - f1_m: 0.9747\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0506 - f1_m: 0.9768\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0487 - f1_m: 0.9764\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0488 - f1_m: 0.9813\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0489 - f1_m: 0.9788\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9749\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9804\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0490 - f1_m: 0.9762\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0482 - f1_m: 0.9810\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0485 - f1_m: 0.9746\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0483 - f1_m: 0.9829\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0485 - f1_m: 0.9762\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0483 - f1_m: 0.9818\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0483 - f1_m: 0.9754\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9793\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0485 - f1_m: 0.9780\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0480 - f1_m: 0.9717\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0482 - f1_m: 0.9788\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0480 - f1_m: 0.9842\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0484 - f1_m: 0.9831\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0477 - f1_m: 0.9786\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0482 - f1_m: 0.9812\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 1ms/step - loss: 0.5617 - f1_m: 0.7096\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2915 - f1_m: 0.8931\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1791 - f1_m: 0.9334\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1207 - f1_m: 0.9607\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0984 - f1_m: 0.9619\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0891 - f1_m: 0.9627\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0845 - f1_m: 0.9690\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0822 - f1_m: 0.9695\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0796 - f1_m: 0.9682\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0770 - f1_m: 0.9659\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0755 - f1_m: 0.9623\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0742 - f1_m: 0.9634\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0719 - f1_m: 0.9681\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0700 - f1_m: 0.9723\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0691 - f1_m: 0.9749\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0681 - f1_m: 0.9719\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0673 - f1_m: 0.9747\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0665 - f1_m: 0.9703\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0654 - f1_m: 0.9763\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0645 - f1_m: 0.9700\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0642 - f1_m: 0.9740\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0639 - f1_m: 0.9774\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0627 - f1_m: 0.9704\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0616 - f1_m: 0.9734\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0611 - f1_m: 0.9612\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0605 - f1_m: 0.9723\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0602 - f1_m: 0.9729\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0598 - f1_m: 0.9779\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0593 - f1_m: 0.9785: 0s - loss: 0.0570 - f1_m\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0584 - f1_m: 0.9771\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0586 - f1_m: 0.9734\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0576 - f1_m: 0.9757\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0572 - f1_m: 0.9697\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0568 - f1_m: 0.9720\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0561 - f1_m: 0.9719\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0561 - f1_m: 0.9756\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0556 - f1_m: 0.9767\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0545 - f1_m: 0.9801\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0544 - f1_m: 0.9758\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0542 - f1_m: 0.9754\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0532 - f1_m: 0.9774\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0535 - f1_m: 0.9639\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0532 - f1_m: 0.9748\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0525 - f1_m: 0.9746\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0518 - f1_m: 0.9724\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0523 - f1_m: 0.9795: 0s - los\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0511 - f1_m: 0.9791\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0517 - f1_m: 0.9769\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0516 - f1_m: 0.9790\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0514 - f1_m: 0.9741\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0503 - f1_m: 0.9750\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0500 - f1_m: 0.9770\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0500 - f1_m: 0.9712\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0501 - f1_m: 0.9736\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0498 - f1_m: 0.9750\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0496 - f1_m: 0.9720\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0497 - f1_m: 0.9758\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0488 - f1_m: 0.9789\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0484 - f1_m: 0.9812\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0487 - f1_m: 0.9806\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0490 - f1_m: 0.9793\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0484 - f1_m: 0.9754\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0477 - f1_m: 0.9782\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0474 - f1_m: 0.9769\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0477 - f1_m: 0.9791\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0484 - f1_m: 0.9762: 0s - loss: 0.0471 - f1_m\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0468 - f1_m: 0.9798\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0473 - f1_m: 0.9743\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0479 - f1_m: 0.9716\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0462 - f1_m: 0.9825\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0468 - f1_m: 0.9763\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0464 - f1_m: 0.9777\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0468 - f1_m: 0.9769: 0s - loss: 0.0438 - f1_m\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0460 - f1_m: 0.9764\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0462 - f1_m: 0.9765\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0463 - f1_m: 0.9789\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0473 - f1_m: 0.9795\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0458 - f1_m: 0.9828\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0457 - f1_m: 0.9804\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0448 - f1_m: 0.9791\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9828\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0446 - f1_m: 0.9830\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0452 - f1_m: 0.9770\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0457 - f1_m: 0.9832\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0451 - f1_m: 0.9808\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0451 - f1_m: 0.9807\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0452 - f1_m: 0.9828\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0446 - f1_m: 0.9772\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0448 - f1_m: 0.9780\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0443 - f1_m: 0.9760\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0449 - f1_m: 0.9805\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0444 - f1_m: 0.9790\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0445 - f1_m: 0.9742\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0435 - f1_m: 0.9829\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0452 - f1_m: 0.9786\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0445 - f1_m: 0.9775\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0445 - f1_m: 0.9796\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0441 - f1_m: 0.9751\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0440 - f1_m: 0.9792\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0442 - f1_m: 0.9779\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 3ms/step - loss: 0.6346 - f1_m: 0.6908\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.3466 - f1_m: 0.9269\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1490 - f1_m: 0.9651\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0928 - f1_m: 0.9736\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0815 - f1_m: 0.9720\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0769 - f1_m: 0.9714\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0730 - f1_m: 0.9788\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0716 - f1_m: 0.9739\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0697 - f1_m: 0.9732\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0691 - f1_m: 0.9762\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0679 - f1_m: 0.9750\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0670 - f1_m: 0.9761\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0662 - f1_m: 0.9746\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0654 - f1_m: 0.9774\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0648 - f1_m: 0.9794\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0631 - f1_m: 0.9779\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0633 - f1_m: 0.9757\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0628 - f1_m: 0.9790\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0625 - f1_m: 0.9708\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0618 - f1_m: 0.9796\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0621 - f1_m: 0.9757\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0618 - f1_m: 0.9708\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0615 - f1_m: 0.9798\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0611 - f1_m: 0.9774\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0606 - f1_m: 0.9724: 0s - loss: 0\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0597 - f1_m: 0.9795\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0608 - f1_m: 0.9774\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0599 - f1_m: 0.9782\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0598 - f1_m: 0.9809\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0593 - f1_m: 0.9762\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0592 - f1_m: 0.9811\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0589 - f1_m: 0.9790\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0585 - f1_m: 0.9790\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9799\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0583 - f1_m: 0.9802\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0582 - f1_m: 0.9760\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0588 - f1_m: 0.9740: 0s - loss: 0\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0582 - f1_m: 0.9723\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0576 - f1_m: 0.9759\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0573 - f1_m: 0.9770\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0574 - f1_m: 0.9759\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0569 - f1_m: 0.9753\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0556 - f1_m: 0.9804\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0567 - f1_m: 0.9757\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0567 - f1_m: 0.9731\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0572 - f1_m: 0.9656\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0571 - f1_m: 0.9761\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0558 - f1_m: 0.9771\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0557 - f1_m: 0.9767\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0555 - f1_m: 0.9726\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0558 - f1_m: 0.9747\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9729\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0551 - f1_m: 0.9794\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0549 - f1_m: 0.9825\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0542 - f1_m: 0.9791\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9762\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0540 - f1_m: 0.9694\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0543 - f1_m: 0.9708\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0542 - f1_m: 0.9777\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0542 - f1_m: 0.9698\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0536 - f1_m: 0.9714\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0534 - f1_m: 0.9812\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0532 - f1_m: 0.9783\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0535 - f1_m: 0.9799\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0530 - f1_m: 0.9768\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0523 - f1_m: 0.9784\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0532 - f1_m: 0.9759\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9753\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0530 - f1_m: 0.9820\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0526 - f1_m: 0.9770\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0521 - f1_m: 0.9749\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0514 - f1_m: 0.9776\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0516 - f1_m: 0.9839\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0514 - f1_m: 0.9799\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0513 - f1_m: 0.9795\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0530 - f1_m: 0.9779\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0533 - f1_m: 0.9798\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0511 - f1_m: 0.9763\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0509 - f1_m: 0.9782\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0513 - f1_m: 0.9760\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0507 - f1_m: 0.9774\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0505 - f1_m: 0.9773\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0513 - f1_m: 0.9757\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0508 - f1_m: 0.9820\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0510 - f1_m: 0.9762\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0509 - f1_m: 0.9764\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0517 - f1_m: 0.9814\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0501 - f1_m: 0.9846\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0514 - f1_m: 0.9775\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0509 - f1_m: 0.9781\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0500 - f1_m: 0.9787\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0500 - f1_m: 0.9800\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0502 - f1_m: 0.9835\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0504 - f1_m: 0.9798\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0497 - f1_m: 0.9772\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0500 - f1_m: 0.9801\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0499 - f1_m: 0.9812\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0501 - f1_m: 0.9717\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0499 - f1_m: 0.9795\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0492 - f1_m: 0.9815\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 2s 4ms/step - loss: 0.5129 - f1_m: 0.7092\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.2560 - f1_m: 0.9065\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1338 - f1_m: 0.9542\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0964 - f1_m: 0.9614\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0819 - f1_m: 0.9700\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0757 - f1_m: 0.9653\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0721 - f1_m: 0.9705\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0691 - f1_m: 0.9679\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0670 - f1_m: 0.9746\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0659 - f1_m: 0.9748\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0650 - f1_m: 0.9714\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0635 - f1_m: 0.9791\n",
      "Epoch 13/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0630 - f1_m: 0.9719\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0621 - f1_m: 0.9770\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0613 - f1_m: 0.9741\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0608 - f1_m: 0.9768\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0605 - f1_m: 0.9738\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0594 - f1_m: 0.9757\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0592 - f1_m: 0.9776\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0587 - f1_m: 0.9784\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0579 - f1_m: 0.9783\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0578 - f1_m: 0.9693\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0568 - f1_m: 0.9752\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0570 - f1_m: 0.9763\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0566 - f1_m: 0.9777\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0560 - f1_m: 0.9734\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0562 - f1_m: 0.9714\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0560 - f1_m: 0.9733\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0560 - f1_m: 0.9766\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0551 - f1_m: 0.9805\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0548 - f1_m: 0.9757\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0548 - f1_m: 0.9777\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0548 - f1_m: 0.9733\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0547 - f1_m: 0.9747\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0548 - f1_m: 0.9721\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0544 - f1_m: 0.9771\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0536 - f1_m: 0.9754\n",
      "Epoch 38/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0537 - f1_m: 0.9784\n",
      "Epoch 39/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0536 - f1_m: 0.9730\n",
      "Epoch 40/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0533 - f1_m: 0.9782\n",
      "Epoch 41/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0537 - f1_m: 0.9783\n",
      "Epoch 42/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0528 - f1_m: 0.9769\n",
      "Epoch 43/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0519 - f1_m: 0.9770\n",
      "Epoch 44/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0534 - f1_m: 0.9751\n",
      "Epoch 45/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0524 - f1_m: 0.9786\n",
      "Epoch 46/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0529 - f1_m: 0.9740\n",
      "Epoch 47/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0515 - f1_m: 0.9758\n",
      "Epoch 48/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0519 - f1_m: 0.9721\n",
      "Epoch 49/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0513 - f1_m: 0.9775\n",
      "Epoch 50/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0520 - f1_m: 0.9777\n",
      "Epoch 51/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0512 - f1_m: 0.9759\n",
      "Epoch 52/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0515 - f1_m: 0.9800\n",
      "Epoch 53/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0515 - f1_m: 0.9736\n",
      "Epoch 54/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0508 - f1_m: 0.9784\n",
      "Epoch 55/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0498 - f1_m: 0.9770\n",
      "Epoch 56/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0498 - f1_m: 0.9756\n",
      "Epoch 57/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0496 - f1_m: 0.9799\n",
      "Epoch 58/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0505 - f1_m: 0.9785\n",
      "Epoch 59/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0499 - f1_m: 0.9749\n",
      "Epoch 60/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0497 - f1_m: 0.9697\n",
      "Epoch 61/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0496 - f1_m: 0.9800\n",
      "Epoch 62/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0495 - f1_m: 0.9728\n",
      "Epoch 63/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0495 - f1_m: 0.9777\n",
      "Epoch 64/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0485 - f1_m: 0.9718\n",
      "Epoch 65/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0487 - f1_m: 0.9799\n",
      "Epoch 66/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0487 - f1_m: 0.9698\n",
      "Epoch 67/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0478 - f1_m: 0.9795\n",
      "Epoch 68/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0476 - f1_m: 0.9782\n",
      "Epoch 69/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0486 - f1_m: 0.9699\n",
      "Epoch 70/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0476 - f1_m: 0.9806\n",
      "Epoch 71/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0479 - f1_m: 0.9771\n",
      "Epoch 72/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0471 - f1_m: 0.9771\n",
      "Epoch 73/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0473 - f1_m: 0.9743\n",
      "Epoch 74/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0468 - f1_m: 0.9830\n",
      "Epoch 75/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0466 - f1_m: 0.9783\n",
      "Epoch 76/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0465 - f1_m: 0.9749\n",
      "Epoch 77/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0473 - f1_m: 0.9805\n",
      "Epoch 78/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0464 - f1_m: 0.9802\n",
      "Epoch 79/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0465 - f1_m: 0.9748\n",
      "Epoch 80/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0459 - f1_m: 0.9797\n",
      "Epoch 81/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0458 - f1_m: 0.9776\n",
      "Epoch 82/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0464 - f1_m: 0.9767\n",
      "Epoch 83/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0455 - f1_m: 0.9785\n",
      "Epoch 84/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0453 - f1_m: 0.9788\n",
      "Epoch 85/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0474 - f1_m: 0.9810\n",
      "Epoch 86/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0455 - f1_m: 0.9805\n",
      "Epoch 87/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0456 - f1_m: 0.9780\n",
      "Epoch 88/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0454 - f1_m: 0.9794\n",
      "Epoch 89/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0449 - f1_m: 0.9763\n",
      "Epoch 90/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0469 - f1_m: 0.9777\n",
      "Epoch 91/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0460 - f1_m: 0.9781\n",
      "Epoch 92/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0448 - f1_m: 0.9762\n",
      "Epoch 93/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0449 - f1_m: 0.9784\n",
      "Epoch 94/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0441 - f1_m: 0.9794\n",
      "Epoch 95/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0443 - f1_m: 0.9818\n",
      "Epoch 96/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0450 - f1_m: 0.9731\n",
      "Epoch 97/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0447 - f1_m: 0.9755\n",
      "Epoch 98/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0453 - f1_m: 0.9789\n",
      "Epoch 99/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0450 - f1_m: 0.9799\n",
      "Epoch 100/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0443 - f1_m: 0.9758\n",
      "Epoch 1/100\n",
      "286/286 [==============================] - 1s 1ms/step - loss: 0.6251 - f1_m: 0.7661\n",
      "Epoch 2/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.4208 - f1_m: 0.8631\n",
      "Epoch 3/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.2426 - f1_m: 0.9251\n",
      "Epoch 4/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1524 - f1_m: 0.9592\n",
      "Epoch 5/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.1167 - f1_m: 0.9620\n",
      "Epoch 6/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.1020 - f1_m: 0.9677\n",
      "Epoch 7/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0945 - f1_m: 0.9673\n",
      "Epoch 8/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0898 - f1_m: 0.9646\n",
      "Epoch 9/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0863 - f1_m: 0.9674\n",
      "Epoch 10/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0841 - f1_m: 0.9721\n",
      "Epoch 11/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0824 - f1_m: 0.9672\n",
      "Epoch 12/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0806 - f1_m: 0.9723\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0792 - f1_m: 0.9727\n",
      "Epoch 14/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0787 - f1_m: 0.9659\n",
      "Epoch 15/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0774 - f1_m: 0.9717\n",
      "Epoch 16/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0768 - f1_m: 0.9740\n",
      "Epoch 17/100\n",
      "286/286 [==============================] - 1s 5ms/step - loss: 0.0756 - f1_m: 0.9743\n",
      "Epoch 18/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0755 - f1_m: 0.9740\n",
      "Epoch 19/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0742 - f1_m: 0.9749\n",
      "Epoch 20/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0738 - f1_m: 0.9731\n",
      "Epoch 21/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0734 - f1_m: 0.9732\n",
      "Epoch 22/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0729 - f1_m: 0.9771\n",
      "Epoch 23/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0725 - f1_m: 0.9733\n",
      "Epoch 24/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0719 - f1_m: 0.9746\n",
      "Epoch 25/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0713 - f1_m: 0.9746\n",
      "Epoch 26/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0705 - f1_m: 0.9756\n",
      "Epoch 27/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0700 - f1_m: 0.9757\n",
      "Epoch 28/100\n",
      "286/286 [==============================] - 1s 4ms/step - loss: 0.0701 - f1_m: 0.9728\n",
      "Epoch 29/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0690 - f1_m: 0.9762\n",
      "Epoch 30/100\n",
      "286/286 [==============================] - 1s 3ms/step - loss: 0.0693 - f1_m: 0.9772\n",
      "Epoch 31/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0686 - f1_m: 0.9770\n",
      "Epoch 32/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0682 - f1_m: 0.9731\n",
      "Epoch 33/100\n",
      "286/286 [==============================] - 1s 2ms/step - loss: 0.0676 - f1_m: 0.9768\n",
      "Epoch 34/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0680 - f1_m: 0.9690\n",
      "Epoch 35/100\n",
      "286/286 [==============================] - 0s 2ms/step - loss: 0.0677 - f1_m: 0.9763\n",
      "Epoch 36/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0672 - f1_m: 0.9776\n",
      "Epoch 37/100\n",
      "286/286 [==============================] - 0s 1ms/step - loss: 0.0671 - f1_m: 0.9786\n",
      "Epoch 38/100\n",
      "209/286 [====================>.........] - ETA: 0s - loss: 0.0654 - f1_m: 0.9747"
     ]
    }
   ],
   "source": [
    "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras import backend as K\n",
    "import numpy\n",
    "\n",
    "seed = 0\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#資料編碼器\n",
    "labelencoder = LabelEncoder()\n",
    "#複製成新的 DataFrame\n",
    "data_le = pd.DataFrame(df_shuffle)\n",
    "#針對 label 進行編碼 female: 0 male: 1 \n",
    "data_le['label'] = labelencoder.fit_transform(data_le['label'])\n",
    "\n",
    "#將 data 跟 target 都轉成 numpy\n",
    "X = data_le.drop(['label'], axis=1).to_numpy()\n",
    "y = data_le['label'].to_numpy()\n",
    "\n",
    "#定義如何計算 metrics 的 recall \n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "#定義如何計算 metrics 的 precision \n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "#定義如何計算 metrics 的 f1 score \n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# 定義 10 fold 方法\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=0)\n",
    "#用來存放 10 fold 的 f1 score\n",
    "cvscores = [[],[]]\n",
    "\n",
    "for train, test in kfold.split(X, y): #不是用分層抽樣的 k fold\n",
    "    # 建立模型\n",
    "    model = Sequential()\n",
    "    # hidden layer\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    # output layer\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # 編譯模型\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[f1_m])\n",
    "    # Fit the model\n",
    "    model.fit(X[train], y[train], epochs=100, batch_size=10)\n",
    "    # 評估模型\n",
    "    scores = model.evaluate(X[test], y[test], verbose=0)\n",
    "    cvscores[0].append(scores[1])\n",
    "    \n",
    "print(\"Keras MLP 平均的 F1-score: \" + str(numpy.mean(cvscores[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Keras MLP 平均的 F1-score: \" + str(numpy.mean(cvscores[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 請問你在上述 3 題所使用的 F1-score 是以哪一類別為依據 (male、female、兩者平均)\n",
    "\n",
    "## Ans: 上述2、3題所使用的 F1-score 是以 female 類別為依據，第4題則以平均作為依據"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. 以 t-test 比較上述三個模型的表現，並簡述結論\n",
    "\n",
    "## 做完 t-test 檢驗後，從統計學的角度來看，p-value 均大於 0.05，我們沒證據拒絕虛無假說，也就是兩兩的 F1-score 均值相等，結論是套用哪一種模型其實不影響結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores1 : 存放 Random Forest F1-score 們\n",
    "scores1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores2 : 存放 scikit-learn MLP F1-score 們\n",
    "scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cvscores : 存放 Keras MLP F1-score 們\n",
    "numpy.array(cvscores[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_rel\n",
    "import numpy as np\n",
    "\n",
    "print(\"Random Forest 與 scikit-learn MLP 比較\")\n",
    "print(\"t-test 檢驗結果: \")\n",
    "print(ttest_rel(scores1,scores2))\n",
    "print(\"=\"*80)\n",
    "print(\"scikit-learn MLP 與 Keras MLP 比較\")\n",
    "print(\"t-test 檢驗結果: \")\n",
    "print(ttest_rel(scores2,numpy.array(cvscores[0])))\n",
    "print(\"=\"*80)\n",
    "print(\"Keras MLP 與 Random Forest 比較\")\n",
    "print(\"t-test 檢驗結果: \")\n",
    "print(ttest_rel(numpy.array(cvscores[0]),scores1))\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. 有某新資料各屬性值如下，請判斷此聲音的性別：\n",
    "\n",
    "![](https://i.imgur.com/M1ByrTN.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 用第2題的模型做判斷\n",
    "\n",
    "### Ans: male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#資料編碼器\n",
    "labelencoder = LabelEncoder()\n",
    "\n",
    "#複製成新的 DataFrame\n",
    "data_le = pd.DataFrame(df_shuffle)\n",
    "\n",
    "#針對 label 進行編碼 female: 0 male: 1 \n",
    "data_le['label'] = labelencoder.fit_transform(data_le['label'])\n",
    "\n",
    "#data\n",
    "X = df.drop(['label'], axis=1)\n",
    "#target\n",
    "y = df['label']\n",
    "\n",
    "#建立 RandomForest 分類器\n",
    "clf1 = RandomForestClassifier(random_state=0)\n",
    "\n",
    "#放入訓練資料 all data\n",
    "clf1.fit(X,y)\n",
    "\n",
    "#匯入欲判別的資料\n",
    "test_data = pd.DataFrame([[0.1528, 0.0735, 0.1490, 0.0479, 0.2095,\n",
    "                  0.1416,1.5325,7.3388,0.9631,0.7383,0.1325,\n",
    "                  0.1427,0.1101,0.0111,0.2539,0.2982, 0.0078,\n",
    "                  2.7235,2.7184,0.1251]],columns=df.columns[:20])\n",
    "\n",
    "#預測\n",
    "print(\"預測結果: \"+str(clf1.predict(test_data)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. 哪一個屬性 在 RandomForest 的分類中最重要\n",
    "\n",
    "## Ans: meanfun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#用來放除了 label 外的 feature names\n",
    "names = []\n",
    "for feature_name in df.columns:\n",
    "    names.append(feature_name)\n",
    "\n",
    "#label不會是重要的屬性之一\n",
    "names.remove(\"label\")\n",
    "\n",
    "#將資料放入模型訓練\n",
    "clf1.fit(X,y)\n",
    "#調整字體大小\n",
    "plt.rc('font', size=14)\n",
    "#調整繪製圖的大小\n",
    "plt.figure(figsize=(12,12))\n",
    "#clf1.feature_importances_ 可以知道重要屬性是誰\n",
    "plt.barh(names, clf1.feature_importances_)\n",
    "#圖的標題\n",
    "plt.title(\"Random Forest Feature Importance\")\n",
    "#畫出圖\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2469a70536e4d2335a2ea8907942d0699c37342a371ac185bdb5b0aa6f073890"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
