# 電商技術 HW3 第三部分

## 1.載入 customer_churn.csv，列出資料筆數、屬性數量以及每個欄位的空值個數

customer_churn.csv 原始資料共3083筆、屬性數20:
![](https://i.imgur.com/IcjK3Cb.jpg)

以下為每個欄位的空值個數 :

1. CustomerID 無空值
![](https://i.imgur.com/fxSytjT.jpg)

2. Churn 無空值
![](https://i.imgur.com/cZWJxS7.jpg)

3. Tenure 有153筆空值
![](https://i.imgur.com/JMAxB9X.jpg)

4. PreferredLoginDevice 無空值
![](https://i.imgur.com/PL8BjY4.jpg)

5. CityTier 無空值
![](https://i.imgur.com/ig7uRAq.jpg)

6. WarehouseToHome 154筆空值
![](https://i.imgur.com/LIh7UUB.jpg)

7. PreferredPaymentMode 無空值
![](https://i.imgur.com/Rf8jIUp.jpg)

8. Gender 無空值
![](https://i.imgur.com/oJIQAwm.jpg)

9. HourSpendOnApp 150筆空值
![](https://i.imgur.com/WQhSFHX.jpg)

10. NumberOfDeviceRegistered 無空值
![](https://i.imgur.com/lziUrXm.jpg)

11. PreferredOrderCat 無空值
![](https://i.imgur.com/ApiNuoX.jpg)

12. SatisfactionScore 無空值
![](https://i.imgur.com/PtSkDhO.jpg)

13. MaritalStatus 無空值
![](https://i.imgur.com/5bbSwzr.jpg)

14. NumberOfAddress 無空值
![](https://i.imgur.com/HOaDD7W.jpg)

15. Complain 無空值
![](https://i.imgur.com/omJkmTz.jpg)

16. OrderAmountHikeFromlastYear 131筆空值
![](https://i.imgur.com/sZEHQ6h.jpg)

17. CouponUsed 126筆空值
![](https://i.imgur.com/A5iyOpl.jpg)

18. OrderCount 128筆空值
![](https://i.imgur.com/J6PexCY.jpg)

19. DaySinceLastOrder 166筆空值
![](https://i.imgur.com/UvDOuQ6.jpg)

20. CashbackAmount 無空值
![](https://i.imgur.com/mqmVDGu.jpg)

---

## 2.請刪除重覆多餘的資料 (僅保留一筆)，並列出剩餘的資料筆數

有重複的 CustomerID 表示有重複的紀錄，必須將其刪除 :

![](https://i.imgur.com/IGGixmQ.jpg)

透過 fiter 找到 RemoveDuplicates 刪去重複資料 : 

![](https://i.imgur.com/tppiWlM.jpg)

Apply 之後，可以觀察到已經沒有重複的 CustomerID，亦即沒有重複的資料 : 

![](https://i.imgur.com/B0EhIRT.jpg)

---

## 3.資料前處理

### 填補 Missing Value

nominal 以 mode 填補 missing value
numeric 以 mean 填補 missing value

![](https://i.imgur.com/Tby2MOU.jpg)

以 Tenure 為例，missing value 都不見了，其餘屬性也是如此

![](https://i.imgur.com/uGsN5OJ.jpg)

接下來將 categorical 屬性值都轉成 numeric value，我選擇的是 filter 中的 NominalToBinary，在屬性值不是二元可分的情況，其實就跟 Python 的 pandas.get_dummies 很像，把屬性變得更多了。

![](https://i.imgur.com/UBJdsSk.jpg)

![](https://i.imgur.com/FyzJ6RM.jpg)

最後，把 churn 用 filter 中的 NumericToNominal 就可以套用 SVM、Logistic Regression、Decision Tree 來預測 churn 了。

![](https://i.imgur.com/Ev94RWN.jpg)

![](https://i.imgur.com/Dqd8Wyt.jpg)

---

## 4.訓練、測試 SVM、Logistic Regression、Decision Tree 模型，請以 Accuracy 評估 模型表現

(模型皆為預設未調整，Training Data: 66%)

**未用 NominalToBinary 前各模型準確率 :**

SVM : 判斷正確為 82.9035%

![](https://i.imgur.com/2KIZ8KZ.jpg)


Logistic Regression : 判斷正確為 83.0946%

![](https://i.imgur.com/1kC1185.jpg)

Decision Tree : 判斷正確為 87.5836%

![](https://i.imgur.com/mC6qs2z.jpg)

**用 NominalToBinary 後各模型準確率 :**

SVM : 判斷正確為 82.9035%

![](https://i.imgur.com/bfbdA3m.jpg)

Logistic Regression : 判斷正確為 83.0946%

![](https://i.imgur.com/e8VqWlk.jpg)


Decision Tree : 判斷正確為 90.4489%

![](https://i.imgur.com/cWBIfn8.jpg)


結論 : 用 NominalToBinary 的前後，SVM 與 Logistic Regression 的準確率沒有影響，但 Decision Tree 的準確率有微幅上升。